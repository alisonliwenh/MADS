{"text": "MATLAB (matrix laboratory) is a multi-paradigm numerical computing environment and proprietary programming language developed by MathWorks. MATLAB allows matrix manipulations, plotting of functions and data, implementation of algorithms, creation of user interfaces, and interfacing with programs written in other languages, including C, C++, C#, Java, Fortran and Python.\n\nAlthough MATLAB is intended primarily for numerical computing, an optional toolbox uses the MuPAD symbolic engine, allowing access to symbolic computing abilities. An additional package, Simulink, adds graphical multi-domain simulation and model-based design for dynamic and embedded systems.\n\nAs of 2018, MATLAB has more than 3 million users worldwide. MATLAB users come from various backgrounds of engineering, science, and economics.", "title": "MATLAB", "category": "Data mining and machine learning software"}
{"text": "Raymond Kurzweil ( ; born February 12, 1948) is an American inventor and futurist. He is involved in fields such as optical character recognition (OCR), text-to-speech synthesis, speech recognition technology, and electronic keyboard instruments. He has written books on health, artificial intelligence (AI), transhumanism, the technological singularity, and futurism. Kurzweil is a public advocate for the futurist and transhumanist movements, and gives public talks to share his optimistic outlook on life extension technologies and the future of nanotechnology, robotics, and biotechnology.\n\nKurzweil received the 1999 National Medal of Technology and Innovation, the United States' highest honor in technology, from President Clinton in a White House ceremony. He was the recipient of the $500,000 Lemelson-MIT Prize for 2001 via  the Internet Archive]. And in 2002 he was inducted into the National Inventors Hall of Fame, established by the U.S. Patent Office. He has received 21 honorary doctorates, and honors from three U.S. presidents. The Public Broadcasting Service (PBS) included Kurzweil as one of 16 \"revolutionaries who made America\" along with other inventors of the past two centuries. Inc. magazine ranked him #8 among the \"most fascinating\" entrepreneurs in the United States and called him \"Edison's rightful heir\".\n\nKurzweil has written seven books, five of which have been national bestsellers. The Age of Spiritual Machines has been translated into 9 languages and was the #1 best-selling book on Amazon in science. Kurzweil's book The Singularity Is Near was a New York Times bestseller, and has been the #1 book on Amazon in both science and philosophy. Kurzweil speaks widely to audiences both public and private and regularly delivers keynote speeches at industry conferences like DEMO, SXSW, and TED. He maintains the news website KurzweilAI.net, which has over three million readers annually.\n\nKurzweil has been employed by Google since 2012, where he is a \"director of engineering\".", "title": "Ray Kurzweil", "category": "Machine learning researchers"}
{"text": "In computer science and operations research, a genetic algorithm (GA) is a metaheuristic inspired by   the process of natural selection that belongs to the larger class of evolutionary algorithms (EA). Genetic algorithms are commonly used to generate high-quality solutions to optimization and search problems by relying on bio-inspired operators such as mutation, crossover and selection. John Holland introduced genetic algorithms in 1960 based on the concept of Darwin\u2019s theory of evolution; afterwards, his student David E. Goldberg extended GA in 1989.", "title": "Genetic algorithm", "category": "Machine learning"}
{"text": "Data mining  is the process of discovering patterns in large data sets involving methods at the intersection of machine learning, statistics, and database systems. Data mining is an interdisciplinary subfield of computer science and statistics with an overall goal to extract information (with intelligent methods) from a data set and transform the information into a comprehensible structure for further use. Data mining is the analysis step of the \"knowledge discovery in databases\" process, or KDD. Aside from the raw analysis step, it also involves database and data management aspects, data pre-processing, model and inference considerations, interestingness metrics, complexity considerations, post-processing of discovered structures, visualization, and online updating. The difference between data analysis and data mining is that data analysis is used to test models and hypotheses on the dataset, e.g., analyzing the effectiveness of a marketing campaign, regardless of the amount of data; in contrast, data mining uses machine-learning and statistical models to uncover clandestine or hidden patterns in a large volume of data.Olson, D. L. (2007). Data mining in business services. Service Business, 1(3), 181-193. doi:10.1007/s11628-006-0014-7\n\nThe term \"data mining\" is in fact a misnomer, because the goal is the extraction of patterns and knowledge from large amounts of data, not the extraction (mining) of data itself. It also is a buzzwordOKAIRP 2005 Fall Conference, Arizona State University  and is frequently applied to any form of large-scale data or information processing (collection, extraction, warehousing, analysis, and statistics) as well as any application of computer decision support system, including artificial intelligence (e.g., machine learning) and business intelligence. The book Data mining: Practical machine learning tools and techniques with Java (which covers mostly machine learning material) was originally to be named just Practical machine learning, and the term data mining was only added for marketing reasons. Often the more general terms (large scale) data analysis and analytics \u2013 or, when referring to actual methods, artificial intelligence and machine learning \u2013 are more appropriate.\n\nThe actual data mining task is the semi-automatic or automatic analysis of large quantities of data to extract previously unknown, interesting patterns such as groups of data records (cluster analysis), unusual records (anomaly detection), and dependencies (association rule mining, sequential pattern mining). This usually involves using database techniques such as spatial indices. These patterns can then be seen as a kind of summary of the input data, and may be used in further analysis or, for example, in machine learning and predictive analytics. For example, the data mining step might identify multiple groups in the data, which can then be used to obtain more accurate prediction results by a decision support system. Neither the data collection, data preparation, nor result interpretation and reporting is part of the data mining step, but do belong to the overall KDD process as additional steps.\n\nThe related terms data dredging, data fishing, and data snooping refer to the use of data mining methods to sample parts of a larger population data set that are (or may be) too small for reliable statistical inferences to be made about the validity of any patterns discovered. These methods can, however, be used in creating new hypotheses to test against the larger data populations.", "title": "Data mining", "category": "Data mining"}
{"text": "GNU Octave is software featuring a high-level programming language, primarily intended for numerical computations. Octave helps in solving linear and nonlinear problems numerically, and for performing other numerical experiments using a language that is mostly compatible with MATLAB. It may also be used as a batch-oriented language.\nSince it is part of the GNU Project, it is free software under the terms of the GNU General Public License.\n\nOctave is one of the major free alternatives to MATLAB, others being Scilab and FreeMat. Scilab, however, puts less emphasis on (bidirectional) syntactic compatibility with MATLAB than Octave does.", "title": "GNU Octave", "category": "Data mining and machine learning software"}
{"text": "Wolfram Mathematica (usually termed Mathematica) is a modern technical computing system spanning most areas of technical computing - including neural networks, machine learning, image processing, geometry, data science, visualizations, and others. The system is used in many technical, scientific, engineering, mathematical, and computing fields. It was conceived by Stephen Wolfram and is developed by Wolfram Research of Champaign, Illinois.Stephen Wolfram: Simple Solutions; The iconoclastic physicist's Mathematica software nails complex puzzles, BusinessWeek, October 3, 2005. The Wolfram Language is the programming language used in Mathematica.\n\n__TOC__", "title": "Wolfram Mathematica", "category": "Data mining and machine learning software"}
{"text": "Stephen Wolfram (; born 29 August 1959) is a British-American computer scientist, physicist, and businessman. He is known for his work in computer science, mathematics, and in theoretical physics. In 2012, he was named an inaugural fellow of the American Mathematical Society.List of Fellows of the American Mathematical Society, retrieved 1 September 2013.\n\nAs a businessman, he is the founder and CEO of the software company Wolfram Research where he worked as chief designer of Mathematica and the Wolfram Alpha answer engine. His recent work has been on knowledge-based programming, expanding and refining the programming language of Mathematica into what is now called the Wolfram Language. \n", "title": "Stephen Wolfram", "category": "Machine learning researchers"}
{"text": "Reinforcement learning (RL) is an area of machine learning concerned with how software agents ought to take actions in an environment so as to maximize some notion of cumulative reward. Reinforcement learning is one of three basic machine learning paradigms, alongside supervised learning and unsupervised learning.\n\nIt differs from supervised learning in that labelled input/output pairs need not be presented, and sub-optimal actions need not be explicitly corrected. Instead the focus is finding a balance between exploration (of uncharted territory) and exploitation (of current knowledge).\n\nThe environment is typically formulated as a Markov decision process (MDP), as many reinforcement learning algorithms for this context utilize dynamic programming techniques.Dimitri P. Bertsekas and John N. Tsitsiklis. \"Neuro-Dynamic Programming\", Athena Scientific, 1996,Dimitri P. Bertsekas. \"Dynamic Programming and Optimal Control: Approximate Dynamic Programming, Vol.II\", Athena Scientific, 2012, The main difference between the classical dynamic programming methods  and reinforcement learning algorithms is that the latter do not assume knowledge of an exact mathematical model of the MDP and they target large MDPs where exact methods become infeasible.", "title": "Reinforcement learning", "category": "Machine learning algorithms"}
{"text": "Maple is a symbolic and numeric computing environment, and is also a multi-paradigm programming language.\n\nDeveloped by Maplesoft, Maple also covers other aspects of technical computing, including visualization, data analysis, matrix computation, and connectivity.\n\nA toolbox, MapleSim, adds functionality for multidomain physical modeling and code generation.", "title": "Maple (software)", "category": "Data mining and machine learning software"}
{"text": "Douglas Bruce Lenat (born 1950) is the CEO of Cycorp, Inc. of Austin, Texas, and has been a prominent researcher in artificial intelligence; he was awarded the biannual IJCAI Computers and Thought Award in 1976 for creating the machine learning program, AM.  He has worked on (symbolic, not statistical) machine learning (with his AM and Eurisko programs),  knowledge representation, \"cognitive economy\", blackboard systems, and what he dubbed in 1984 \"ontological engineering\" (with his Cyc program at MCC and, since 1994, at Cycorp).  He has also worked in military simulations, and numerous projects for US government, military, intelligence, and scientific organizations.  In 1980, he published a critique of conventional random-mutation Darwinism.Lenat, Douglas. \"The Heuristics of Nature: The Plausible Mutation of DNA.\" Stanford Heuristic Programming Project, 1980, technical report HPP-80-27.  He authored a series of articles in the Journal of Artificial Intelligence exploring the nature of heuristic rules.\n\nLenat was one of the original Fellows of the AAAI, and is the only individual to have served on the Scientific Advisory Boards of both Microsoft and Apple.  He is a Fellow of the AAAS, AAAI, and Cognitive Science Society, and an editor of the J. Automated Reasoning, J. Learning Sciences, and J. Applied Ontology.   He was one of the founders of  TTI/Vanguard in 1991 and remains a member of its advisory board still in 2017.  He was named one of the Wired 25.", "title": "Douglas Lenat", "category": "Machine learning researchers"}
{"text": "Pattern recognition is the automated recognition of patterns and regularities in data. Pattern recognition is closely related to artificial intelligence and machine learning,\n together with applications such as data mining and knowledge discovery in databases (KDD), and is often used interchangeably with these terms. However, these are distinguished: machine learning is one approach to pattern recognition, while other approaches include hand-crafted (not learned) rules or heuristics; and pattern recognition is one approach to artificial intelligence, while other approaches include symbolic artificial intelligence. A modern definition of pattern recognition is:\n\nThis article focuses on machine learning approaches to pattern recognition. Pattern recognition systems are in many cases trained from labeled \"training\" data (supervised learning), but when no labeled data are available other algorithms can be used to discover previously unknown patterns (unsupervised learning). Machine learning is the common term for supervised learning methods and originates from artificial intelligence, whereas KDD and data mining have a larger focus on unsupervised methods and stronger connection to business use. Pattern recognition has its origins in engineering, and the term is popular in the context of computer vision: a leading computer vision conference is named Conference on Computer Vision and Pattern Recognition. In pattern recognition, there may be a higher interest to formalize, explain and visualize the pattern, while machine learning traditionally focuses on maximizing the recognition rates. Yet, all of these domains have evolved substantially from their roots in artificial intelligence, engineering and statistics, and they've become increasingly similar by integrating developments and ideas from each other.\n\nIn machine learning, pattern recognition is the assignment of a label to a given input value. In statistics, discriminant analysis was introduced for this same purpose in 1936. An example of pattern recognition is classification, which attempts to assign each input value to one of a given set of classes (for example, determine whether a given email is \"spam\" or \"non-spam\"). However, pattern recognition is a more general problem that encompasses other types of output as well. Other examples are regression, which assigns a real-valued output to each input; sequence labeling, which assigns a class to each member of a sequence of values (for example, part of speech tagging, which assigns a part of speech to each word in an input sentence); and parsing, which assigns a parse tree to an input sentence, describing the syntactic structure of the sentence.\n\nPattern recognition algorithms generally aim to provide a reasonable answer for all possible inputs and to perform \"most likely\" matching of the inputs, taking into account their statistical variation. This is opposed to pattern matching algorithms, which look for exact matches in the input with pre-existing patterns. A common example of a pattern-matching algorithm is regular expression matching, which looks for patterns of a given sort in textual data and is included in the search capabilities of many text editors and word processors. In contrast to pattern recognition, pattern matching is not generally a type of machine learning, although pattern-matching algorithms (especially with fairly general, carefully tailored patterns) can sometimes succeed in providing similar-quality output of the sort provided by pattern-recognition algorithms.", "title": "Pattern recognition", "category": "Machine learning"}
{"text": "SAS Institute (or SAS, pronounced \"sass\") is an American multinational developer of analytics software based in Cary, North Carolina. SAS develops and markets a suite of analytics software (also called SAS), which helps access, manage, analyze and report on data to aid in decision-making. The company is the world's largest privately held software business and its software is used by most of the Fortune 500.\n\nSAS Institute started as a project at North Carolina State University to create a statistical analysis system (hence the proper name, Statistical Analysis System) that was originally used primarily by agricultural departments at universities in the late 1960s. It became an independent, private business led by current CEO James Goodnight and three other project leaders from the university in 1976. SAS grew from $10 million in revenues in 1980 to $1.1 billion by 2000. A larger proportion of these revenues are spent on research and development than at most other software companies, at one point more than double the industry average.", "title": "SAS Institute", "category": "Data analysis software"}
{"text": "Vladimir Naumovich Vapnik (; born 6 December 1936) is one of the main developers of the Vapnik\u2013Chervonenkis theory of statistical learning, and the co-inventor of the support-vector machine method, and support-vector clustering algorithm.", "title": "Vladimir Vapnik", "category": "Machine learning researchers"}
{"text": "In machine learning, early stopping is a form of regularization used to avoid overfitting when training a learner with an iterative method, such as gradient descent. Such methods update the learner so as to make it better fit the training data with each iteration. Up to a point, this improves the learner's performance on data outside of the training set. Past that point, however, improving the learner's fit to the training data comes at the expense of increased generalization error. Early stopping rules provide guidance as to how many iterations can be run before the learner begins to over-fit. Early stopping rules have been employed in many different machine learning methods, with varying amounts of theoretical foundation.", "title": "Early stopping", "category": "Machine learning"}
{"text": "Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use in order to perform a specific task effectively without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model based on sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task. Machine learning algorithms are used in a wide variety of applications, such as email filtering, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning. In its application across business problems, machine learning is also referred to as predictive analytics.", "title": "Machine learning", "category": "Machine learning"}
{"text": "Formal concept analysis (FCA) is a principled way of deriving a concept hierarchy or formal ontology from a collection of objects and their properties. Each concept in the hierarchy represents the objects sharing some set of properties; and each sub-concept in the hierarchy represents a subset of the objects (as well as a superset of the properties) in the concepts above it. The term was introduced by Rudolf Wille in 1981, and builds on the mathematical theory of lattices and ordered sets that was developed by Garrett Birkhoff and others in the 1930s.\n\nFormal concept analysis finds practical application in fields including data mining, text mining, machine learning, knowledge management, semantic web, software development, chemistry and biology.", "title": "Formal concept analysis", "category": "Machine learning"}
{"text": "In time series analysis, dynamic time warping (DTW) is one of the algorithms for measuring similarity between two temporal sequences, which may vary in speed.  For instance, similarities in walking could be detected using DTW, even if one person was walking faster than the other, or if there were accelerations and decelerations during the course of an observation. DTW has been applied to temporal sequences of video, audio, and graphics data \u2014 indeed, any data that can be turned into a linear sequence can be analyzed with DTW. A well known application has been automatic speech recognition, to cope with different speaking speeds. Other applications include speaker recognition and online signature recognition. Also it is seen that it can be used in partial shape matching application.\n\nIn general, DTW is a method that calculates an optimal match between two given sequences (e.g. time series) with certain restriction and rules:\n Every index from the first sequence must be matched with one or more indices from the other sequence, and vice versa\n The first index from the first sequence must be matched with the first index from the other sequence (but it does not have to be its only match)\n The last index from the first sequence must be matched with the last index from the other sequence (but it does not have to be its only match)\n The mapping of the indices from the first sequence to indices from the other sequence must be monotonically increasing, and vice versa, i.e. if j > i are indices from the first sequence, then there must not be two indices l > k in the other sequence, such that index i is matched with index l and index j is matched with index k, and vice versa\n\nThe optimal match is denoted by the match that satisfies all the restrictions and the rules and that has the minimal cost, where the cost is computed as the sum of absolute differences, for each matched pair of indices, between their values.\n\nThe sequences are \"warped\" non-linearly in the time dimension to determine a measure of their similarity independent of certain non-linear variations in the time dimension. This sequence alignment method is often used in time series classification. Although DTW measures a distance-like quantity between two given sequences, it doesn't guarantee the triangle inequality to hold.\n\nIn addition to a similarity measure between the two sequences, a so called \"warping path\" is produced, by warping according to this path the two signals may be aligned in time. The signal with an original set of points X(original), Y(original) is transformed to X(warped), Y(warped). This finds applications in genetic sequence and audio synchronisation. In a related technique sequences of varying speed may be averaged using this technique see the average sequence section.\n\nThis is conceptually very similar to the Needleman\u2013Wunsch algorithm, which is explained in greater details.", "title": "Dynamic time warping", "category": "Machine learning algorithms"}
{"text": "R is a programming language and free software environment for statistical computing and graphics supported by the R Foundation for Statistical Computing. The R language is widely used among statisticians and data miners for developing statistical software and data analysis. Polls, data mining surveys, and studies of scholarly literature databases show substantial increases in popularity;  R ranks 22nd in the TIOBE index, a measure of popularity of programming languages.\n\nA GNU package, source code for the R software environment is written primarily in C, Fortran and R itself, and is freely available under the GNU General Public License. Pre-compiled binary versions are provided for various operating systems. Although R has a command line interface, there are several graphical user interfaces, such as RStudio, an integrated development environment.", "title": "R (programming language)", "category": "Data mining and machine learning software"}
{"text": "In computer science, computational learning theory (or just learning theory) is a subfield of artificial intelligence devoted to studying the design and analysis of machine learning algorithms.http://www.learningtheory.org/", "title": "Computational learning theory", "category": "Machine learning"}
{"text": "Visual inspection is a common method of quality control, data acquisition, and data analysis.Visual Inspection, used in maintenance of facilities, mean inspection of equipment and structures using either or all of raw human senses such as vision, hearing, touch and smell and/or any non-specialized inspection equipment.\nInspections requiring Ultrasonic, X-Ray equipment, Infra-red, etc. are not typically regarded as Visual Inspection as these Inspection methodologies require specialized equipment, training and certification.", "title": "Visual inspection", "category": "Data analysis"}
{"text": "J\u00fcrgen Schmidhuber (born 17 January 1963)CV is a computer scientist most noted for his work in the field of artificial intelligence, deep learning and artificial neural networks. He is a co-director of the Dalle Molle Institute for Artificial Intelligence Research in  Manno, in the district of Lugano, in Ticino in southern Switzerland. He is sometimes called the \"father of (modern) AI\" or \"father of deep learning.\"\n\nSchmidhuber did his undergraduate studies at the Technische Universit\u00e4t M\u00fcnchen in Munich, Germany. He taught there from 2004 until 2009 when he became a professor of artificial intelligence at the Universit\u00e0 della Svizzera Italiana in Lugano, Switzerland.", "title": "J\u00fcrgen Schmidhuber", "category": "Machine learning researchers"}
{"text": "Ray Solomonoff's theory of universal inductive inference is a theory of prediction based on logical observations, such as predicting the next symbol based upon a given series of symbols. The only assumption that the theory makes is that the environment follows some unknown but computable probability distribution. It is a mathematical formalization of Occam's razorJJ McCall. Induction: From Kolmogorov and Solomonoff to De Finetti and Back to Kolmogorov \u2013 Metroeconomica, 2004 \u2013 Wiley Online Library.D Stork. Foundations of Occam's razor and parsimony in learning from ricoh.com \u2013 NIPS 2001 Workshop, 2001A.N. Soklakov. Occam's razor as a formal basis for a physical theory\nfrom arxiv.org \u2013 Foundations of Physics Letters, 2002 \u2013 SpringerM Hutter. On the existence and convergence of computable universal priors arxiv.org \u2013 Algorithmic Learning Theory, 2003 \u2013 Springer and the Principle of Multiple Explanations.Ming Li and Paul Vitanyi, An Introduction to Kolmogorov Complexity and Its Applications.  Springer-Verlag, N.Y., 2008p 339 ff.\n\nPrediction is done using a completely Bayesian framework. The universal prior is calculated for all computable sequences\u2014this is the universal a priori probability distribution;\nno computable hypothesis will have a zero probability. This means that Bayes rule of causation can be used in predicting the continuation of any particular computable sequence.", "title": "Solomonoff's theory of inductive inference", "category": "Machine learning"}
{"text": "Folding@home (FAH or F@h) is a distributed computing project for disease research that simulates protein folding, computational drug design, and other types of molecular dynamics. The project uses the idle processing resources of thousands of personal computers owned by volunteers who have installed the software on their systems. Its main purpose is to determine the mechanisms of protein folding, which is the process by which proteins reach their final three-dimensional structure, and to examine the causes of protein misfolding. This is of significant academic interest with major implications for medical research into Alzheimer's disease, Huntington's disease, and many forms of cancer, among other diseases. To a lesser extent, Folding@home also tries to predict a protein's final structure and determine how other molecules may interact with it, which has applications in drug design. Folding@home is developed and operated by the Pande Laboratory at Stanford University, under the direction of Prof. Vijay Pande, and is shared by various scientific institutions and research laboratories across the world.\n\nThe project has pioneered the use of graphics processing units (GPUs), PlayStation\u00a03s, Message Passing Interface (used for computing on multi-core processors), and some Sony Xperia smartphones for distributed computing and scientific research. The project uses statistical simulation methodology that is a paradigm shift from traditional computing methods. As part of the client\u2013server model network architecture, the volunteered machines each receive pieces of a simulation (work units), complete them, and return them to the project's database servers, where the units are compiled into an overall simulation. Volunteers can track their contributions on the Folding@home website, which makes volunteers' participation competitive and encourages long-term involvement.\n\nFolding@home is one of the world's fastest computing systems, with a speed of approximately . This performance from its large-scale computing network has allowed researchers to run computationally costly atomic-level simulations of protein folding thousands of times longer than formerly achieved. Since its launch on 1\u00a0Oct\u00a02000, the Pande Lab has produced 206 scientific research papers as a direct result of Folding@home. Results from the project's simulations agree well with experiments.", "title": "Folding@home", "category": "Data mining and machine learning software"}
{"text": "Evolutionary programming is one of the four major evolutionary algorithm paradigms.  It is similar to genetic programming, but the structure of the program to be optimized is fixed, while its numerical parameters are allowed to evolve.\nIt was first used by Lawrence J. Fogel in the US in 1960 in order to use simulated evolution as a learning process aiming to generate artificial intelligence. Fogel used finite-state machines as predictors and evolved them.\nCurrently evolutionary programming is a wide evolutionary computing dialect with no fixed structure or (representation), in contrast with some of the other dialects. It is becoming harder to distinguish from evolutionary strategies.\n\nIts main variation operator is mutation; members of the population are viewed as part of a specific species rather than members of the same species therefore each parent generates an offspring, using a (\u03bc + \u03bc) survivor selection.", "title": "Evolutionary programming", "category": "Machine learning"}
{"text": "FICO (legal name: Fair Isaac Corporation), originally Fair, Isaac and Company, is a data analytics company based in San Jose, California focused on credit scoring services. It was founded by Bill Fair and Earl Isaac in 1956. Its FICO score, a measure of consumer credit risk, has become a fixture of consumer lending in the United States.\n\nIn 2013, lenders purchased more than 10 billion FICO scores and about 30 million American consumers accessed their scores themselves.", "title": "FICO", "category": "Data mining and machine learning software"}
{"text": "In statistics, an expectation\u2013maximization (EM) algorithm is an iterative method to find maximum likelihood or maximum a posteriori (MAP) estimates of parameters in statistical models, where the model depends on unobserved latent variables. The EM iteration alternates between performing an expectation (E) step, which creates a function for the expectation of the log-likelihood evaluated using the current estimate for the parameters, and a maximization (M) step, which computes parameters maximizing the expected log-likelihood found on the E step. These parameter-estimates are then used to determine the distribution of the latent variables in the next E step.", "title": "Expectation\u2013maximization algorithm", "category": "Machine learning algorithms"}
{"text": "Geoffrey Everest Hinton  One or more of the preceding sentences incorporates text from the royalsociety.org website where:  (born 6 December 1947) is an English Canadian cognitive psychologist and computer scientist, most noted for his work on artificial neural networks. Since 2013 he divides his time working for Google (Google Brain) and the University of Toronto.\n\nWith David E. Rumelhart and Ronald J. Williams, Hinton was co-author of a highly-cited paper published in 1986 that popularized the backpropagation algorithm for training multi-layer neural networks, although they were not the first to propose the approach. Hinton is viewed by some as a leading figure in the deep learning community and is referred to by some as the \"Godfather of Deep Learning\". The dramatic image-recognition milestone of the AlexNet designed by his student Alex Krizhevsky for the Imagenet challenge 2012 helped to revolutionize the field of computer vision. Hinton was awarded the 2018 Turing Prize alongside Yoshua Bengio and Yann LeCun for their work on deep learning.", "title": "Geoffrey Hinton", "category": "Machine learning researchers"}
{"text": "AprioriRakesh Agrawal and Ramakrishnan Srikant Fast algorithms for mining association rules. Proceedings of the 20th International Conference on Very Large Data Bases, VLDB, pages 487-499, Santiago, Chile, September 1994. is an algorithm for frequent item set mining and association rule learning over transactional databases. It proceeds by identifying the frequent individual items in the database and extending them to larger and larger item sets as long as those item sets appear sufficiently often in the database. The frequent item sets determined by Apriori can be used to determine association rules which highlight general trends in the database: this has applications in domains such as market basket analysis.", "title": "Apriori algorithm", "category": "Data mining algorithms"}
{"text": "Cluster analysis or clustering is the task of grouping a set of objects in such a way that objects in the same group (called a cluster) are more similar (in some sense) to each other than to those in other groups (clusters). It is a main task of exploratory data mining, and a common technique for statistical data analysis, used in many fields, including machine learning, pattern recognition, image analysis, information retrieval, bioinformatics, data compression, and computer graphics.\n\nCluster analysis itself is not one specific algorithm, but the general task to be solved. It can be achieved by various algorithms that differ significantly in their understanding of what constitutes a cluster and how to efficiently find them. Popular notions of clusters include groups with small distances between cluster members, dense areas of the data space, intervals or particular statistical distributions. Clustering can therefore be formulated as a multi-objective optimization problem. The appropriate clustering algorithm and parameter settings (including parameters such as the distance function to use, a density threshold or the number of expected clusters) depend on the individual data set and intended use of the results. Cluster analysis as such is not an automatic task, but an iterative process of knowledge discovery or interactive multi-objective optimization that involves trial and failure. It is often necessary to modify data preprocessing and model parameters until the result achieves the desired properties.\n\nBesides the term clustering, there are a number of terms with similar meanings, including automatic classification, numerical taxonomy, botryology (from Greek \u03b2\u03cc\u03c4\u03c1\u03c5\u03c2 \"grape\"), typological analysis, and community detection. The subtle differences are often in the use of the results: while in data mining, the resulting groups are the matter of interest, in automatic classification the resulting discriminative power is of interest.\n\nCluster analysis was originated in anthropology by Driver and Kroeber in 1932 and introduced to psychology by Joseph Zubin in 1938 and Robert Tryon in 1939 and famously used by Cattell beginning in 1943 for trait theory classification in personality psychology.", "title": "Cluster analysis", "category": "Data mining"}
{"text": "The curse of dimensionality refers to various phenomena that arise when analyzing and organizing data in high-dimensional spaces (often with hundreds or thousands of dimensions) that do not occur in low-dimensional settings such as the three-dimensional physical space of everyday experience.The expression was coined by Richard E. Bellman when considering problems in dynamic programming.,Republished: \n\nCursed phenomena occur in domains such as numerical analysis, sampling, combinatorics, machine learning, data mining and databases. The common theme of these problems is that when the dimensionality increases, the volume of the space increases so fast that the available data become sparse. This sparsity is problematic for any method that requires statistical significance. In order to obtain a statistically sound and reliable result, the amount of data needed to support the result often grows exponentially with the dimensionality. Also, organizing and searching data often relies on detecting areas where objects form groups with similar properties; in high dimensional data, however, all objects appear to be sparse and dissimilar in many ways, which prevents common data organization strategies from being efficient.", "title": "Curse of dimensionality", "category": "Machine learning"}
{"text": "Data profiling is the process of examining the data available from an existing information source (e.g. a database or a file) and collecting statistics or informative summaries about that data. The purpose of these statistics may be to:\n Find out whether existing data can be easily used for other purposes\n Improve the ability to search data by tagging it with keywords, descriptions, or assigning it to a category\n Assess data quality, including whether the data conforms to particular standards or patterns\n Assess the risk involved in integrating data in new applications, including the challenges of joins\n Discover metadata of the source database, including value patterns and distributions, key candidates, foreign-key candidates, and functional dependencies\n Assess whether known metadata accurately describes the actual values in the source database\n Understanding data challenges early in any data intensive project, so that late project surprises are avoided. Finding data problems late in the project can lead to delays and cost overruns.\n Have an enterprise view of all data, for uses such as master data management, where key data is needed, or data governance for improving data quality.", "title": "Data profiling", "category": "Data analysis"}
{"text": "Web mining is the application of data mining techniques to discover patterns from the World Wide Web. As the name proposes, this is information gathered by mining the web. It makes utilization of automated apparatuses to reveal and extricate data from servers and web2 reports, and it permits organizations to get to both organized and unstructured information from browser activities, server logs, website and link structure, page content and different sources.\n\nThe goal of Web structure mining is to generate structural summary about the Web site and Web page. Technically, Web content mining mainly focuses on the structure of inner-document, while Web structure mining tries to discover the link structure of the hyperlinks at the inter-document level. Based on the topology of the hyperlinks, Web structure mining will categorize the Web pages and generate the information, such as the similarity and relationship between different Web sites.\n\nWeb structure mining can also have another direction -- discovering the structure of Web document itself. This type of structure mining can be used to reveal the structure (schema) of Web pages, this would be good for navigation purpose and make it possible to compare/integrate Web page schemes. This type of structure mining will facilitate introducing database techniques for accessing information in Web pages by providing a reference schema.", "title": "Web mining", "category": "Data mining"}
{"text": "In the field of machine learning and specifically the problem of statistical classification, a confusion matrix, also known as an error matrix, is a specific table layout that allows visualization of the performance of an algorithm, typically a supervised learning one (in unsupervised learning it is usually called a matching matrix).  Each row of the matrix represents the instances in a predicted class while each column represents the instances in an actual class (or vice versa).  The name stems from the fact that it makes it easy to see if the system is confusing two classes (i.e. commonly mislabeling one as another).\n\nIt is a special kind of contingency table, with two dimensions (\"actual\" and \"predicted\"), and identical sets of \"classes\" in both dimensions (each combination of dimension and class is a variable in the contingency table).", "title": "Confusion matrix", "category": "Machine learning"}
{"text": "A receiver operating characteristic curve, or ROC curve, is a graphical plot that illustrates the diagnostic ability of a binary classifier system as its discrimination threshold is varied.\n\nThe ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. The true-positive rate is also known as sensitivity, recall or probability of detection in machine learning. The false-positive rate is also known as the fall-out or probability of false alarm and can be calculated as (1 \u2212 specificity). It can also be thought of as a plot of the power as a function of the Type I Error of the decision rule (when the performance is calculated from just a sample of the population, it can be thought of as estimators of these quantities). The ROC curve is thus the sensitivity as a function of fall-out. In general, if the probability distributions for both detection and false alarm are known, the ROC curve can be generated by plotting the cumulative distribution function (area under the probability distribution from -\\infty to the discrimination threshold) of the detection probability in the y-axis versus the cumulative distribution function of the false-alarm probability on the x-axis.\n\nROC analysis provides tools to select possibly optimal models and to discard suboptimal ones independently from (and prior to specifying) the cost context or the class distribution. ROC analysis is related in a direct and natural way to cost/benefit analysis of diagnostic decision making.\n\nThe ROC curve was first developed by electrical engineers and radar engineers during World War II for detecting enemy objects in battlefields and was soon introduced to psychology to account for perceptual detection of stimuli. ROC analysis since then has been used in medicine, radiology, biometrics, forecasting of natural hazards, meteorology, model performance assessment, and other areas for many decades and is increasingly used in machine learning and data mining research.\n\nThe ROC is also known as a relative operating characteristic curve, because it is a comparison of two operating characteristics (TPR and FPR) as the criterion changes.Swets, John A.; Signal detection theory and ROC analysis in psychology and diagnostics : collected papers, Lawrence Erlbaum Associates, Mahwah, NJ, 1996", "title": "Receiver operating characteristic", "category": "Data mining"}
{"text": "Relational data mining is the data mining technique for relationaldatabases.Dzeroski, Saso, Lavra\u010d, Nada (Eds.), Relational Data Mining, Springer 2001  Unlike traditional data mining algorithms, which look for\npatterns in a single table (propositional patterns), \nrelational data mining algorithms look for patterns among multiple tables\n(relational patterns). For most types of propositional\npatterns, there are corresponding relational patterns. For example,\nthere are relational classification rules (relational classification), relational regression tree, and relational association rules.\n\nThere are several approaches to relational data mining:\n Inductive Logic Programming (ILP)\n Statistical Relational Learning (SRL)\n Graph Mining\n Propositionalization\n Multi-view learning", "title": "Relational data mining", "category": "Machine learning"}
{"text": "SAS (previously \"Statistical Analysis System\") is a software suite developed by SAS Institute for advanced analytics, multivariate analysis, business intelligence, data management, and predictive analytics.\n\nSAS was developed at North Carolina State University from 1966 until 1976, when SAS Institute was incorporated. SAS was further developed in the 1980s and 1990s with the addition of new statistical procedures, additional components and the introduction of JMP. A point-and-click interface was added in version 9 in 2004. A social media analytics product was added in 2010.", "title": "SAS (software)", "category": "Data mining and machine learning software"}
{"text": "Savi Technology was founded in 1989 and is based in Alexandria, Virginia.\n\nSavi delivers live streaming facts and insights about the location, condition, and security of in-transit goods. Using big data analytics, Savi equips shippers, carriers, 3PLs, and governments to optimize supply chain logistics before, during and after transit, reducing costs and inventory while improving service. Savi is trusted to run the world\u2019s largest and most complex asset tracking and monitoring network serving the US DoD, Allied military and more than 1000 commercial companies around the globe.", "title": "Savi Technology", "category": "Machine learning"}
{"text": "ROOT is an object-oriented program and library developed by CERN. It was originally designed for particle physics data analysis and contains several features specific to this field, but it is also used in other applications such as astronomy and data mining.  The latest release is 6.18.00, as of 2019-06-25.", "title": "ROOT", "category": "Data analysis software"}
{"text": "Statistical learning theory is a framework for machine learning\ndrawing from the fields of statistics and functional analysis.Trevor Hastie, Robert Tibshirani, Jerome Friedman (2009) The Elements of Statistical Learning, Springer-Verlag . Statistical learning theory deals with the problem of finding a predictive function based on data. Statistical learning theory has led to successful applications in fields such as computer vision, speech recognition, bioinformatics and baseball.Gagan Sidhu, Brian Caffo. Exploiting pitcher decision-making using Reinforcement Learning. Annals of Applied Statistics", "title": "Statistical learning theory", "category": "Machine learning"}
{"text": "Stochastic gradient descent (often abbreviated SGD) is an iterative method for optimizing an objective function with suitable smoothness properties (e.g. differentiable or subdifferentiable). It is called stochastic because the method uses randomly selected (or shuffled) samples to evaluate the gradients, hence SGD can be regarded as a stochastic approximation of gradient descent optimization. The ideas can be traced back at least to the 1951 article titled \"A Stochastic Approximation Method\" by Herbert Robbins and Sutton Monro, who proposed with detailed analysis a root-finding method now called the Robbins\u2013Monro algorithm.", "title": "Stochastic gradient descent", "category": "Machine learning algorithms"}
{"text": "A Bongard problem is a kind of puzzle invented by the Russian computer scientist Mikhail Moiseevich Bongard (\u041c\u0438\u0445\u0430\u0438\u043b \u041c\u043e\u0438\u0441\u0435\u0435\u0432\u0438\u0447 \u0411\u043e\u043d\u0433\u0430\u0440\u0434, 1924\u20131971), probably in the mid-1960s. They were published in his 1967 book on pattern recognition. Bongard, in the introduction of the book (which deals with a number of topics including perceptrons) credits the ideas in it to a group including M. N. Vaintsvaig, V. V. Maksimov, and M. S. Smirnov.", "title": "Bongard problem", "category": "Machine learning"}
{"text": "Temporal difference (TD) learning refers to a class of model-free reinforcement learning methods which learn by bootstrapping from the current estimate of the value function. These methods sample from the environment, like Monte Carlo methods, and perform updates based on current estimates, like dynamic programming methods.\n\nWhile Monte Carlo methods only adjust their estimates once the final outcome is known, TD methods adjust predictions to match later, more accurate, predictions about the future before the final outcome is known. (A revised version is available on Richard Sutton's publication page ) This is a form of bootstrapping, as illustrated with the following example:\n\n\"Suppose you wish to predict the weather for Saturday, and you have some model that predicts Saturday's weather, given the weather of each day in the week. In the standard case, you would wait until Saturday and then adjust all your models. However, when it is, for example, Friday, you should have a pretty good idea of what the weather would be on Saturday \u2013 and thus be able to change, say, Saturday's model before Saturday arrives.\"\n\nTemporal difference methods are related to the temporal difference model of animal learning.", "title": "Temporal difference learning", "category": "Machine learning algorithms"}
{"text": "In statistical classification, including machine learning, two main approaches are called the generative approach and the discriminative approach. These compute classifiers by different approaches, differing in the degree of statistical modelling. Terminology is inconsistent, but three major types can be distinguished, following :* Given an observable variable X and a target variable Y, a generative model is a statistical model of the joint probability distribution on X\u00a0\u00d7\u00a0Y, P(X, Y);: \"Generative classifiers learn a model of the joint probability, p(x, y), of the inputs x and the label y, and make their predictions by using Bayes rules to calculate p(y|x), and then picking the most likely label y. \n A discriminative model is a model of the conditional probability of the target Y, given an observation x, symbolically, P(Y|X = x); and \n Classifiers computed without using a probability model are also referred to loosely as \"discriminative\". \nThe distinction between these last two classes is not consistently made;: \"This distinction between conditional learning and discriminative learning is not currently a well established convention in the field.\"  refers to these three classes as generative learning, conditional learning, and discriminative learning, but  only distinguish two classes, calling them generative classifiers (joint distribution) and discriminative classifiers (conditional distribution or no distribution), not distinguishing between the latter two classes.: \"Discriminative classifiers model the posterior p(y|x) directly, or learn a direct map from inputs x to the class labels.\" Analogously, a classifier based on a generative model is a generative classifier, while a classifier based on a discriminative model is a discriminative classifier, though this term also refers to classifiers that are not based on a model. Standard examples of each, all of which are linear classifiers, are: generative classifiers: naive Bayes classifier and linear discriminant analysis; discriminative model: logistic regression; non-model classifier: perceptron and support vector machine.\n\nIn application to classification, one wishes to go from an observation x to a label y (or probability distribution on labels). One can compute this directly, without using a probability distribution (distribution-free classifier); one can estimate the probability of a label given an observation, P(Y|X=x) (discriminative model), and base classification on that; or one can estimate the joint distribution P(X, Y) (generative model), from that compute the conditional probability P(Y|X=x), and then base classification on that. These are increasingly indirect, but increasingly probabilistic, allowing more domain knowledge and probability theory to be applied. In practice different approaches are used, depending on the particular problem, and hybrids can combine strengths of multiple approaches.", "title": "Generative model", "category": "Machine learning"}
{"text": "Q-learning is a model-free reinforcement learning algorithm. The goal of Q-learning is to learn a policy, which tells an agent what action to take under what circumstances. It does not require a model (hence the connotation \"model-free\") of the environment, and it can handle problems with stochastic transitions and rewards, without requiring adaptations.\n\nFor any finite Markov decision process (FMDP), Q-learning finds a policy that is optimal in the sense that it maximizes the expected value of the total reward over any and  all successive steps, starting from the current state. Q-learning can identify an optimal action-selection policy for any given FMDP, given infinite exploration time and a partly-random policy. \"Q\" names the function that returns the reward used to provide the reinforcement and can be said to stand for the \"quality\" of an action taken in a given state.", "title": "Q-learning", "category": "Machine learning algorithms"}
{"text": "In machine learning and pattern recognition, a feature is an individual measurable property or characteristic of a phenomenon being observed. Choosing informative, discriminating and independent features is a crucial step for effective algorithms in pattern recognition,  classification and regression. Features are usually numeric, but structural features such as strings and graphs are used in syntactic pattern recognition.The concept of \"feature\" is related to that of explanatory variable used in statistical techniques such as linear regression.", "title": "Feature (machine learning)", "category": "Machine learning"}
{"text": "Bootstrap aggregating, also called bagging, is a machine learning ensemble meta-algorithm designed to improve the stability and accuracy of machine learning algorithms used in statistical classification and regression. It also reduces variance and helps to avoid overfitting. Although it is usually applied to decision tree methods, it can be used with any type of method. Bagging is a special case of the model averaging approach.", "title": "Bootstrap aggregating", "category": "Machine learning algorithms"}
{"text": "Data dredging (also data fishing, data snooping, data butchery, and p-hacking) is the misuse of data analysis to find patterns in data that can be presented as statistically significant when in fact there is no real underlying effect. This is done by performing many statistical tests on the data and only paying attention to those that come back with significant results, instead of stating a single hypothesis about an underlying effect before the analysis and then conducting a single test for it.\n\nThe process of data dredging involves automatically testing huge numbers of hypotheses about a single data set by exhaustively searching\u2014perhaps for combinations of variables that might show a correlation, and perhaps for groups of cases or observations that show differences in their mean or in their breakdown by some other variable.\n\nConventional tests of statistical significance are based on the probability that a particular result would arise if chance alone were at work, and necessarily accept some risk of mistaken conclusions of a certain type (mistaken rejections of the null hypothesis).  This level of risk is called the significance. When large numbers of tests are performed, some produce false results of this type, hence 5% of randomly chosen hypotheses turn out to be significant at the 5% level, 1% turn out to be significant at the 1% significance level, and so on, by chance alone. When enough hypotheses are tested, it is virtually certain that some will be statistically significant but misleading, since almost every data set with any degree of randomness is likely to contain (for example) some spurious correlations. If they are not cautious, researchers using data mining techniques can be easily misled by these results.\n\nThe multiple comparisons hazard is common in data dredging. Moreover, subgroups are sometimes explored without alerting the reader to the number of questions at issue, which can lead to misinformed conclusions.\n", "title": "Data dredging", "category": "Data mining"}
{"text": "Document classification or document categorization is a problem in library science, information science and computer science. The task is to assign a document to one or more classes or categories. This may be done \"manually\" (or \"intellectually\") or algorithmically. The intellectual classification of documents has mostly been the province of library science, while the algorithmic classification of documents is mainly in information science and computer science. The problems are overlapping, however, and there is therefore interdisciplinary research on document classification.\nThe documents to be classified may be texts, images, music, etc. Each kind of document possesses its special classification problems. When not otherwise specified, text classification is implied.\n\nDocuments may be classified according to their subjects or according to other attributes (such as document type, author, printing year etc.). In the rest of this article only subject classification is considered. There are two main philosophies of subject classification of documents: the content-based approach and the request-based approach.", "title": "Document classification", "category": "Data mining"}
{"text": "Backpropagation algorithms are a family of methods used to efficiently train artificial neural networks (ANNs) following a gradient descent approach that exploits the chain rule. The main feature of backpropagation is its iterative, recursive and efficient method for calculating the weights updates to improve the network until it is able to perform the task for which it is being trained.Goodfellow, Ian; Bengio, Yoshua; Courville, Aaaron (2016) Deep Learning. MIT Press. p. 196.  It is closely related to the Gauss\u2013Newton algorithm.  \n\nBackpropagation requires the derivatives of activation functions to be known at network design time. Automatic differentiation is a technique that can automatically and analytically provide the derivatives to the training algorithm.  In the context of learning, backpropagation is commonly used by the gradient descent optimization algorithm to adjust the weight of neurons by calculating the gradient of the loss function; backpropagation computes the gradient(s), whereas (stochastic) gradient descent uses the gradients for training the model (via optimization).", "title": "Backpropagation", "category": "Machine learning algorithms"}
{"text": "OPeNDAP is an acronym for \"Open-source Project for a Network Data Access Protocol,\" an endeavor focused on enhancing the retrieval of remote, structured data through a Web-based architecture and a discipline-neutral Data Access Protocol (DAP). Widely used, especially in Earth science, the protocol is layered on HTTP, and its current specification is DAP4,DAP4 Specification though the previous DAP2 version remains broadly used. Developed and advanced (openly and collaboratively) by the non-profit  OPeNDAP, Inc.,Official website DAP is intended to enable remote, selective data-retrieval as an easily invoked Web service. OPeNDAP, Inc. also develops and maintains zero-cost (reference) implementations of the DAP protocol in both server-side and client-side software. \n\"OPeNDAP\" often is used in place of \"DAP\" to denote the protocol but also may refer to an entire DAP-based data-retrieval architecture. Other DAP-centered architectures, such as THREDDSTHREDDS and ERDDAP, the NOAA GEO-IDE UAF ERDDAPERDDAP exhibit significant interoperability with one another as well as with systems employing OPeNDAP's own (open-source) servers and software.\n\nA DAP client can be an ordinary browser or even a spreadsheet, though with limited functionality (see OPeNDAP's Web page on Available Client Software). More typically, DAP clients are:\n Data-analysis or data-visualization tools (such as MATLAB, IDL, Panoply, GrADS, Integrated Data Viewer, Ferret and ncBrowseA Graphical netCDF File Browser) which their authors have adapted to enable DAP-based data input;\n Similarly adapted Web applications (such as Dapper Data Viewer, aka DChart)OPeNDAP software\n Similarly adapted end-user programs (in common languages)\n\nRegardless of their types, and whether developed commercially or by an end-user, clients almost universally link to DAP servers through libraries that implement the DAP2 or DAP4 protocol in one language or another. OPeNDAP offers open-source libraries in C++ and Java, but many clients rely on community developed libraries such as PyDAP or, especially, the NetCDF suite. Developed and maintained by the Unidata Program at the UCAR in multiple programming languages, all NetCDF libraries include embedded capabilities for retrieving (array-style) data from DAP servers.\n\nA data-using client references a data set by its URL and requests metadata or content by issuing (usually through an embedded DAP library) an HTTP request to a DAP server. Content requests usually are preceded by requests for metadata describing the structure and other details about the referenced data set. With this information, the client may construct DAP constraint expressionsDAP constraint expressions to retrieve specific content (i.e., subsets) from the source. OPeNDAP servers offer various types of responses, depending on the specific form of the client's request, including XML, JSON, HTML and ASCII. In response to requests for content, OPeNDAP servers can respond with multi-part mime documents that include a binary portion with NetCDF or DAP-native encoding. (These binary forms offer compact means to deliver large volumes of content, and the DAP-native form may even be streamed if desired.)\n\nOPeNDAP's software for building DAP servers (on top of Apache) is dubbed Hyrax and includes adapters that facilitate serving a wide variety of source data. DAP servers most frequently enable (remote) access to (large) HDF or NetCDF files, but the source data can exist in databases or other formats, including user-defined ones. When source data are organized as files, DAP retrievals enable, via subsetting, finer-grained access than does the FTP. Furthermore, OPeNDAP servers can aggregate subsets from multiple files for delivery in a single retrieval. Taken together, subsetting, aggregation and streaming can yield substantial data-access efficiencies, even in the presence of slow networks.\n\nOPeNDAP and other DAP servers are used operationally in government agencies, including NASA and NOAA, for providing access to Earth science data, including satellite imagery and other high-volume information sources. The DAP data model embraces a comprehensive set of data structures, including multidimensional arrays and nested sequences (i.e., records), complemented by a correspondingly rich set of constraint expressions. Hence the OPeNDAP data-retrieval architecture has demonstrated utility across a broad range of scientific data types, including data generated via simulations and data generated via observations (whether remotely sensed or measured in situ).", "title": "OPeNDAP", "category": "Data analysis"}
{"text": "Bernhard Sch\u00f6lkopf (born February 20, 1968) is a director at the Max Planck Institute for Intelligent Systems in T\u00fcbingen, Germany, where he heads the Department of Empirical Inference.\n\nHe is a leading researcher in the machine learning community, where he is particularly active in the field of kernel methods. He has made particular contributions to support vector machines and kernel PCA. A large part of his work is the development of novel machine learning algorithms through their formulation as (typically convex) optimisation problems.", "title": "Bernhard Sch\u00f6lkopf", "category": "Machine learning researchers"}
{"text": "Michael Irwin Jordan is an American scientist, professor at the University of California, Berkeley and researcher in machine learning, statistics, and artificial intelligence.David M. Blei, Andrew Y. Ng, Michael I. Jordan. Latent Dirichlet allocation. The Journal of Machine Learning Research, Volume 3, 3/1/2003Michael I. Jordan, ed. Learning in Graphical Models. Proceedings of the NATO Advanced Study Institute, Ettore Maiorana Centre, Erice, Italy, September 27-October 7, 1996 He is one of the leading figures in machine learning, and in 2016 Science reported him as the world's most influential computer scientist.", "title": "Michael I. Jordan", "category": "Machine learning researchers"}
{"text": "In machine learning, a common task is the study and construction of algorithms that can learn from and make predictions on data. Such algorithms work by making data-driven predictions or decisions,Machine learning and pattern recognition \"can be viewed as two facets of the same field.\" through building a mathematical model from input data.\n\nThe data used to build the final model usually comes from multiple datasets. In particular, three data sets are commonly used in different stages of the creation of the model.\n\nThe model is initially fit on a training dataset, that is a set of examples used to fit the parameters (e.g. weights of connections between neurons in artificial neural networks) of the model. The model (e.g. a neural net or a naive Bayes classifier) is trained on the training dataset using a supervised learning method (e.g. gradient descent or stochastic gradient descent). In practice, the training dataset often consist of pairs of an input vector (or scalar) and the corresponding output vector (or scalar), which is commonly denoted as the target (or label). The current model is run with the training dataset and produces a result, which is then compared with the target, for each input vector in the training dataset. Based on the result of the comparison and the specific learning algorithm being used, the parameters of the model are adjusted. The model fitting can include both variable selection and parameter estimation.\n\nSuccessively, the fitted model is used to predict the responses for the observations in a second dataset called the validation dataset. The validation dataset provides an unbiased evaluation of a model fit on the training dataset while tuning the model's hyperparameters  (e.g. the number of hidden units in a neural network). Validation datasets can be used for regularization by early stopping: stop training when the error on the validation dataset increases, as this is a sign of overfitting to the training dataset.\nThis simple procedure is complicated in practice by the fact that the validation dataset's error may fluctuate during training, producing multiple local minima. This complication has led to the creation of many ad-hoc rules for deciding when overfitting has truly begun.\n\nFinally, the test dataset is a dataset used to provide an unbiased evaluation of a final model fit on the training dataset. If the data in the test dataset has never been used in training (for example in cross-validation), the test dataset is also called a holdout dataset.", "title": "Training, validation, and test sets", "category": "Machine learning"}
{"text": "Prof. Selmer Bringsjord (born November 24, 1958) is the chair of the Department of Cognitive Science at Rensselaer Polytechnic Institute and a professor of Computer Science and Cognitive Science. He also holds an appointment in the Lally School of Management & Technology and teaches artificial Intelligence (AI), formal logic, human and machine reasoning, and philosophy of AI.\nBringsjord's education includes a B.A. in Philosophy from the University of Pennsylvania and a Ph.D. in Philosophy from Brown University. He conducts research in AI as the director of the Rensselaer AI & Reasoning Laboratory (RAIR). He specializes in the logico-mathematical and philosophical foundations of AI and cognitive science, and in collaboratively building AI systems on the basis of computational logic.\n\nBringsjord believes that \"the human mind will forever be superior to AI\", and that \"much of what many humans do for a living will be better done by indefatigable machines who require not a cent in pay\". Bringsjord has stated that the \"ultimate growth industry will be building smarter and smarter such machines on the one hand, and philosophizing about whether they are truly conscious and free on the other\".\n\nBringsjord has an argument for P = NP using digital physics. Other research includes developing a new computational-logic framework allowing the formalization of deliberative multi-agent \"mindreading\" as applied to the realm of nuclear strategy, with the goal of creating a model and simulation to enable reliable prediction. He has published an opinion piece advocating for counter-terrorism security ensured by pervasive, all-seeing sensors; automated reasoners; and autonomous, lethal robots.\n\nProf. Selmer Bringsjord received a National Science Foundation award to research Social Robotics and the Covey Award for the advancement of philosophy of computing awarded by the International Association for Computing And Philosophy, among several others prizes.", "title": "Selmer Bringsjord", "category": "Machine learning researchers"}
{"text": "In machine learning and statistics, classification is the problem of identifying to which of a set of categories (sub-populations) a new observation belongs, on the basis of a training set of data containing observations (or instances) whose category membership is known.  Examples are assigning a given email to the \"spam\" or \"non-spam\" class, and assigning a diagnosis to a given patient based on observed characteristics of the patient (sex, blood pressure, presence or absence of certain symptoms, etc.).  Classification is an example of pattern recognition.\n\nIn the terminology of machine learning, classification is considered an instance of supervised learning, i.e., learning where a training set of correctly identified observations is available.  The corresponding unsupervised procedure is known as clustering, and involves grouping data into categories based on some measure of inherent similarity or distance.\n\nOften, the individual observations are analyzed into a set of quantifiable properties, known variously as explanatory variables or features.  These properties may variously be categorical (e.g. \"A\", \"B\", \"AB\" or \"O\", for blood type), ordinal (e.g. \"large\", \"medium\" or \"small\"), integer-valued (e.g. the number of occurrences of a particular word in an email) or real-valued (e.g. a measurement of blood pressure). Other classifiers work by comparing observations to previous observations by means of a similarity or distance function.\n\nAn algorithm that implements classification, especially in a concrete implementation, is known as a classifier.  The term \"classifier\" sometimes also refers to the mathematical function, implemented by a classification algorithm, that maps input data to a category.\n\nTerminology across fields is quite varied. In statistics, where classification is often done with logistic regression or a similar procedure, the properties of observations are termed explanatory variables (or independent variables, regressors, etc.), and the categories to be predicted are known as outcomes, which are considered to be possible values of the dependent variable.  In machine learning, the observations are often known as instances, the explanatory variables are termed features (grouped into a feature vector), and the possible categories to be predicted are classes.  Other fields may use different terminology: e.g. in community ecology, the term \"classification\" normally refers to cluster analysis, i.e., a type of unsupervised learning, rather than the supervised learning described in this article.", "title": "Statistical classification", "category": "Machine learning"}
{"text": "The Natural Language Toolkit, or more commonly NLTK, is a suite of libraries and programs for symbolic and statistical natural language processing (NLP) for English written in the Python programming language. It was developed by Steven Bird and Edward Loper in the Department of Computer and Information Science at the University of Pennsylvania. NLTK includes graphical demonstrations and sample data. It is accompanied by a book that explains the underlying concepts behind the language processing tasks supported by the toolkit, plus a cookbook.\n\nNLTK is intended to support research and teaching in NLP or closely related areas, including empirical linguistics, cognitive science, artificial intelligence, information retrieval, and machine learning.\nNLTK has been used successfully as a teaching tool, as an individual study tool, and as a platform for prototyping and building research systems. There are 32 universities in the US and 25 countries using NLTK in their courses. NLTK supports classification, tokenization, stemming, tagging, parsing, and semantic reasoning functionalities.", "title": "Natural Language Toolkit", "category": "Data analysis software"}
{"text": "Teuvo Kalevi Kohonen (born July 11, 1934) is a prominent Finnish academic (Dr. Eng.) and researcher. He is currently professor emeritus of the Academy of Finland.\n\nProf. Kohonen has made many contributions to the field of artificial neural networks, including the Learning Vector Quantization algorithm, fundamental theories of distributed associative memory and optimal associative mappings, the learning subspace method and novel algorithms for symbol processing like redundant hash addressing. He has published several books and over 300 peer-reviewed papers.\nHis most famous contribution is the Self-Organizing Map (also known as the Kohonen map or  Kohonen artificial neural networks, although Kohonen himself prefers SOM). Due to the popularity of the SOM algorithm in many research and in practical applications, Kohonen is often considered to be the most cited Finnish scientist. The current version of the SOM bibliography contains close to 8000 entries.\n\nMost of his career, Prof. Kohonen conducted research at Helsinki University of Technology (TKK). The Neural Networks Research Centre of TKK, a center of excellence appointed by Academy of Finland was founded to conduct research related to Teuvo Kohonen's innovations. After Kohonen's retirement, the center has been led by Prof. Erkki Oja and later renamed to Adaptive Informatics Research Centre with widened foci of research.\n\nTeuvo Kohonen was elected the First Vice President of the International Association for Pattern Recognition from 1982 to 1984, and acted as the first president of the European Neural Network Society from 1991 to 1992.\n\nFor his scientific achievements, Prof. Kohonen has received a number of prizes including the following:\n\n IEEE Neural Networks Council Pioneer Award, 1991\n Technical Achievement Award of the IEEE Signal Processing Society, 1995\n IEEE Frank Rosenblatt Award, 2008", "title": "Teuvo Kohonen", "category": "Machine learning researchers"}
{"text": "Data Stream Mining is the process of extracting knowledge structures from continuous, rapid data records. A data stream is an ordered sequence of instances that in many applications of data stream mining can be read only once or a small number of times using limited computing and storage capabilities.\nIn many data stream mining applications, the goal is to predict the class or value of new instances in the data stream given some knowledge about the class membership or values of previous instances in the data stream.\nMachine learning techniques can be used to learn this prediction task from labeled examples in an automated fashion.\nOften, concepts from the field of incremental learning are applied to cope with structural changes, on-line learning and real-time demands. \nIn many applications, especially operating within non-stationary environments, the distribution underlying the instances or the rules underlying their labeling may change over time, i.e. the goal of the prediction, the class to be predicted or the target value to be predicted, may change over time. This problem is referred to as concept drift.\n\nExamples of data streams include computer network traffic, phone conversations, ATM transactions, web searches, and sensor data.\nData stream mining can be considered a subfield of data mining, machine learning, and knowledge discovery.", "title": "Data stream mining", "category": "Data mining"}
{"text": "In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression. In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression:\n\n In k-NN classification, the output is a class membership. An object is classified by a plurality vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small). If k\u00a0=\u00a01, then the object is simply assigned to the class of that single nearest neighbor.\n\n In k-NN regression, the output is the property value for the object. This value is the average of the values of k nearest neighbors.\n\nk-NN is a type of instance-based learning, or lazy learning, where the function is only approximated locally and all computation is deferred until classification. The k-NN algorithm is among the simplest of all machine learning algorithms.\n\nBoth for classification and regression, a useful technique can be used to assign weight to the contributions of the neighbors, so that the nearer neighbors contribute more to the average than the more distant ones. For example, a common weighting scheme consists in giving each neighbor a weight of 1/d, where d is the distance to the neighbor.This scheme is a generalization of linear interpolation.\n\nThe neighbors are taken from a set of objects for which the class (for k-NN classification) or the object property value (for k-NN regression) is known. This can be thought of as the training set for the algorithm, though no explicit training step is required.\n\nA peculiarity of the k-NN algorithm is that it is sensitive to the local structure of the data.", "title": "K-nearest neighbors algorithm", "category": "Machine learning algorithms"}
{"text": "The Linde\u2013Buzo\u2013Gray algorithm (introduced by Yoseph Linde, Andr\u00e9s Buzo and Robert M. Gray in 1980) is a vector quantization algorithm to derive a good codebook.\n\nIt is similar to the k-means method in data clustering.", "title": "Linde\u2013Buzo\u2013Gray algorithm", "category": "Machine learning algorithms"}
{"text": "JMP (pronounced \"jump\") is a suite of computer programs for statistical analysis developed by the JMP business unit of SAS Institute. It was launched in 1989 to take advantage of the graphical user interface introduced by the Macintosh. It has since been significantly rewritten and made available for the Windows operating system. JMP is used in applications such as Six Sigma, quality control, and engineering, design of experiments, as well as for research in science, engineering, and social sciences.\n\nThe software can be purchased in any of five configurations: JMP, JMP Pro, JMP Clinical, JMP Genomics and the JMP Graph Builder App for the iPad. JMP can be automated with its proprietary scripting language, JSL. The software is focused on exploratory visual analytics, where users investigate and explore data. These explorations can also be verified by hypothesis testing, data mining, or other analytic methods. In addition, discoveries made through graphical exploration can lead to a designed experiment that can be both designed and analyzed with JMP.", "title": "JMP (statistical software)", "category": "Data analysis software"}
{"text": "In statistics, kernel density estimation (KDE) is a non-parametric way to estimate the probability density function of a random variable.  Kernel density estimation is a fundamental data smoothing problem where inferences about the population are made, based on a finite data sample. In some fields such as signal processing and econometrics it is also termed the Parzen\u2013Rosenblatt window method,  after Emanuel Parzen and Murray Rosenblatt, who are usually credited with independently creating it in its current form.", "title": "Kernel density estimation", "category": "Machine learning"}
{"text": "Predictive learning is a technique of machine learning in which an agent tries to build a model of its environment by trying out different actions in various circumstances. It uses knowledge of the effects its actions appear to have, turning them into planning operators. These allow the agent to act purposefully in its world. Predictive learning is one attempt to learn with a minimum of pre-existing mental structure. It may have been inspired by Piaget's account of how children construct knowledge of the world by interacting with it. Gary Drescher's book 'Made-up Minds' was seminal for the area.\n\nAnother more recent predictive learning theory is Jeff Hawkins' memory-prediction framework, which is laid out in his On Intelligence.\n\nCategory:Machine learning", "title": "Predictive learning", "category": "Machine learning"}
{"text": "The Facial Recognition Technology (FERET) database is a dataset used for facial recognition system evaluation as part of the Face Recognition Technology (FERET) program. It was first established in 1993 under a collaborative effort between Dr. Harry Wechsler at George Mason University and Dr. Jonathan Phillips at the Army Research Laboratory in Adelphi, Maryland. The FERET database serves as a standard database of facial images for researchers to use to develop various algorithms and report results. The use of a common database also allowed one to compare the effectiveness of different approaches in methodology and gauge their strengths and weaknesses.\nThe facial images for the database were collected between December 1993 and August 1996, accumulating a total of 14,126 images pertaining to 1199 individuals along with 365 duplicate sets of images that were taken on a different day. In 2003, the Defense Advanced Research Projects Agency (DARPA) released a high-resolution, 24-bit color version of these images. The dataset tested includes 2,413 still facial images, representing 856 individuals. The FERET database has been used by more than 460 research groups and is managed by the National Institute of Standards and Technology (NIST).P. J. Phillips, H. Moon, S. A. Rizvi, and P. J. Rauss (January 7, 1999). \"The FERET Evaluation Methodology for Face-recognition Algorithms\". NISTIR 6264 and IEEE Trans. Patern Analysis and Machine Intelligence, 22(10), Oct. 2000. ", "title": "FERET database", "category": "Machine learning task"}
{"text": "A pivot table is a table of statistics that summarizes  the data of a more extensive table (such as from a database, spreadsheet, or business intelligence program). This summary might include sums, averages, or other statistics, which the pivot table groups together in a meaningful way.\n\nPivot tables are a technique in data processing. They enable a person to arrange and rearrange (or \"pivot\") statistics in order to draw attention to useful information.\n\nAlthough pivot table is a generic term, Microsoft Corporation trademarked PivotTable in the United States in 1994.", "title": "Pivot table", "category": "Data analysis"}
{"text": "Orange is an open-source data visualization, machine learning and data mining toolkit. It features a visual programming front-end for explorative data analysis and interactive data visualization, and can also be used as a Python library.", "title": "Orange (software)", "category": "Data mining and machine learning software"}
{"text": "Microsoft SQL Server Analysis Services, SSAS,Tableau frequently refers to SSAS Cubes as MSAS Cubes is an online analytical processing (OLAP) and data mining tool in Microsoft SQL Server. SSAS is used as a tool by organizations to analyze and make sense of information possibly spread out across multiple databases, or in disparate tables or files. Microsoft has included a number of services in SQL Server related to business intelligence and data warehousing. These services include Integration Services, Reporting Services and Analysis Services. Analysis Services includes a group of OLAP and data mining capabilities and comes in two flavors - Multidimensional and Tabular.", "title": "Microsoft Analysis Services", "category": "Data analysis software"}
{"text": "Data analysis is a process of inspecting, cleansing, transforming, and modeling data with the goal of discovering useful information, informing conclusions, and supporting decision-making. Data analysis has multiple facets and approaches, encompassing diverse techniques under a variety of names, and is used in different business, science, and social science domains. In today's business world, data analysis plays a role in making decisions more scientific and helping businesses operate more effectively.Xia, B. S., & Gong, P. (2015). Review of business intelligence through data analysis. Benchmarking, 21(2), 300-311. doi:10.1108/BIJ-08-2012-0050\n\nData mining is a particular data analysis technique that focuses on modeling and knowledge discovery for predictive rather than purely descriptive purposes, while business intelligence covers data analysis that relies heavily on aggregation, focusing mainly on business information.Exploring Data Analysis In statistical applications, data analysis can be divided into descriptive statistics, exploratory data analysis (EDA), and confirmatory data analysis (CDA). EDA focuses on discovering new features in the data while CDA focuses on confirming or falsifying existing hypotheses. Predictive analytics focuses on application of statistical models for predictive forecasting or classification, while text analytics applies statistical, linguistic, and structural techniques to extract and classify information from textual sources, a species of unstructured data. All of the above are varieties of data analysis.\n\nData integration is a precursor to data analysis, and data analysis is closely linked to data visualization and data dissemination. The term data analysis is sometimes used as a synonym for data modeling.", "title": "Data analysis", "category": "Data analysis"}
{"text": "Biomedical text mining (including biomedical natural language processing or BioNLP) refers to the methods and study of how text mining may be applied to texts and literature of the biomedical and molecular biology domains. As a field of research, biomedical text mining incorporates ideas from natural language processing, bioinformatics, medical informatics and computational linguistics. The strategies developed through studies in this field are frequently applied to the biomedical and molecular biology literature available through services such as PubMed.", "title": "Biomedical text mining", "category": "Data mining"}
{"text": "In predictive analytics and machine learning, the concept drift means that the statistical properties of the target variable, which the model is trying to predict, change over time in unforeseen ways. This causes problems because the predictions become less accurate as time passes.\nThe term concept refers to the quantity to be predicted. More generally, it can also refer to other phenomena of interest besides the target concept, such as an input, but, in the context of concept drift, the term commonly refers to the target variable.", "title": "Concept drift", "category": "Data mining"}
{"text": "In computational learning theory in mathematics, given a class of concepts C, a subclass D is reachable if there exists a partial approximation S of some concept such that D contains exactly those concepts in C that are extensions to S (i.e., D=C|S).\n\nCategory:Machine learning", "title": "Subclass reachability", "category": "Machine learning"}
{"text": "Demis Hassabis  (born 27 July 1976) is a British artificial intelligence researcher, neuroscientist, video game designer, entrepreneur, and world-class games player.", "title": "Demis Hassabis", "category": "Machine learning researchers"}
{"text": "Multifactor dimensionality reduction (MDR) is a statistical approach, also used in machine learning automatic approaches, for detecting and characterizing combinations of attributes or independent variables that interact to influence a dependent or class variable. MDR was designed specifically to identify nonadditive interactions among discrete variables that influence a binary outcome and is considered a nonparametric and model-free alternative to traditional statistical methods such as logistic regression.\nThe basis of the MDR method is a constructive induction or feature engineering algorithm that converts two or more variables or attributes to a single attribute.  This process of constructing a new attribute changes the representation space of the data.  The end goal is to create or discover a representation that facilitates the detection of nonlinear or nonadditive interactions among the attributes such that prediction of the class variable is improved over that of the original representation of the data.", "title": "Multifactor dimensionality reduction", "category": "Data mining"}
{"text": "A learning automaton is one type of machine learning algorithm studied since 1970s. Learning automata select their current action based on past experiences from the environment. It will fall into the range of reinforcement learning if the environment is stochastic and a Markov decision process (MDP) is used.", "title": "Learning automaton", "category": "Machine learning"}
{"text": "Robot learning is a research field at the intersection of machine learning and robotics. It studies techniques allowing a robot to acquire novel skills or adapt to its environment through learning algorithms. The embodiment of the robot, situated in a physical embedding, provides at the same time specific difficulties (e.g. high-dimensionality, real time constraints for collecting data and learning) and opportunities for guiding the learning process (e.g. sensorimotor synergies, motor primitives).\nExample of skills that are targeted by learning algorithms include sensorimotor skills such as locomotion, grasping, active object categorization,  as well as interactive skills such as joint manipulation of an object with a human peer, and linguistic skills such as the grounded and situated meaning of human language. Learning can happen either through autonomous self-exploration or through guidance from a human teacher, like for example in robot learning by imitation.\n\nRobot learning can be closely related to adaptive control, reinforcement learning as well as developmental robotics which considers the problem of autonomous lifelong acquisition of repertoires of skills.\nWhile machine learning is frequently used by computer vision algorithms employed in the context of robotics, these applications are usually not referred to as \"robot learning\".\n\n", "title": "Robot learning", "category": "Machine learning"}
{"text": "Vasant G. Honavar is an Indian born American computer scientist, and artificial intelligence, machine learning, big data, data science, causality, knowledge representation, bioinformatics and health informatics researcher and educator.", "title": "Vasant Honavar", "category": "Machine learning researchers"}
{"text": "Sebastian Thrun (born May 14, 1967) is an innovator, entrepreneur educator,  and computer scientist from Germany. He is CEO of the Kitty Hawk Corporation, chairman and co-founder of Udacity. Before that, he was a Google VP and Fellow, a Professor of Computer Science at Stanford University, and before that at Carnegie Mellon University. At Google, he founded Google X and Google's self-driving car team. He is currently also an Adjunct Professor at Stanford University and at Georgia Tech.\n\nThrun led development of the robotic vehicle StanleyThrun, S. et al.,  which won the 2005 DARPA Grand Challenge, and which has since been placed on exhibit in the Smithsonian Institution's National Museum of American History. His team also developed a vehicle called Junior,Montemerlo, M. et al.,  which placed second at the DARPA Grand Challenge in 2007. Thrun led the development of the Google self-driving car.\n\nThrun is also known for his work on probabilistic algorithms for robotics with applications including robotic mapping.Robotic mapping: a survey by Sebastian Thrun in  In recognition of his contributions, and at the age of 39, he was elected into the National Academy of Engineering and also into the Academy of Sciences Leopoldina in 2007. The Guardian recognized him as one of 20 \"fighters for internet freedom\".", "title": "Sebastian Thrun", "category": "Machine learning researchers"}
{"text": "Waikato Environment for Knowledge Analysis (Weka) is a suite of machine learning software written in Java, developed at the University of Waikato, New Zealand. It is free software licensed under the GNU General Public License.", "title": "Weka (machine learning)", "category": "Data mining and machine learning software"}
{"text": "Fityk is a curve fitting and data analysis application, predominantly used to fit analytical,\nbell-shaped functions to experimental data. It is positioned to fill the gap between general plotting software and programs specific for one field, e.g. crystallography or XPS.\n\nOriginally, Fityk was developed to analyse powder diffraction data. It is also used in other fields that require peak analysis and peak-fitting, like chromatography or various kinds of spectroscopy.\n\nFityk is distributed under the terms of GNU General Public License, but since version 1.0.0, subscription is required for downloading binaries. It runs on Linux, macOS, Microsoft Windows, FreeBSD and other platforms. It operates either as a command line program or with a graphical user interface.\n\nIt is written in C++, using wxWidgets, and providing bindings for Python and other scripting languages.", "title": "Fityk", "category": "Data analysis software"}
{"text": "John Ross Quinlan is a computer science researcher in data mining and decision theory. He has contributed extensively to the development of decision tree algorithms, including inventing the canonical C4.5 and ID3 algorithms. He also contributed to early ILP literature with First Order Inductive Learner (FOIL). He is currently running the company RuleQuest Research which he founded in 1997.", "title": "Ross Quinlan", "category": "Machine learning researchers"}
{"text": "Marcus Hutter (born April 14, 1967) is a German computer scientist. He is a professor at the ANU College of Engineering and Computer Science of the Australian National University in Canberra, Australia. Hutter studied physics and computer science at the Technical University of Munich. In 2000 he joined J\u00fcrgen Schmidhuber's group at the Istituto Dalle Molle di Studi sull'Intelligenza Artificiale (Dalle Molle Institute for Artificial Intelligence Research) in Manno, Switzerland. With others, he developed a mathematical theory of artificial general intelligence. His book Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability was published by Springer in 2005.Marcus Hutter (2005). Universal Artificial Intelligence: Sequential Decisions Based on Algorithmic Probability. Berlin; Heidelberg; New York: Springer. .", "title": "Marcus Hutter", "category": "Machine learning researchers"}
{"text": "LabWindows/CVI (CVI is short for C for Virtual Instrumentation) is an ANSI C programming environment for test and measurement developed by National Instruments. The program was originally released as LabWindows for DOS in 1987, but was soon revisioned (and renamed) for the Microsoft Windows platform. The current version of LabWindows/CVI (commonly referred to as CVI) is 2019.\n\nLabWindows/CVI uses the same libraries and data-acquisition modules as the better known National Instrument product LabVIEW and is thus highly compatible with it.\n\nLabVIEW is targeted more at domain experts and scientists, and CVI more towards software engineers that are more comfortable with text-based linear languages such as C.", "title": "LabWindows/CVI", "category": "Data analysis software"}
{"text": "Euler (now Euler Mathematical Toolbox or EuMathT) is a free and open-source numerical software package. It contains a matrix language, a graphical notebook style interface, and a plot window.  Euler is designed for higher level math such as calculus, optimization, and statistics.\n\nThe software can handle real, complex and interval numbers, vectors and matrices, it can produce 2D/3D plots, and uses Maxima for symbolic operations.\nThe software is compilable with Windows. The Unix and Linux versions do not contain a computer algebra subsystem.", "title": "Euler (software)", "category": "Data analysis software"}
{"text": "When the data vectors are high-dimensional it is computationally infeasible to use data analysis or pattern recognition algorithms which repeatedly compute similarities or distances in the original data space. It is therefore necessary to reduce the dimensionality before, for example, clustering the data.\nRandom Mapping (RM) is a fast dimensionality reduction method  categorized as feature extraction method. The RM consists in generation of a random matrix that is multiplied by each original vector and result in a reduced vector.\nIn Text mining context, it is demonstrated that the document classification accuracy obtained after the dimensionality has been reduced using a random mapping method will be almost as good as the original accuracy if the final dimensionality is sufficiently large (about 100 out of 6000). In fact, it can be shown that the inner product (similarity) between the mapped vectors follows closely the inner product of the original vectors.", "title": "Random mapping", "category": "Data analysis"}
{"text": "In a scientific study, post hoc analysis (from Latin post hoc, \"after this\") consists of statistical analyses that were not specified before the data was seen. This typically creates a multiple testing problem because each potential analysis is effectively a statistical test. Multiple testing procedures are sometimes used to compensate, but that is often difficult or impossible to do precisely. Post hoc analysis that is conducted and interpreted without adequate consideration of this problem is sometimes called data dredging by critics because the statistical associations that it finds are often spurious. ", "title": "Post hoc analysis", "category": "Data analysis"}
{"text": "Galvanize (formerly known as ACL Services Ltd.) is a privately-owned software as a service (SaaS) company founded and headquartered in Vancouver, British Columbia, Canada. The Company builds security, risk management, compliance and audit software for the governance, risk management, and compliance (GRC) market. \n\nGalvanize has offices in Vancouver (HQ), Singapore, London, Tokyo, and Secaucus, New Jersey. They also have a number of representatives and partners around the world, including throughout Africa, France, Malaysia, the Philippines, Indonesia, Hong Kong, China, Australia, and more.", "title": "Galvanize (software company)", "category": "Data analysis software"}
{"text": "Leo Breiman (January 27, 1928 \u2013 July 5, 2005) was a distinguished statistician at the University of California, Berkeley. He was the recipient of numerous honors and awards, and was a member of the United States National Academy of Science.\n\nBreiman's work helped to bridge the gap between statistics and computer science, particularly in the field of machine learning. His most important contributions were his work on classification and regression trees and ensembles of trees fit to bootstrap samples. Bootstrap aggregation was given the name bagging by Breiman. Another of Breiman's ensemble approaches is the random forest.", "title": "Leo Breiman", "category": "Machine learning researchers"}
{"text": "Sequential pattern mining is a topic of data mining concerned with finding statistically relevant patterns between data examples where the values are delivered in a sequence. It is usually presumed that the values are discrete, and thus time series mining is closely related, but usually considered a different activity.  Sequential pattern mining is a special case of structured data mining.\n\nThere are several key traditional computational problems addressed within this field.  These include building efficient databases and indexes for sequence information, extracting the frequently occurring patterns, comparing sequences for similarity, and recovering missing sequence members.  In general, sequence mining problems can be classified as string mining which is typically based on string processing algorithms  and itemset mining which is typically based on association rule learning. Local process models  extend sequential pattern mining to more complex patterns that can include (exclusive) choices, loops, and concurrency constructs in addition to the sequential ordering construct. ", "title": "Sequential pattern mining", "category": "Data mining"}
{"text": "An inauthentic text is a computer-generated expository document meant to appear as genuine, but which is actually meaningless.  Frequently they are created in order to be intermixed with genuine documents and thus manipulate the results of search engines, as with Spam blogs.  They are also carried along in email in order to fool spam filters by giving the spam the superficial characteristics of legitimate text.\n\nSometimes nonsensical documents are created with computer assistance for humorous effect, as with Dissociated press or Flarf poetry.  They have also been used to challenge the veracity of a publication\u2014MIT students submitted papers generated by a computer program called SCIgen to a conference, where they were initially accepted.  This led the students to claim that the bar for submissions was too low.\n\nWith the amount of computer generated text outpacing the ability of people to humans to curate it, there needs some means of distinguishing between the two.  Yet automated approaches to determining absolutely whether a text is authentic or not face intrinsic challenges of semantics.  Noam Chomsky coined the phrase \"Colorless green ideas sleep furiously\" giving an example of grammatically-correct, but semantically incoherent sentence; some will point out that in certain contexts one could give this sentence (or any phrase) meaning.\n\nThe first group to use the expression in this regard can be found below from Indiana University.  Their work explains in detail an attempt to detect inauthentic texts and identify pernicious problems of inauthentic texts in cyberspace.  The site has a means of submitting text that assesses, based on supervised learning, whether a corpus is inauthentic or not.  Many users have submitted incorrect types of data and have correspondingly commented on the scores. This application is meant for a specific kind of data; therefore, submitting, say, an email, will not return a meaningful score.", "title": "Inauthentic text", "category": "Machine learning"}
{"text": "The Ugly Duckling theorem is an argument showing that classification is not really possible without some sort of bias. More particularly, it assumes finitely many properties combinable by logical connectives, and finitely many objects; it asserts that any two different objects share the same number of (extensional) properties. The theorem is named after Hans Christian Andersen's story \"The Ugly Duckling\", because it shows that a duckling is just as similar to a swan as two duckling are to each other. It was proposed by Satosi Watanabe in 1969.", "title": "Ugly duckling theorem", "category": "Machine learning"}
{"text": "RapidMiner is a data science software platform developed by the company of the same name that provides an integrated environment for data preparation, machine learning, deep learning, text mining, and predictive analytics. It is used for business and commercial applications as well as for research, education, training, rapid prototyping, and application development and supports all steps of the machine learning process including data preparation, results visualization, model validation and optimization.Markus Hofmann, Ralf Klinkenberg, \u201cRapidMiner: Data Mining Use Cases and Business Analytics Applications (Chapman & Hall/CRC Data Mining and Knowledge Discovery Series),\u201d CRC Press, October 25, 2013. RapidMiner is developed on an open core model. The RapidMiner Studio Free Edition, which is limited to 1 logical processor and 10,000 data rows is available under the AGPL license.\u201cRapidMiner, September 1, 2015. Commercial pricing starts at $5,000 and is available from the developer.", "title": "RapidMiner", "category": "Data mining and machine learning software"}
{"text": "HippoDraw is a powerful object-oriented statistical data analysis package written in C++, with user interaction via a Qt-based GUI and a Python-scriptable interface. It is being developed by Paul Kunz at SLAC, primarily for the analysis and presentation of particle physics and astrophysics data, but can be equally well used in other fields where data handling is important.\n\nHippoDraw can read and write files in an XML-based format, astrophysics FITS files, data objects produced by ROOT (optional), and through the Python bindings, anything that can be read/written by Python (HDF5, for instance, with PyTables).\n\nHippoDraw can be used as a Python extension module, allowing users to use HippoDraw data objects with the full power of the Python language. This includes other scientific Python extension modules such Numeric and numarray, whose use with HippoDraw can lead to a large increase in processing speed, even for ROOT objects.", "title": "HippoDraw", "category": "Data analysis software"}
{"text": "MALLET is a Java \"Machine Learning for Language Toolkit\".", "title": "Mallet (software project)", "category": "Data mining and machine learning software"}
{"text": "Java Analysis Studio (JAS) is an object oriented  data analysis package developed for the analysis of particle physics data. The latest major version is JAS3.\n\nJAS3 is particularly notable for being a fully AIDA-compliant data analysis system. It is popular for data analysis in areas of particle physics which are familiar with the Java programming language.\n\nThe Studio uses many other libraries from the FreeHEP project.", "title": "Java Analysis Studio", "category": "Data analysis software"}
{"text": "The Journal of Machine Learning Research is a peer-reviewed open access scientific journal covering machine learning. It was established in 2000 and the first editor-in-chief was Leslie Kaelbling. The current editors-in-chief are Francis Bach (Inria), David Blei (Columbia University) and Bernhard Sch\u00f6lkopf (Max Planck Institute for Intelligent Systems).", "title": "Journal of Machine Learning Research", "category": "Machine learning"}
{"text": "Machine Learning  is a peer-reviewed scientific journal, published since 1986.\nIt should be distinguished from the journal Machine intelligence which was established in the mid-1960s.E.g.: vs.:  \n\nIn 2001, forty editors and members of the editorial board of Machine Learning resigned in order to support the Journal of Machine Learning Research (JMLR), saying that in the era of the internet, it was detrimental for researchers to continue publishing their papers in expensive journals with pay-access archives. Instead, they wrote, they supported the model of JMLR, in which authors retained copyright over their papers and archives were freely available on the internet.\n\nFollowing the mass resignation, Kluwer changed their publishing policy to allow authors to self-archive their papers online after peer-review.", "title": "Machine Learning (journal)", "category": "Machine learning"}
{"text": "Ernst Dieter Dickmanns is a German pioneer of dynamic computer vision and of driverless cars. Dickmanns has been a professor at Bundeswehr University Munich (1975\u20132001), and visiting professor to Caltech and to MIT, teaching courses on \"dynamic vision\".", "title": "Ernst Dickmanns", "category": "Machine learning researchers"}
{"text": "Deep Web Technologies  is a software company that specializes in mining the Deep Web \u2014 the part of the Internet  that is not directly searchable through ordinary web search engines. The company produces a proprietary software platform  \"Explorit\"  for such searches. It also produces the federated search engine ScienceResearch.com, which provides free federated public searching of a large number of databases, and is also produced in specialized versions,  Biznar for business research, Mednar  for medical research, and customized versions for individual clients.", "title": "Deep Web Technologies", "category": "Data mining and machine learning software"}
{"text": "In the field of multivariate statistics, kernel principal component analysis (kernel PCA) \nis an extension of principal component analysis (PCA) using techniques of kernel methods. Using a kernel, the originally linear operations of PCA are performed in a reproducing kernel Hilbert space.", "title": "Kernel principal component analysis", "category": "Machine learning algorithms"}
{"text": "Origin is a proprietary computer program for interactive scientific graphing and data analysis. It is produced by OriginLab Corporation, and runs on Microsoft Windows. It has inspired several platform-independent open-source clones like SciDAVis.\n\nGraphing support in Origin includes various 2D/3D plot types.\n\nData analyses in Origin include statistics, signal processing, curve fitting and peak analysis. Origin's curve fitting is performed by a nonlinear least squares fitter which is based on the Levenberg\u2013Marquardt algorithm.\n\nOrigin imports data files in various formats such as ASCII text, Excel, NI TDM, DIADem, NetCDF, SPC, etc. It also exports the graph to various image file formats such as JPEG, GIF, EPS, TIFF, etc. There is also a built-in query tool for accessing database data via ADO.", "title": "Origin (data analysis software)", "category": "Data analysis software"}
{"text": "Brian David Ripley FRSE (born  29 April 1952) is a British statistician. From 1990, he was professor of applied statistics at the University of Oxford and is also a professorial fellow at St Peter's College. He retired August 2014 due to ill health.Professor Ripley's Homepage at Oxford University. Accessed 2015-05-10.", "title": "Brian D. Ripley", "category": "Machine learning researchers"}
{"text": "Pattern recognition is a very active field of research intimately bound to machine learning. Also known as classification or statistical classification, pattern recognition aims at building a classifier that can determine the class of an input pattern. This procedure, known as training, corresponds to learning an unknown decision function based only on a set of input-output pairs (\\boldsymbol{x}_i,y_i) that form the training data (or training set). Nonetheless, in real world applications such as character recognition, a certain amount of information on the problem is usually known beforehand. The incorporation of this prior knowledge into the training is the key element that will allow an increase of performance in many applications.", "title": "Prior knowledge for pattern recognition", "category": "Machine learning"}
{"text": "GSP algorithm (Generalized Sequential Pattern algorithm) is an algorithm used for sequence mining. The algorithms for solving sequence mining problems are mostly based on the a priori (level-wise) algorithm. One way to use the level-wise paradigm is to first discover all the frequent items in a level-wise fashion. It simply means counting the occurrences of all singleton elements in the database. Then, the transactions are filtered by removing the non-frequent items. At the end of this step, each transaction consists of only the frequent elements it originally contained. This modified database becomes an input to the GSP algorithm. This process requires one pass over the whole database.\n\nGSP algorithm makes multiple database passes. In the first pass, all single items (1-sequences) are counted. From the frequent items, a set of candidate 2-sequences are formed, and another pass is made to identify their frequency. The frequent 2-sequences are used to generate the candidate 3-sequences, and this process is repeated until no more frequent sequences are found. There are two main steps in the algorithm.\n Candidate Generation. Given the set of frequent (k-1)-frequent sequences Fk-1, the candidates for the next pass are generated by joining F(k-1) with itself. A pruning phase eliminates any sequence, at least one of whose subsequences is not frequent.\n Support Counting. Normally, a hash tree\u2013based search is employed for efficient support counting. Finally non-maximal frequent sequences are removed.", "title": "GSP algorithm", "category": "Data mining algorithms"}
{"text": "Zoubin Ghahramani FRS (; born 8 February 1970) is a British-Iranian researcher and Professor of Information Engineering at the University of Cambridge. He holds joint appointments at University College London and the Alan Turing Institute. and has been a Fellow of St John's College, Cambridge since 2009.  He was Associate Research Professor at Carnegie Mellon University School of Computer Science from 2003-2012. He is also the Chief Scientist of Uber and Deputy Director of the Leverhulme Centre for the Future of Intelligence.", "title": "Zoubin Ghahramani", "category": "Machine learning researchers"}
{"text": "Leabra stands for local, error-driven and associative, biologically realistic algorithm. It is a model of learning which is a balance between Hebbian and error-driven learning with other network-derived characteristics.  This model is used to mathematically predict outcomes based on inputs and previous learning influences. This model is heavily influenced by and contributes to neural network designs and models. This algorithm is the default algorithm in emergent (successor of PDP++) when making a new project, and is extensively used in various simulations.\nHebbian learning is performed using conditional principal components analysis (CPCA) algorithm with correction factor for sparse expected activity levels.\n\nError-driven learning is performed using GeneRec, which is a generalization of the recirculation algorithm, and approximates Almeida\u2013Pineda recurrent backpropagation. The symmetric, midpoint version of GeneRec is used, which is equivalent to the contrastive Hebbian learning algorithm (CHL). See O'Reilly (1996; Neural Computation) for more details.\n\nThe activation function is a point-neuron approximation with both discrete spiking and continuous rate-code output.\n\nLayer or unit-group level inhibition can be computed directly using a k-winners-take-all (KWTA) function, producing sparse distributed representations.\n\nThe net input is computed as an average, not a sum, over connections, based on normalized, sigmoidally transformed weight values, which are subject to scaling on a connection-group level to alter relative contributions.  Automatic scaling is performed to compensate for differences in expected activity level in the different projections.\n\nDocumentation about this algorithm can be found in the book \"Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain\" published by MIT press. and in the Emergent Documentation", "title": "Leabra", "category": "Machine learning algorithms"}
{"text": "Grace Wahba (born August 3, 1934) is a now-retired I. J. Schoenberg-Hilldale Professor of Statistics at the University of Wisconsin\u2013Madison. She is a pioneer in methods for smoothing noisy data. Best known for the development of generalized cross-validation and \"Wahba's problem\", she has developed methods with applications in demographic studies, machine learning, DNA microarrays, risk modeling, medical imaging, and climate prediction.\n\nShe was educated at Cornell (B.A. 1956), University of Maryland, College Park (M.A. 1962) and Stanford (Ph.D. 1966), and worked in industry for several years before receiving her doctorate in 1966 and settling in Madison in 1967. She is the author of Spline Models for Observational Data. She was elected to the United States National Academy of Sciences in 2000 and received an honorary degree of Doctor of Science from the University of Chicago in 2007.", "title": "Grace Wahba", "category": "Machine learning researchers"}
{"text": "Nearest neighbor search (NNS), as a form of proximity search,  is the optimization problem of finding the point in a given set that is closest (or most similar) to a given point. Closeness is typically expressed in terms of a dissimilarity function: the less similar the objects, the larger the function values. Formally, the nearest-neighbor (NN) search problem is defined as follows: given a set S of points in a space M and a query point q\u00a0\u2208\u00a0M, find the closest point in S to q. Donald Knuth in vol. 3 of The Art of Computer Programming (1973) called it the post-office problem, referring to an application of assigning to a residence the nearest post office. A direct generalization of this problem is a k-NN search, where we need to find the k closest points.\nMost commonly M is a  metric space and dissimilarity is expressed as a distance metric, which is symmetric and satisfies the triangle inequality. Even more common, M is taken to be the d-dimensional vector space where dissimilarity is measured using the Euclidean distance, Manhattan distance or other distance metric. However, the dissimilarity function can be arbitrary. One example is asymmetric Bregman divergence, for which the triangle inequality does not hold.", "title": "Nearest neighbor search", "category": "Machine learning"}
{"text": "Jacek M. Zurada serves as a Professor of Electrical and Computer Engineering Department at the University of Louisville, Kentucky. He has held visiting appointments at Princeton, Northeastern, Auburn, and at overseas universities in Australia, Chile, China, France, Germany, Hong Kong, Italy, Japan, Poland, Singapore, Spain, and South Africa. He is a Life Fellow of IEEE.", "title": "Jacek M. Zurada", "category": "Machine learning researchers"}
{"text": "Rule induction is an area of machine learning in which formal rules are extracted from a set of observations.  The rules extracted may represent a full scientific model of the data, or merely represent local patterns in the data.", "title": "Rule induction", "category": "Machine learning"}
{"text": "Information Harvesting (IH) was an early data mining product from the 1990s.  It was invented by Ralphe Wiggins and produced by the Ryan Corp, later Information Harvesting Inc., of Cambridge, Massachusetts.  IH sought to infer rules from sets of data.  It did this first by classifying various input variables into one of a number of bins, thereby putting some structure on the continuous variables in the input.  IH then proceeds to generate rules, trading off generalization against memorization, that will infer the value of the prediction variable, possibly creating many levels of rules in the process.  It included strategies for checking if overfitting took place and, if so, correcting for it.  Because of its strategies for correcting for overfitting by considering more data, and refining the rules based on that data, IH might also be considered to be a form of machine learning.\n\nThe advantage of IH, as compared with other data mining products of its time and even later, was that it provided a mechanism for finding multiple rules that would classify the data and determining, according to set criteria, the best rules to use.", "title": "Information Harvesting", "category": "Data mining and machine learning software"}
{"text": "Stephen H. Muggleton FBCS, FIET, FAAAI,FECCAI, FSB, FREnghttp://www.raeng.org.uk/research/researcher/chairs/currentapp.htm Research Chairs: Current and Recently Completed at the Royal Academy of Engineering (born 6 December 1959, son of Louis Muggleton) is Professor of Machine Learning and Head of the Computational Bioinformatics Laboratory at Imperial College London.Grants awarded to Stephen Muggleton by the Engineering and Physical Sciences Research Council", "title": "Stephen Muggleton", "category": "Machine learning researchers"}
{"text": "In data mining, anomaly detection (also outlier detection) is the identification of rare items, events or observations which raise suspicions by differing significantly from the majority of the data. Typically the anomalous items will translate to some kind of problem such as bank fraud, a structural defect, medical problems or errors in a text. Anomalies are also referred to as outliers, novelties, noise, deviations and exceptions.\n\nIn particular, in the context of abuse and network intrusion detection, the interesting objects are often not rare objects, but unexpected bursts in activity. This pattern does not adhere to the common statistical definition of an outlier as a rare object, and many outlier detection methods (in particular unsupervised methods) will fail on such data, unless it has been aggregated appropriately. Instead, a cluster analysis algorithm may be able to detect the micro clusters formed by these patterns.\n\nThree broad categories of anomaly detection techniques exist. Unsupervised anomaly detection techniques detect anomalies in an unlabeled test data set under the assumption that the majority of the instances in the data set are normal by looking for instances that seem to fit least to the remainder of the data set. Supervised anomaly detection techniques require a data set that has been labeled as \"normal\" and \"abnormal\" and involves training a classifier (the key difference to many other statistical classification problems is the inherent unbalanced nature of outlier detection). Semi-supervised anomaly detection techniques construct a model representing normal behavior from a given normal training data set, and then test the likelihood of a test instance to be generated by the learnt model.", "title": "Anomaly detection", "category": "Machine learning"}
{"text": "Minimum redundancy feature selection is an algorithm frequently used in a method to accurately identify characteristics of genes and phenotypes and narrow down their relevance and is usually described in its pairing with relevant feature selection as Minimum Redundancy Maximum Relevance (mRMR).\nFeature selection, one of the basic problems in pattern recognition and machine learning, identifies subsets of data that are relevant to the parameters used and is normally called Maximum Relevance. These subsets often contain material which is relevant but redundant and mRMR attempts to address this problem by removing those redundant subsets. mRMR has a variety of applications in many areas such as cancer diagnosis and speech recognition.\n\nFeatures can be selected in many different ways. One scheme is to select features that correlate strongest to the classification variable. This has been called maximum-relevance selection. Many heuristic algorithms can be used, such as the sequential forward, backward, or floating selections.\n\nOn the other hand features can be selected to be mutually far away from each other while still having \"high\" correlation to the classification variable. This scheme, termed as Minimum Redundancy Maximum Relevance (mRMR) selection has been found to be more powerful than the maximum relevance selection.\n\nAs a special case, the \"correlation\" can be replaced by the statistical dependency between variables. Mutual information can be used to quantify the dependency. In this case, it is shown that mRMR is an approximation to maximizing the dependency between the joint distribution of the selected features and the classification variable.\n\nStudies have tried different measures for redundancy and relevance measures. A recent study compared several measures within the context of biomedical images.Auffarth, B., Lopez, M., Cerquides, J. (2010). Comparison of redundancy and relevance measures for feature selection in tissue classification of CT images. Advances in Data Mining. Applications and Theoretical Aspects. p. 248--262. Springer. http://www.csc.kth.se/~auffarth/publications/redrel.pdf", "title": "Minimum redundancy feature selection", "category": "Machine learning algorithms"}
{"text": "In game theory, Bayesian regret is the average difference between the utility of a strategy and an ideal utility where desired outcomes are maximized. \nThe term Bayesian refers to Thomas Bayes (1702\u20131761), who proved a special case of what is now called Bayes' theorem, who provided the first mathematical treatment of a non-trivial problem of statistical data analysis using what is now known as Bayesian inference.", "title": "Bayesian regret", "category": "Machine learning"}
{"text": "In computer science, programming by example (PbE), also termed programming by demonstration or more generally as demonstrational programming, is an end-user development technique for teaching a computer new behavior by demonstrating actions on concrete examples.A Machine Learning Framework for Programming by Example - Microsoft The system records user actions and infers a generalized program that can be used on new examples.\nPbE is intended to be easier to do than traditional computer programming, which generally requires learning and using a programming language.  Many PbE systems have been developed as research prototypes, but few have found widespread real-world application.  More recently, PbE has proved to be a useful paradigm for creating scientific work-flows. PbE is used in two independent clients for the BioMOBY protocol: Seahawk and Gbrowse moby. Also the programming by demonstration term has been mostly adopted by robotics researchers for teaching new behaviors to the robot through a physical demonstration of the task.", "title": "Programming by example", "category": "Machine learning"}
{"text": "The CN2 induction algorithm is a learning algorithm for rule induction.Clark, P. and Niblett, T (1989) The CN2 induction algorithm. Machine Learning 3(4):261-283. It is designed to work even when the training data is imperfect. It is based on ideas from the AQ algorithm and the ID3 algorithm. As a consequence it creates a rule set like that created by AQ but is able to handle noisy data like ID3.", "title": "CN2 algorithm", "category": "Machine learning algorithms"}
{"text": "Category utility is a measure of \"category goodness\" defined in  and . It attempts to maximize both the probability that two objects in the same category have attribute values in common, and the probability that objects from different categories have different attribute values. It was intended to supersede more limited measures of category goodness such as \"cue validity\" (; ) and \"collocation index\" . It provides a normative information-theoretic measure of the predictive advantage gained by the observer who possesses knowledge of the given category structure (i.e., the class labels of instances) over the observer who does not possess knowledge of the category structure. In this sense the motivation for the category utility measure is similar to the information gain metric used in decision tree learning. In certain presentations, it is also formally equivalent to the mutual information, as discussed below. A review of category utility in its probabilistic incarnation, with applications to machine learning, is provided in .", "title": "Category utility", "category": "Machine learning"}
{"text": "The forward\u2013backward algorithm is an  inference algorithm for hidden Markov models which computes the posterior marginals of all hidden state variables given a sequence of observations/emissions o_{1:T}:= o_1,\\dots,o_T, i.e. it computes, for all hidden state variables X_t \\in \\{X_1, \\dots, X_T\\}, the distribution P(X_t\\ |\\ o_{1:T}). This inference task is usually called smoothing. The algorithm makes use of the principle of dynamic programming to efficiently compute the values that are required to obtain the posterior marginal distributions in two passes. The first pass goes forward in time while the second goes backward in time; hence the name forward\u2013backward algorithm.\n\nThe term forward\u2013backward algorithm is also used to refer to any algorithm belonging to the general class of algorithms that operate on sequence models in a forward\u2013backward manner. In this sense, the descriptions in the remainder of this article refer but to one specific instance of this class.", "title": "Forward\u2013backward algorithm", "category": "Machine learning algorithms"}
{"text": "Shogun is a free, open-source machine learning software library  written in C++. It offers numerous algorithms and data structures for machine learning problems. It offers interfaces for Octave, Python, R, Java, Lua, Ruby and C# using SWIG.\n\nIt is licensed under the terms of the GNU General Public License version 3 or later.", "title": "Shogun (toolbox)", "category": "Data mining and machine learning software"}
{"text": "A committee machine is a type of artificial neural network using a divide and conquer strategy in which the responses of multiple neural networks (experts) are combined into a single response.HAYKIN, S. Neural Networks - A Comprehensive Foundation. Second edition. Pearson Prentice Hall: 1999.  The combined response of the committee machine is supposed to be superior to those of its constituent experts.  Compare with ensembles of classifiers.", "title": "Committee machine", "category": "Machine learning"}
{"text": "In the field of mathematical modeling, a radial basis function network is an artificial neural network that uses radial basis functions as activation functions. The output of the network is a linear combination of radial basis functions of the inputs and neuron parameters. Radial basis function networks have many uses, including function approximation, time series prediction, classification, and system control. They were first formulated in a 1988 paper by Broomhead and Lowe, both researchers at the Royal Signals and Radar Establishment.", "title": "Radial basis function network", "category": "Machine learning algorithms"}
{"text": "Probability matching is a decision strategy in which predictions of class membership are proportional to the class base rates.  Thus, if in the training set positive examples are observed 60% of the time, and negative examples are observed 40% of the time, then the observer using a probability-matching strategy will predict (for unlabeled examples) a class label of \"positive\" on 60% of instances, and a class label of \"negative\" on 40% of instances.  \n\nThe optimal Bayesian decision strategy (to maximize the number of correct predictions, see ) in such a case is to always predict \"positive\" (i.e., predict the majority category in the absence of other information), which has 60% chance of winning rather than matching which has 52% of winning  (where p is the probability of positive realization, the result of matching would be p^2+(1-p)^2, here .6 \\times .6+ .4 \\times .4).  The probability-matching strategy is of psychological interest because it is frequently employed by human subjects in decision and classification studies (where it may be related to Thompson sampling).\n\nThe only case when probability matching will yield same results as Bayesian decision strategy mentioned above is when all class base rates are the same. So, if in the training set positive examples are observed 50% of the time, then the Bayesian strategy would yield 50% accuracy (1 \u00d7 .5), just as probability matching (.5 \u00d7.5 + .5 \u00d7 .5). ", "title": "Probability matching", "category": "Machine learning"}
{"text": "Optimal matching is a sequence analysis method used in social science, to assess the dissimilarity of ordered arrays of tokens that usually represent a time-ordered sequence of socio-economic states two individuals have experienced. Once such distances have been calculated for a set of observations (e.g. individuals in a cohort) classical tools (such as cluster analysis) can be used. The method was tailored to social sciencesA. Abbott and A. Tsay, (2000) Sequence Analysis and Optimal Matching Methods in Sociology: Review and Prospect Sociological Methods & Research], Vol. 29, 3-33.  from a technique originally introduced to study molecular biology (protein or genetic) sequences (see sequence alignment). Optimal matching uses the Needleman-Wunsch algorithm.", "title": "Optimal matching", "category": "Data mining"}
{"text": "Stephen M. Omohundro (born 1959) is an American computer scientist whose areas of research include Hamiltonian physics, dynamical systems, programming languages, machine learning, machine vision, and the social implications of artificial intelligence. His current work uses rational economics to develop safe and beneficial intelligent technologies for better collaborative modeling, understanding, innovation, and decision making.", "title": "Steve Omohundro", "category": "Machine learning researchers"}
{"text": "Pieter Adriaan Flach (born 8 April 1961, Sneek) is a Dutch computer scientist and a Professor of Artificial Intelligence in the Department of Computer Science at the University of Bristol.", "title": "Peter Flach", "category": "Machine learning researchers"}
{"text": "Katia Sycara () is a professor in the Robotics Institute, School of Computer Science at Carnegie Mellon University internationally known for her research in artificial intelligence, particularly in the fields of negotiation, autonomous agents and multi-agent systems. She directs the Advanced Agent-Robotics Technology Lab at Robotics Institute, Carnegie Mellon University. She also serves as academic advisor for PhD students at both Robotics Institute and Tepper School of Business.\nBorn in Greece, she went to the United States to pursue advanced education through various scholarships, including a Fulbright (1965-1969). She received a B.S. in Applied Mathematics from Brown University, M.S. in Electrical Engineering from the University of Wisconsin\u2013Milwaukee, and Ph.D. in Computer Science from Georgia Institute of Technology. She was awarded an Honorary Doctorate from the University of the Aegean in 2004.", "title": "Katia Sycara", "category": "Machine learning researchers"}
{"text": "In artificial intelligence, eager learning is a learning method in which the system tries to construct a general, input-independent target function during training of the system, as opposed to lazy learning, where generalization beyond the training data is delayed until a query is made to the system. The main advantage gained in employing an eager learning method, such as an artificial neural network, is that the target function will be approximated globally during training, thus requiring much less space than using a lazy learning system. Eager learning systems also deal much better with noise in the training data. Eager learning is an example of offline learning, in which post-training queries to the system have no effect on the system itself, and thus the same query to the system will always produce the same result.\n\nThe main disadvantage with eager learning is that it is generally unable to provide good local approximations in the target function.", "title": "Eager learning", "category": "Machine learning"}
{"text": "In machine learning, systems which employ offline learning do not change their approximation of the target function when the initial training phase has been completed. These systems are also typically examples of eager learning.\n\nWhile in online learning, only the set of possible elements is known, in offline learning, the identity of the elements as well as the order in which they are presented is known to the learner.", "title": "Offline learning", "category": "Machine learning"}
{"text": "Michael J. Collins (born 4 March 1970) is a researcher in the field of computational linguistics.\n\nHis research interests are in natural language processing as well as machine learning and he has made important contributions in statistical parsing and in statistical machine learning. In his studies Collins covers a wide range of topics such as parse re-ranking, tree kernels, semi-supervised learning, machine translation and exponentiated gradient algorithms with a general focus on discriminative models and structured prediction. One notable contribution is a state-of-the-art parser for the Penn Wall Street Journal corpus. As of November 11, 2015, his works have been cited 16,020 times, and he has an h-index of 47.\n\nCollins worked as a researcher at AT&T Labs between January 1999 and November 2002, and later held the positions of assistant and associate professor at M.I.T. Since January 2011, he has been a professor at Columbia University.Collins, Michael. Collins's Columbia website. In 2011, he was named a fellow of the Association for Computational Linguistics.", "title": "Michael Collins (computational linguist)", "category": "Machine learning researchers"}
{"text": "General Architecture for Text Engineering or GATE is a Java suite of tools originally developed at the University of Sheffield beginning in 1995 and now used worldwide by a wide community of scientists, companies, teachers and students for many natural language processing tasks, including information extraction in many languages.Languages mentioned on http://gate.ac.uk/gate/plugins/ include Arabic, Bulgarian, Cebuano, Chinese, French, German, Hindi, Italian, Romanian and Russian.\n\nGATE has been compared to NLTK, R and RapidMiner. As well as being widely used in its own right, it forms the basis of the KIM semantic platform.\n\nGATE community and research has been involved in several European research projects including TAO, SEKT, NeOn, Media-Campaign, Musing, Service-Finder, LIRICS and KnowledgeWeb, as well as many other projects.\n\nAs of May 28, 2011, 881 people are on the gate-users mailing list at SourceForge.net, and 111,932 downloads from SourceForge are recorded since the project moved to SourceForge in 2005. The paper \"GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications\"\"GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications\", by Cunningham H., Maynard D., Bontcheva K. and Tablan V. (In proc. of the 40th Anniversary Meeting of the Association for Computational Linguistics, 2002) has received over 800 citations in the seven years since publication (according to Google Scholar). Books covering the use of GATE, in addition to the GATE User Guide, include \"Building Search Applications: Lucene, LingPipe, and Gate\", by Manu Konchady,Konchady, Manu. Building Search Applications: Lucene, LingPipe, and Gate. Mustru Publishing. 2008. and \"Introduction to Linguistic Annotation and Text Analytics\", by Graham Wilcock.", "title": "General Architecture for Text Engineering", "category": "Data mining and machine learning software"}
{"text": "In computer science, a predictive state representation (PSR) is a way to model a state of controlled dynamical system from a history of actions taken and resulting observations. PSR captures the state of a system as a vector of predictions for future tests (experiments) that can be done on the system. A test is a sequence of action-observation pairs and its prediction is the probability of the test's observation-sequence happening if the test's action-sequence were to be executed on the system. One of the advantage of using PSR is that the predictions are directly related to observable quantities.  This is in contrast to other models of dynamical systems, such as partially observable Markov decision processes (POMDPs) where the state of the system is represented as a probability distribution over unobserved nominal states.", "title": "Predictive state representation", "category": "Machine learning"}
{"text": "TIBCO Software Inc. is an American company that provides integration, analytics and event-processing software for companies to use on-premises or as part of cloud computing environments. The software manages information, decisions, processes and applications for over 10,000 customers.\"TIBCO Software Inc\". Bloomberg. March 20, 2012.\n\nIt has headquarters in Palo Alto, California, and offices in North America, Europe, Asia, the Middle East, Africa and South America. Its Palo Alto campus consists of four buildings on 16 acres in Palo Alto's Stanford Research Park.\n\nClients include AirFrance/KLM, Carrefour, Citi, Airbus Group, Conway, ING, Marks and Spencer, Nielsen, Shell, University of Chicago Medicine, and Western Union.", "title": "TIBCO Software", "category": "Data analysis software"}
{"text": "KXEN was an American software company which existed from 1998 to 2013 when it was acquired by SAP AG.", "title": "KXEN Inc.", "category": "Data mining and machine learning software"}
{"text": "The Matthews correlation coefficient is used in machine learning as a measure of the quality of binary (two-class) classifications, introduced by biochemist Brian W. Matthews in 1975. It takes into account true and false positives and negatives and is generally regarded as a balanced measure which can be used even if the classes are of very different sizes. The MCC is in essence a correlation coefficient between the observed and predicted binary classifications; it returns a value between \u22121 and +1. A coefficient of +1 represents a perfect prediction, 0 no better than random prediction and \u22121 indicates total disagreement between prediction and observation. The statistic is also known as the phi coefficient. MCC is related to the chi-square statistic for a 2\u00d72 contingency table\n |\\text{MCC}| = \\sqrt{\\frac{\\chi^2}{n}}\n\nwhere n is the total number of observations.\n\nWhile there is no perfect way of describing the confusion matrix of true and false positives and negatives by a single number, the Matthews correlation coefficient is generally regarded as being one of the best such measures. Other measures, such as the proportion of correct predictions (also termed accuracy), are not useful when the two classes are of very different sizes. For example, assigning every object to the larger set achieves a high proportion of correct predictions, but is not generally a useful classification.\n\nThe MCC can be calculated directly from the confusion matrix using the formula:\n\n \n\\text{MCC} = \\frac{ \\mathit{TP} \\times \\mathit{TN} - \\mathit{FP} \\times \\mathit{FN} } {\\sqrt{ (\\mathit{TP} + \\mathit{FP}) ( \\mathit{TP} + \\mathit{FN} ) ( \\mathit{TN} + \\mathit{FP} ) ( \\mathit{TN} + \\mathit{FN} ) } }\n\n\nIn this equation, TP is the number of true positives, TN the number of true negatives, FP the number of false positives and FN the number of false negatives. If any of the four sums in the denominator is zero, the denominator can be arbitrarily set to one; this results in a Matthews correlation coefficient of zero, which can be shown to be the correct limiting value.\n\nThe MCC can be calculated with the formula:\n \n\\text{MCC} = \\sqrt{\\mathit{PPV} \\times \\mathit{TPR} \\times \\mathit{TNR} \\times \\mathit{NPV}}\n-\\sqrt{\\mathit{FDR} \\times \\mathit{FNR} \\times \\mathit{FPR} \\times \\mathit{FOR}}\n\nusing the positive predictive value, the true positive rate, the true negative rate, the negative predictive value, the false discovery rate, the false negative rate, the false positive rate, and the false omission rate.\n\nThe original formula as given by Matthews was:\n\nN = \\mathit{TN} + \\mathit{TP} + \\mathit{FN} + \\mathit{FP}\n\n\nS = \\frac{ \\mathit{TP} + \\mathit{FN} } { N }\n\n\nP = \\frac{ \\mathit{TP} + \\mathit{FP} } { N }\n\n\n\\text{MCC} = \\frac{ \\mathit{TP} / N - S \\times P } {\\sqrt{ P S  ( 1 - S)  ( 1 - P ) } }\n\n\nThis is equal to the formula given above. As a correlation coefficient, the Matthews correlation coefficient is the geometric mean of the regression coefficients of the problem and its dual. The component regression coefficients of the Matthews correlation coefficient are Markedness (\u0394p) and Youden's J statistic (Informedness or \u0394p'). Markedness and Informedness correspond to different directions of information flow and generalize Youden's J statistic, the  \\delta p statistics and (as their geometric mean) the Matthews Correlation Coefficient to more than two classes.\n\nSome scientists claim the Matthews correlation coefficient to be the most informative single score to establish the quality of a binary classifier prediction in a confusion matrix context.", "title": "Matthews correlation coefficient", "category": "Machine learning"}
{"text": "Novelty detection is the mechanism by which an intelligent organism is able to identify an incoming sensory pattern as being hitherto unknown. If the pattern is sufficiently salient or associated with a high positive or strong negative utility, it will be given computational resources for effective future processing. The principle is long known in neurophysiology, with roots in the orienting response research by E. N. SokholovSokolov, E. N., (1960). Neuronal models and the orienting reflex, In The Central Nervous System and Behavior, Mary A.B. Brazier, ed. NY: JosiahMacy, Jr. Foundation, pp. 187\u2013276 in the 1950s. The reverse phenomenon is habituation, i.e., the phenomenon that known patterns yield a less marked response. Early neural modeling attempts were by Yehuda Salu.Salu, Y. (1988). Models of neural novelty detectors, with similarities to cerebral cortex. BioSystems, 21, pp. 99-113, Elsevier. An increasing body of knowledge has been collected concerning the corresponding mechanisms in the brain.Tiitinen, H., May, P., Reinikainen K. &  N\u00e4\u00e4t\u00e4nen, R. (1994). Attentive novelty detection in humans is governed by pre-attentive sensory memory, Nature, 372, pp. 90\u201392.Duncan, K., Ketz, N., Inati, S.J., Davachi, L. (2012). Evidence for area CA1 as a match/mismatch detector: A high-resolution fMRI study of the human hippocampus, Hippocampus, 22(3), pp. 389-398 In technology, the principle became important for radar detection methods during the Cold War, where unusual aircraft-reflection patterns could indicate an attack by a new type of aircraft. Today, the phenomenon plays an important role in machine learning and data science, where the corresponding methods are known as anomaly detection or outlier detection. An extensive methodological overview is given by Markou and Singh.Markou, M. & Singh, S. (2003). Novelty detection: a review \u2014 Part 1: statistical approaches, Signal Processing, Volume 83, Issue 12, pp. 2481-2497, ISSN 0165-1684Markou, M. & Singh, S. (2003). Novelty detection: a review \u2014 Part 2: neural network based approaches, Signal Processing, Volume 83, Issue 12, pp. 2499-2521, ISSN 0165-1684", "title": "Novelty detection", "category": "Machine learning"}
{"text": "John Langford is a machine learning research scientist, a field that he says \"is shifting from an academic discipline to an industrial tool\".  He is the author of the weblog hunch.net and the principal developer of Vowpal Wabbit.  John works at Microsoft Research New York, of which he was one of the founding members, and was previously affiliated with Yahoo! Research, Toyota Technological Institute at Chicago, and IBM's Watson Research Center.  He studied Physics and Computer Science at the California Institute of Technology, earning a double bachelor's degree in 1997, and he received his Ph.D. in Computer Science from Carnegie Mellon University in the year of 2002.  He was the program co-chair for the 2012 International Conference on Machine Learning.", "title": "John Langford (computer scientist)", "category": "Machine learning researchers"}
{"text": "Ben Goertzel (born December 8, 1966) is the founder and CEO of SingularityNET, a blockchain-based AI marketplace project. Goertzel is also the chief scientist of financial prediction firm Aidyia Holdings and robotics firm Hanson Robotics; chairman of AI software company Novamente LLC, a privately held software company; chairman of the Artificial General Intelligence Society and the OpenCog Foundation; vice chairman of futurist nonprofit Humanity+; scientific advisor of biopharma firm Genescient Corp.; advisor to Singularity University; research professor in the Fujian Key Lab for Brain-Like Intelligent Systems at Xiamen University of Technology, China; chair of the Artificial General Intelligence (AGI) conference series, and an American author and researcher in the field of artificial intelligence. He was the Director of Research of the Machine Intelligence Research Institute (formerly the Singularity Institute).\"The Singularity Institute's Scary Idea (and Why I Don't Buy It)\", The Multiverse According to Ben, 29 October 2010\n\nGoertzel is the son of Ted Goertzel, a former professor of sociology at Rutgers University.Pauling's Prizes, The New York Times, 5 November 1995  He left high school after the tenth grade to attend Bard College at Simon's Rock, where he graduated with a bachelor's degree in Quantitative Studies. Goertzel went on to obtain a Ph.D. in mathematics from Temple University in 1989. He is the Chief Scientist of Hanson Robotics, the company that created the robot Sophia. ", "title": "Ben Goertzel", "category": "Machine learning researchers"}
{"text": "Jaime Guillermo Carbonell (born July 29, 1953) is a computer scientist who has made seminal contributions to the development of natural language processing tools and technologies. His extensive research in machine translation has resulted in the development of several state-of-the-art language translation and artificial intelligence systems. He earned his B.S. degrees in Physics and in Mathematics from MIT in 1975 and did his Ph.D. under Dr. Roger Schank at Yale University in 1979. He joined Carnegie Mellon University as an assistant professor of computer science in 1979 and has lived in Pittsburgh since then. He is currently affiliated with the Language Technologies Institute, Computer Science Department, Machine Learning Department, and Computational Biology Department at Carnegie Mellon.\n\nHis interests span several areas of artificial intelligence, language technologies and machine learning. In particular, his research is focused on areas such as text mining (extraction, categorization, novelty detection) and in new theoretical frameworks such as a unified utility-based theory bridging information retrieval, summarization, free-text question-answering and related tasks.  He also works on machine translation, both high-accuracy knowledge-based MT and machine learning for corpus-based MT (such as generalized example-based MT).", "title": "Jaime Carbonell", "category": "Machine learning researchers"}
{"text": "Elastic matching is one of the pattern recognition techniques in computer science. Elastic matching (EM) is also known as deformable template, flexible matching, or nonlinear template matching.\n\nElastic matching can be defined as an optimization problem of two-dimensional warping specifying corresponding pixels between subjected images.", "title": "Elastic matching", "category": "Machine learning"}
{"text": "LanguageWare is a natural language processing (NLP) technology developed by IBM, which allows applications to process natural language text. It comprises a set of Java libraries which provide a range of NLP functions: language identification, text segmentation/tokenization, normalization, entity and relationship extraction, and semantic analysis and disambiguation. The analysis engine uses Finite State Machine approach at multiple levels, which aids its performance characteristics, while maintaining a reasonably small footprint.\nThe behaviour of the system is driven by a set of configurable lexico-semantic resources which describe the characteristics and domain of the processed language. A default set of resources comes as part of LanguageWare and these describe the native language characteristics, such as morphology, and the basic vocabulary for the language. Supplemental resources have been created which capture additional vocabularies, terminologies, rules and grammars, which may be generic to the language or specific to one or more domains.\n\nA set of Eclipse-based customization tooling, LanguageWare Resource Workbench, is available on IBM's alphaWorks site, and allows domain knowledge to be compiled into these resources and thereby incorporated into the analysis process.\n\nLanguageWare can be deployed as a set of UIMA-compliant annotators, Eclipse plug-ins or Web Services.", "title": "LanguageWare", "category": "Data mining and machine learning software"}
{"text": "In machine learning, semantic analysis of a corpus is the task of building structures that approximate concepts from a large set of documents. It generally does not involve prior semantic understanding of the documents.\n\nLatent semantic analysis (sometimes latent semantic indexing), is a class of techniques where documents are represented as vectors in term space. A prominent example is PLSI.\n\nLatent Dirichlet allocation involves attributing document terms to topics.\n\nn-grams and hidden Markov models work by representing the term stream as a markov chain where each term is derived from the few terms before it.", "title": "Semantic analysis (machine learning)", "category": "Machine learning"}
{"text": "The dominance-based rough set approach (DRSA) is an extension of rough set theory for multi-criteria decision analysis (MCDA), introduced by Greco, Matarazzo and S\u0142owi\u0144ski.\nGreco, S., Matarazzo, B., S\u0142owi\u0144ski, R.: Rough sets theory for multi-criteria decision analysis. European Journal of Operational Research, 129, 1 (2001) 1\u201347\nGreco, S., Matarazzo, B., S\u0142owi\u0144ski, R.: Multicriteria classification by\ndominance-based rough set approach. In: W.Kloesgen and J.Zytkow (eds.), Handbook of Data Mining and Knowledge Discovery, Oxford University Press, New York, 2002\nS\u0142owi\u0144ski, R., Greco, S., Matarazzo, B.: Rough set based decision support. Chapter 16 [in]: E.K. Burke and G. Kendall (eds.), Search Methodologies: Introductory Tutorials in Optimization and Decision Support Techniques, Springer-Verlag , New York (2005) 475\u2013527 The main change compared to the classical rough sets is the substitution for the indiscernibility relation by a dominance relation, which permits one to deal with inconsistencies typical to consideration of criteria  and preference-ordered decision classes.", "title": "Dominance-based rough set approach", "category": "Machine learning algorithms"}
{"text": "In computational learning theory (machine learning and theory of computation), Rademacher complexity, named after Hans Rademacher, measures richness of a class of real-valued functions with respect to a probability distribution.", "title": "Rademacher complexity", "category": "Machine learning"}
{"text": "Expectation propagation (EP) is a technique in Bayesian machine learning.\n\nEP finds approximations to a probability distribution. It uses an iterative approach that leverages the factorization structure of the target distribution.  It differs from other Bayesian approximation approaches such as variational Bayesian methods.\n\nMore specifically, suppose we wish to approximate an intractable probability distribution p(\\mathbf{x}) with a tractable distribution q(\\mathbf{x}). Expectation propagation achieves this approximation by minimizing the Kullback-Leibler divergence \\mathrm{KL}(p||q). Variational Bayesian methods minimize \\mathrm{KL}(q||p) instead.\n\nIf q(\\mathbf{x}) is a Gaussian \\mathcal{N}(\\mathbf{x}|\\mu, \\Sigma), then \\mathrm{KL}(p||q) is minimized with \\mu and \\Sigma being equal to the mean of p(\\mathbf{x}) and the covariance of p(\\mathbf{x}), respectively; this is called moment matching.", "title": "Expectation propagation", "category": "Machine learning"}
{"text": "Barney Pell (born March 18, 1968) is an American entrepreneur, angel investor and computer scientist. He is co-founder, Vice Chairman and Chief Strategy Officer of Moon Express; co-founder and Chairman of LocoMobi; and Associate Founder of Singularity University. He was co-founder and CEO of Powerset, a pioneering natural language search startup, search strategist and architect for Microsoft's Bing search engine, a pioneer in the field of General Game Playing in Artificial Intelligence, and the architect of the first intelligent agent to fly onboard and control a spacecraft.", "title": "Barney Pell", "category": "Machine learning researchers"}
{"text": "Michael Lederman Littman (born August 30, 1966) is a computer scientist. He works mainly in reinforcement learning, but has done work in machine learning, game theory, computer networking, partially observable Markov decision process solving, computer solving of analogy problems and other areas. He is currently a professor of computer science at Brown University.", "title": "Michael L. Littman", "category": "Machine learning researchers"}
{"text": "Item tree analysis (ITA) is a data analytical method which allows constructing ahierarchical structure on the items of a questionnaire or test from observed response\npatterns. Assume that we have a questionnaire with m items and that subjects can\nanswer positive (1) or negative (0) to each of these items, i.e. the items are\ndichotomous. If n subjects answer the items this results in a binary data matrix D\nwith m columns and n rows.\nTypical examples of this data format are test items which can be solved (1) or failed\n(0) by subjects. Other typical examples are questionnaires where the items are\nstatements to which subjects can agree (1) or disagree (0).\nDepending on the content of the items it is possible that the response of a subject to an\nitem j determines her or his responses to other items. It is, for example, possible that\neach subject who agrees to item j will also agree to item i. In this case we say that\nitem j implies item i (short i \\rightarrow j). The goal of an ITA is to uncover such\ndeterministic implications from the data set D.", "title": "Item tree analysis", "category": "Data analysis"}
{"text": "Ayanna MacCalla Howard (born January 24, 1972) is an African-American roboticist and the School Chair for Interactive Computing, Georgia Institute of Technology. She is also the Linda J. and Mark C. Smith Endowed Chair in Bioengineering in the School of Electrical and Computer Engineering, and the director of the Human-Automation Systems (HumAnS) Lab. Currently, she is the Chair of the School of Interactive Computing in the Georgia Tech College of Computing.", "title": "Ayanna Howard", "category": "Machine learning researchers"}
{"text": "Hartmut Neven (born 1964 in Aachen, Germany) is a scientist working in quantum computing, computer vision, robotics and computational neuroscience. He is best known for his work in face and object recognition and his contributions to quantum machine learning. He is currently Director of Engineering at Google where he is leading the Quantum Artificial Intelligence Laboratory.\n Quantum AI Lab on Google+", "title": "Hartmut Neven", "category": "Machine learning researchers"}
{"text": "Photoanalysis (or photo analysis) refers to the study of pictures to compile various types of data, for example, to measure the size distribution of virtually anything that can be captured by photo.  Photoanalysis technology has changed the way mines and mills quantify fragmented material.\nImages are a good way to document conditions before, after, and even during blasting activities.   The technology is advancing at a high rate, and lenses, storage media memory, light sensitivity and resolution have been improving steadily.  Today's digital cameras and camcorders include high-resolution optics, compact size, automatic time and date stamps, good battery life, shutters to freeze motion, and computers to autofocus and eliminate jitter using image stabilization.Palangio, Tom C. in the article \"Digital Image Analysis\" Featured in The Journal of Explosives Engineering Volume 26, Number 1", "title": "Photoanalysis", "category": "Data analysis software"}
{"text": "Co-occurrence networks are generally used to provide a graphic visualization of potential relationships between people, organizations, concepts, biological organisms like bacteria or other entities represented within written material. The generation and visualization of co-occurrence networks has become practical with the advent of electronically stored text compliant to text mining.\n\nBy way of definition, co-occurrence networks are the collective interconnection of terms based on their paired presence within a specified unit of text. Networks are generated by connecting pairs of terms using a set of criteria defining co-occurrence. For example, terms A and B may be said to \u201cco-occur\u201d if they both appear in a particular article. Another article may contain terms B and C. Linking A to B and B to C creates a co-occurrence network of these three terms. Rules to define co-occurrence within a text corpus can be set according to desired criteria. For example, a more stringent criteria for co-occurrence may require a pair of terms to appear in the same sentence.", "title": "Co-occurrence network", "category": "Data mining"}
{"text": "In machine learning and computational learning theory, LogitBoost is a boosting algorithm formulated by Jerome Friedman, Trevor Hastie, and Robert Tibshirani.  The original paper casts the AdaBoost algorithm into a statistical framework.  Specifically, if one considers AdaBoost as a generalized additive model and then applies the cost function of logistic regression, one can derive the LogitBoost algorithm.", "title": "LogitBoost", "category": "Machine learning algorithms"}
{"text": "In applied mathematics, topological data analysis (TDA) is an approach to the analysis of datasets using techniques from topology. Extraction of information from datasets that are high-dimensional, incomplete and noisy is generally challenging. TDA provides a general framework to analyze such data in a manner that is insensitive to the particular metric chosen and provides dimensionality reduction and robustness to noise.  Beyond this, it inherits functoriality, a fundamental concept of modern mathematics, from its topological nature, which allows it to adapt to new mathematical tools.\n\nThe initial motivation is to study the shape of data. TDA has combined algebraic topology and other tools from pure mathematics to allow mathematically rigorous study of \"shape\". The main tool is persistent homology, an adaptation of homology to point cloud data. Persistent homology has been applied to many types of data across many fields. Moreover, its mathematical foundation is also of theoretical importance. The unique features of TDA make it a promising bridge between topology and geometry.", "title": "Topological data analysis", "category": "Data analysis"}
{"text": "In statistics, combinatorial data analysis (CDA) is the study of data sets where the order in which objects are arranged is important. CDA can be used either to determine how well a given combinatorial construct reflects the observed data, or to search for a suitable combinatorial construct that does fit the data.", "title": "Combinatorial data analysis", "category": "Data analysis"}
{"text": "In statistics, qualitative comparative analysis (QCA) is a data analysis technique for determining which logical conclusions a data set supports. The analysis begins with listing and counting all the combinations of variables observed in the data set, followed by applying the rules of logical inference to determine which descriptive inferences or implications the data supports. The technique was originally developed by Charles Ragin in 1987.", "title": "Qualitative comparative analysis", "category": "Data analysis"}
{"text": "PatientsLikeMe is a for profit patient network and real-time research platform. Through the network, patients connect with others who have the same disease or condition and track and share their own experiences with the goal to improve outcomes. In the process, they generate data about the real-world nature of disease. With over 600,000 members, PatientsLikeMe is a source for real-world disease information and its patient-generated data form the basis of more than 100 peer-reviewed scientific studies. PatientsLikeMe was inspired by the life experiences of Stephen Heywood, diagnosed in 1998 at the age of 29 with amyotrophic lateral sclerosis (ALS), or Lou Gehrig's disease. The company was founded in 2004 by his brothers Jamie and Ben Heywood and long-time family friend Jeff Cole.", "title": "PatientsLikeMe", "category": "Data mining"}
{"text": "Leslie Pack Kaelbling is an American roboticist and the Panasonic Professor of Computer Science and Engineering at the Massachusetts Institute of Technology. She is widely recognized for adapting partially observable Markov decision process from operations research for application in artificial intelligence and robotics.TOMAS LOZANO-PEREZ: An Interview Conducted by Selma \u0160abanovic with Matthew R. Francisco, IEEE History Center, 28 August 2011. Interview #733 for Indiana University and IEEE History Center, The Institute of Electrical and Electronics Engineers Inc. Kaelbling received the IJCAI Computers and Thought Award in 1997 for applying reinforcement learning to embedded control systems and developing programming tools for robot navigation. In 2000, she was elected as a Fellow of the Association for the Advancement of Artificial Intelligence.AAAI Fellows, retrieved 2010-01-25.", "title": "Leslie P. Kaelbling", "category": "Machine learning researchers"}
{"text": "Apache Mahout is a project of the Apache Software Foundation to produce free implementations of distributed or otherwise scalable machine learning algorithms focused primarily in the areas of collaborative filtering, clustering and classification. Many of the implementations use the Apache Hadoop platform. Mahout also provides Java libraries for common maths operations (focused on linear algebra and statistics) and primitive Java collections. Mahout is a work in progress; the number of implemented algorithms has grown quickly, but various algorithms are still missing.\n\nWhile Mahout's core algorithms for clustering, classification and batch based collaborative filtering are implemented on top of Apache Hadoop using the map/reduce paradigm, it does not restrict contributions to Hadoop-based implementations. Contributions that run on a single node or on a non-Hadoop cluster are also welcomed. For example, the 'Taste' collaborative-filtering recommender component of Mahout was originally a separate project and can run stand-alone without Hadoop.\n\nStarting with the release 0.10.0, the project shifted its focus to building a backend-independent programming environment, code named \"Samsara\". The environment consists of an algebraic backend-independent optimizer and an algebraic Scala DSL unifying in-memory and distributed algebraic operators. At the time of this writing supported algebraic platforms are Apache Spark and H2O, and Apache Flink. Support for MapReduce algorithms is being gradually phased out.", "title": "Apache Mahout", "category": "Data mining and machine learning software"}
{"text": "Kirix Strata is a discontinued specialty web browser designed for data analytics.  Strata offers a browser's ability to view web pages, but also includes additional tools to perform data analysis and create reports based on structured data from local files, external relational databases and the Web.\n\nThe browser incorporates Mozilla'sMozilla-Based Applications XULRunnerMozilla XULRunner Hall of Fame into a proprietary data engine to create a rich internet application for working with data. Kirix Strata is a commercial product that uses the cross-platform wxWidgets toolkit and is supported on both Microsoft Windows and Linux.", "title": "Kirix Strata", "category": "Data analysis software"}
{"text": "In computer science, uncertain data is data that contains noise that makes it deviate from the correct, intended or original values. In the age of big data, uncertainty or data veracity is one of the defining characteristics of data. Data is constantly growing in volume, variety, velocity and uncertainty (1/veracity). Uncertain data is found in abundance today on the web, in sensor networks, within enterprises both in their structured and unstructured sources. For example, there may be uncertainty regarding the address of a customer in an enterprise dataset, or the temperature readings captured by a sensor due to aging of the sensor. In 2012 IBM called out managing uncertain data at scale in its global technology outlook report that presents a comprehensive analysis looking three to ten years into the future seeking to identify significant, disruptive technologies that will change the world. In order to make confident business decisions based on real-world data, analyses must necessarily account for many different kinds of uncertainty present in very large amounts of data. Analyses based on uncertain data will have an effect on the quality of subsequent decisions, so the degree and types of inaccuracies in this uncertain data cannot be ignored.\nUncertain data is found in the area of sensor networks; text where noisy text is found in abundance on social media, web and within enterprises where the structured and unstructured data may be old, outdated, or plain incorrect; in modeling where the mathematical model may only be an approximation of the actual process. When representing such data in a database, some indication of the probability of the correctness of the various values also needs to be estimated.\n\nThere are three main models of uncertain data in databases. In attribute uncertainty, each uncertain attribute in a tuple is subject to its own independent probability distribution. For example, if readings are taken of temperature and wind speed, each would be described by its own probability distribution, as knowing the reading for one measurement would not provide any information about the other.\n\nIn correlated uncertainty, multiple attributes may be described by a joint probability distribution. For example, if readings are taken of the position of an object, and the x- and y-coordinates stored, the probability of different values may depend on the distance from the recorded coordinates. As distance depends on both coordinates, it may be appropriate to use a joint distribution for these coordinates, as they are not independent.\n\nIn tuple uncertainty, all the attributes of a tuple are subject to a joint probability distribution. This covers the case of correlated uncertainty, but also includes the case where there is a probability of a tuple not belonging in the relevant relation, which is indicated by all the probabilities not summing to one. For example, assume we have the following tuple from a probabilistic database:\n (a, 0.4) | (b, 0.5)\n\nThen, the tuple has 10% chance of not existing in the database.", "title": "Uncertain data", "category": "Machine learning"}
{"text": "Double mass analysis Searcy, J.K. and C.H. Hardison (1960). Double-mass curves. U.S. Geological Survey Water-Supply Paper 1541-B'''' is a commonly used data analysis approach for investigating the behaviour of records made of hydrological or meteorological data at a number of locations. It is used to determine whether there is a need for corrections to the data - to account for changes in data collection procedures or other local conditions. Such changes may result from a variety of things including changes in instrumentation, changes in observation procedures, or changes in gauge location or surrounding conditions. Double mass analysis for checking consistency of a hydrological or meteorological record is considered to be an essential tool before taking it for analysis purpose. This method is based on the hypothesis that each item of the recorded data of a population is consistent.\nAn example of a double mass analysis is a \"double mass plot\", or \"double mass curve\".Wilson, E.M. (1983) Engineering Hydrology, 3rd edition. Macmillan Press, London. p.27 For this, points and/or a joining line are plotted where the x- and y- coordinates are determined by the running totals of the values observed at two stations. If both stations are affected to the same extent by the same trends then a double mass curve should follow a straight line. A break in the slope of the curve would indicate that conditions have changed at one location but not at another.\nThis technique is based on the principle that when each recorded data comes from the same parent population, they are consistent.", "title": "Double mass analysis", "category": "Data analysis"}
{"text": "Decision lists are a representation for Boolean functions which can be easily learnable from examples.  Single term decision lists are more expressive than disjunctions and conjunctions; however, 1-term decision lists are less expressive than the general disjunctive normal form and the conjunctive normal form.\nThe language specified by a k-length decision list includes as a subset the language specified by a k-depth decision tree.\n\nLearning decision lists can be used for attribute efficient learning.Adam R. Klivans and Rocco A. Servedio, \"Toward Attribute Efficient Learning of Decision Lists and Parities\", Journal of Machine Learning Research 7:12:587-602 ACM Digital Library full text", "title": "Decision list", "category": "Machine learning"}
{"text": "Tableau Software ( ) is an interactive data visualization software companyA Dead-Simple Tool That Lets Anyone Create Interactive Maps founded on January 2003 by Christian Chabot, Pat Hanrahan and Chris Stolte, in Mountain View, California. The company is currently headquartered in Seattle, Washington, United States Tableau Software Helping Data Become More Visual focused on business intelligence. On June 10, 2019,  Salesforce.com announced it would be acquiring Tableau.\n\nChabot, Hanrahan and Stolte were researchers at the Department of Computer Science at Stanford University  who specialized in visualization techniques for exploring and analyzing relational databases and data cubes. The company was started as a commercial outlet for research produced at Stanford between 1999-2002. \n\nTableau products query relational databases, online analytical processing cubes, cloud databases, and spreadsheets to generate graph-type data visualizations. The products can also extract, store, and retrieve data from an in-memory data engine.", "title": "Tableau Software", "category": "Data analysis software"}
{"text": "Truviso (pronounced true-VEE-so) is a continuous analytics, venture-backed, startup headquartered in Foster City, California developing and supporting its solution leveraging PostgreSQL, to deliver a proprietary analytics solutions for net-centric customers.  Truviso was acquired by Cisco Systems, Inc. on May 4, 2012.", "title": "Truviso", "category": "Data analysis software"}
{"text": "The Facial Recognition Technology (FERET) program was a government-sponsored project that aimed to create a large, automatic face-recognition system for intelligence, security, and law enforcement purposes. The program began in 1993 under the combined leadership of Dr. Harry Wechsler at George Mason University (GMU) and Dr. Jonathan Phillips at the Army Research Laboratory (ARL) in Adelphi, Maryland and resulted in the development of the Facial Recognition Technology (FERET) database. The goal of the FERET program was to advance the field of face recognition technology by establishing a common database of facial imagery for researchers to use and setting a performance baseline for face-recognition algorithms.P. J. Phillips, H. Moon, S. A. Rizvi, and P. J. Rauss (January 7, 1999). \"The FERET Evaluation Methodology for Face-recognition Algorithms\". NISTIR 6264 and IEEE Trans. Patern Analysis and Machine Intelligence, 22(10), Oct. 2000.\nPotential areas where this face-recognition technology could be used include:\n\n Automated searching of mug books using surveillance photos\n Controlling access to restricted facilities or equipment\n Checking the credentials of personnel for background and security clearances\n Monitoring airports, border crossings, and secure manufacturing facilities for particular individuals\n Finding and logging multiple appearances of individuals over time in surveillance videos\n Verifying identities at ATM machines\n Searching photo ID records for fraud detection\n\nThe FERET database has been used by more than 460 research groups and is currently managed by the National Institute of Standards and Technology (NIST).Li, Stan; Jain, Anil, eds. (2011). Handbook of Face Recognition. Springer-Verlag London. pp. 310\u2013312. . By 2017, the FERET database has been used to train artificial intelligence programs and computer vision algorithms to identify and sort faces.", "title": "FERET (facial recognition technology)", "category": "Machine learning task"}
{"text": "Ocean Data View (ODV) is a proprietary, freely available, software package for the analysis and visualization of oceanographic and meteorological data sets.Reiner Schlitzer, Interactive analysis and visualization of geoscience data with Ocean Data View, Computers & Geosciences, Volume 28, Issue 10, December 2002, Pages 1211-1218, http://epic.awi.de/Publications/Sch2001h.pdfhttp://gcmd.nasa.gov/records/ODV_AWI.htmlhttp://www.tos.org/oceanography/issues/issue_archive/.../11.2_brown.pdf\nODV is used by a large number of oceanographers.  The UNESCO Ocean Teacher project employs ODV as one of its main analysis and display tools.ODV homepage  ODV is used to display and analyze data from several oceanographic projects such as Argo, World Ocean Circulation Experiment, World Ocean Database Project, SeaDataNet, World Ocean Atlas, and Medar/Medatlas projects.Murray Brown, Ocean Data View 4.0, Oceanography, 11, No 2/1998, 19-21, http://www.jcommops.org/FTPRoot/Argo/Tools/ODV/MBrown_ODV_Review.pdf\nOcean Data View includes also options that permit to perform objective analysis thanks to the add-on DIVA software.", "title": "Ocean Data View", "category": "Data analysis software"}
{"text": "Quadratic unconstrained binary optimization (QUBO) is a pattern matching technique, common in machine learning applications. QUBO is an NP hard problem. Examples of problems that can be formulated as QUBO problems are the Maximum cut, Graph coloring and the Partition problem.\n\nQUBO problems may sometimes be well-suited to algorithms aided by quantum annealing.\n\nQUBO is the problem of minimizing a quadratic polynomial over binary variables.  The quadratic polynomial will be of the form \nE(X_1, X_2, ... , X_N) = \\sum_{i=1}^N \\sum_{j=1}^i Q_{ij} \\times X_i \\times X_j\nwith X_i \\in \\{0,1\\} and c_i, Q_{ij} \\in R .", "title": "Quadratic unconstrained binary optimization", "category": "Machine learning algorithms"}
{"text": "IBM SPSS Modeler is a data mining and text analytics software application from IBM. It is used to build predictive models and conduct other analytic tasks. It has a visual interface which allows users to leverage statistical and data mining algorithms without programming. One of its main aims from the outset was to get rid of unnecessary complexity in data transformations, and to make complex predictive models very easy to use. The first version incorporated decision trees (ID3), and neural networks (backprop), which could both be trained without underlying knowledge of how those techniques worked.\n\nIBM SPSS Modeler was originally named Clementine by its creators, Integral Solutions Limited. This name continued for a while after SPSS's acquisition of the product. SPSS later changed the name to SPSS Clementine, and then later to PASW Modeler. Following IBM's 2009 acquisition of SPSS, the product was renamed IBM SPSS Modeler, its current name.", "title": "SPSS Modeler", "category": "Data mining and machine learning software"}
{"text": "OpenScientist is an integration of open source products working together to do scientific visualization and data analysis, in particular for high energy physics (HEP).\n\nAmong other things, it contains a light C++ AIDA implementation that can be used to run the histogramming part of Geant4 examples.", "title": "OpenScientist", "category": "Data analysis software"}
{"text": "Pierre Baldi is a chancellor's professor of computer science at University of California IrvineList of UCI Chancellor's Professors , retrieved 2009-04-03. and the director of its Institute for Genomics and Bioinformatics.List of IGB faculty, retrieved 2009-04-03.", "title": "Pierre Baldi", "category": "Machine learning researchers"}
{"text": "PowerLab (before 1998 was referred to as MacLab) is a data acquisition system developed by ADInstruments comprising hardware and software and designed for use in life science researchPapers on Google Scholar Reference to ADInstruments & PowerLab and teaching applications. It is commonly used in physiology, pharmacology, biomedical engineering, sports/exercise studies and psychophysiology laboratories to record and analyse physiological signals from human or animal subjects or from isolated organs. The system consists of an input device connected to a Microsoft Windows or Mac OS computer using a USB cable and LabChart software which is supplied with the PowerLab and provides the recording, display and analysis functions. The use of PowerLab and supplementary ADInstruments products have been demonstrated on the Journal of Visualised Experiments.JOVE: Journal of Visualised Experiments using PowerLab\nThe original MacLab unit was developed in the late 1980s to run with only Macintosh computers to perform computer-based data acquisition and analysis. The MacLab product range was renamed \"PowerLab\" in 1997 to reflect the cross-platform nature of the system.\n\nThe PowerLab system is essentially a peripheral device designed to perform various functions needed for data acquisition, signal conditioning and pre-processing.  Versatile display options and analysis functions are complemented by the ability to export data to other software (such as Microsoft Excel).", "title": "PowerLab", "category": "Data analysis software"}
{"text": "Mehryar Mohri is a professor of computer science at the Courant Institute of Mathematical Sciences at New York University known for his work in machine learning, automata theory and algorithms, speech recognition and natural language processing.\nHe received his B.S from \u00c9cole Polytechnique (1987), his M.S. in computer science and applied mathematics from \u00c9cole Normale Sup\u00e9rieure (1989) and his Ph.D. in 1993 from the University of Paris 7 Denis Diderot.Analyse et representation par automates de structures syntaxiques compos\u00e9es. Application aux compl\u00e9tives, (1993), U. Paris VII Prior to joining the Courant Institute in 2004, Mohri worked for ten years at Bell Labs and AT&T Labs, where he was Head of the Speech Algorithms Department.Biography from Mohri's web site.\n\nMohri's main areas of research are machine learning, theory, computational biology,\nand text and speech processing.Home page from Mohri's web site. He is\nthe author of many core weighted automata and finite state transducer algorithms and pioneered the application of weighted finite state transducers (WFSTs) to speech recognition and natural language processing with his colleagues at AT&T.IDIAP Research Report.\n\nAt the Eurospeech 2001 conference in Aalborg, a paper by Mohri and Michael Riley, \u201cNetwork Optimizations for Large-Vocabulary Speech Recognition,\u201d was given an award by the International Speech Communication Association as \u201cthe best paper published in Speech Communications during 1998-2000.\u201dISCA awards . His work with Brian Roark, \u201cProbabilistic Context-Free Grammar Induction Based on Structural Zeros,\u201d won a best paper award at HLT-NAACL 2006.NAACL program committee chairs report. Mohri is Editorial Board member of Machine LearningEditorial Board, Machine Learning and member of the advisory board for the Journal of Automata, Languages and Combinatorics.official website of Journal of Automata, Languages and Combinatorics", "title": "Mehryar Mohri", "category": "Machine learning researchers"}
{"text": "XLfit is a Microsoft Excel-based plug-in which performs Regression, curve fitting and statistical analysis. XLfit generates 2D and 3D graphs and analyses data sets produced by any type of research. XLfit\u2019s curve fitting engine allows linear and non-linear curve fits, smoothing, statistics, weighting and error bars.\n\nXLfit includes over seventy linear and non-linear curve fitting models. Predefined categories include:\n Exponential/Log, Power Series, Sigmoidal, Hyperbolic, Yield Density, Linear, Polynomial, Dose Response, Pharmacology, Equilibrium, Inhibition\n Levenberg-Marquardt fitting algorithm\n\nA range of statistical calculations can also be applied to the data from within the spreadsheet.\n\nExample statistics include:\n F test and T test\n Area under the curve\n Confidence intervals\n Error values relating to parameter values or any point on the curve.\n\nAvailable statistics models include\nSpearman's Rank Correlations, Student's T-Test, Mann Whitney U-Test, least squares, ANOVA, among others. It is possible to add your own models and statistics to the provided ones using a model editor.\n\nXLfit was validated by The UK National Physical Laboratoryhttp://www.engineeringtalk.com/news/ade/ade261.html in 2004. The unit tests for this are provided in the model editor from version 5.4 onwards to allow each version to be easily validated.\n\nXLfit was used by NASA to analyse the battery life of the Curiosity Mars Lander.", "title": "XLfit", "category": "Data analysis software"}
{"text": "Web intelligence is the area of scientific research and development that explores the roles and makes use of artificial intelligence and information technology for new products, services and frameworks that are empowered by the World Wide Web.\nThe term was coined in a paper written by Ning Zhong, Jiming Liu Yao and Y.Y. Ohsuga in the Computer Software and Applications Conference in 2000.", "title": "Web intelligence", "category": "Data mining"}
{"text": "Data Mining and Knowledge Discovery is a bimonthly peer-reviewed scientific journal focusing on data mining published by Springer Science+Business Media.  It was started in 1996 and launched in 1997 by Usama Fayyad as founding Editor-in-Chief by Kluwer Academic Publishers (later becoming Springer). The first Editorial provides a summary of why it was started.", "title": "Data Mining and Knowledge Discovery", "category": "Data mining"}
{"text": "In machine learning, instance-based learning (sometimes called memory-based learning) is a family of learning algorithms that, instead of performing explicit generalization, compares new problem instances with instances seen in training, which have been stored in memory.\nIt is called instance-based because it constructs hypotheses directly from the training instances themselves.Stuart Russell and Peter Norvig (2003). Artificial Intelligence: A Modern Approach, second edition, p. 733. Prentice Hall. \nThis means that the hypothesis complexity can grow with the data: in the worst case, a hypothesis is a list of n training items and the computational complexity of classifying a single new instance is O(n). One advantage that instance-based learning has over other methods of machine learning is its ability to adapt its model to previously unseen data. Instance-based learners may simply store a new instance or throw an old instance away.\n\nExamples of instance-based learning algorithm are the k-nearest neighbors algorithm, kernel machines and RBF networks. These store (a subset of) their training set; when predicting a value/class for a new instance, they compute distances or similarities between this instance and the training instances to make a decision.\n\nTo battle the memory complexity of storing all training instances, as well as the risk of overfitting to noise in the training set, instance reduction algorithms have been proposed.\n\nGagliardi applies this family of classifiers in medical field as second-opinion diagnostic tools and as tools for the knowledge extraction phase in the process of knowledge discovery in databases. \nOne of these classifiers (called Prototype exemplar learning classifier (PEL-C) is able to extract a mixture of abstracted prototypical cases (that are syndromes) and selected atypical clinical cases.", "title": "Instance-based learning", "category": "Machine learning"}
{"text": "The computational intelligence and machine learning (CIML) community portal is an international multi-university initiative.  Its primary purpose is to help facilitate a virtual scientific community infrastructure for all those involved with, or interested in, computational intelligence and machine learning.  This includes CIML research-, education, and application-oriented resources residing at the portal and others that are linked from the CIML site.", "title": "CIML community portal", "category": "Machine learning"}
{"text": "The Biopac Student Lab is a proprietary teaching device and method introduced in 1995 as a digital replacement for aging chart recorders and oscilloscopes that were widely used in undergraduate teaching laboratories prior to that time. It is manufactured by BIOPAC Systems, Inc., of Goleta, California.biopac The advent of low cost personal computers meant that older analog technologies could be replaced with powerful and less expensive computerized alternatives.Investigative Process & Technology in Introductory Physiology   Author: Hawke, Scott D.\n\nStudents in undergraduate teaching labs use the BSL system to record data from their own bodies, animals or tissue preparations. The BSL system integrates hardware, software and curriculum materials including over sixty experiments that students use to study the cardiovascular system, muscles, pulmonary function, autonomic nervous system, and the brain.", "title": "Biopac student lab", "category": "Data analysis software"}
{"text": "Uniform convergence in probability is a form of convergence in probability in statistical asymptotic theory and probability theory. It means that, under certain conditions, the empirical frequencies of all events in a certain event-family converge to their theoretical probabilities.  Uniform convergence in probability has applications to statistics as well as machine learning as part of statistical learning theory.\n\nThe law of large numbers says that, for each single event, its empirical frequency in a sequence of independent trials converges (with high probability) to its theoretical probability. But in some applications, we are interested not in a single event but in a whole family of events. We would like to know whether the empirical frequency of every event in the family converges to its theoretical probability simultaneously. The Uniform Convergence Theorem gives a sufficient condition for this convergence to hold. Roughly, if the event-family is sufficiently simple (its VC dimension is sufficiently small) then uniform convergence holds.", "title": "Uniform convergence in probability", "category": "Machine learning"}
{"text": "L\u00e9on Bottou (born 1965) is a researcher best known for his work in machine learning and data compression. His work presents stochastic gradient descent as a fundamental learning algorithm. He is also one of the main creators of the DjVu image compression technology (together with Yann LeCun and Patrick Haffner), and the maintainer of DjVuLibre, the open source implementation of DjVu. He is the original developer of the Lush programming language.", "title": "L\u00e9on Bottou", "category": "Machine learning researchers"}
{"text": "Yann LeCun ( ;  originally spelled Le Cun; born July 8, 1960) is a French computer scientist working primarily in the fields of machine learning, computer vision, mobile robotics, and computational neuroscience. He is the Silver Professor of the Courant Institute of Mathematical Sciences at New York University, and Vice President, Chief AI Scientist at Facebook.\n\nHe is well known for his work on optical character recognition and computer vision using convolutional neural networks (CNN), and is a founding father of convolutional nets.  He is also one of the main creators of the DjVu image compression technology (together with L\u00e9on Bottou and Patrick Haffner). He co-developed the Lush programming language with L\u00e9on Bottou.\n\nHe is co-recipient of the 2018 ACM A.M. Turing Award for his work in deep learning.", "title": "Yann LeCun", "category": "Machine learning researchers"}
{"text": "Kunihiko Fukushima (born in Japan) is a Japanese computer scientist, most noted for his work on artificial neural networks and deep learning. He is currently working part-time as a Senior Research Scientist at the Fuzzy Logic Systems Institute in Tokyo.\n\nIn 1980, Fukushima published the neocognitron, \nthe original deep convolutional neural network (CNN) architecture. Fukushima proposed several supervised and unsupervised learning algorithms to train the parameters of a deep neocognitron such that it could learn internal representations of incoming data. (Today, however, the CNN architecture is usually trained through backpropagation. This approach is now heavily used in computer vision.)\n\nIn 1958, Fukushima received his Bachelor of Engineering in electronics from Kyoto University. He became a Senior Research Scientist at the NHK Science & Technology Research Laboratories. In 1989, he joined the faculty of Osaka University. In 1999, he joined the faculty of the University of Electro-Communications. In 2001, he joined the faculty of Tokyo University of Technology. From 2006 to 2010, he was a visiting professor at Kansai University.\n\nFukushima acted as founding President the Japanese Neural Network Society (JNNS). He also was a founding member on the Board of Governors of the International neural network society (INNS), and President of the Asia-Pacific Neural Network Assembly (APNNA).", "title": "Kunihiko Fukushima", "category": "Machine learning researchers"}
{"text": "Parity learning is a problem in machine learning. An algorithm that solves this problem must find a function \u0192, given some samples (x,\u00a0\u0192(x)) and the assurance that \u0192 computes the parity of bits at some fixed locations. The samples are generated using some distribution over the input. The problem is easy to solve using Gaussian elimination provided that a sufficient number of samples (from a distribution which is not too skewed) are provided to the algorithm.", "title": "Parity learning", "category": "Machine learning"}
{"text": "In machine learning, a subfield of computer science, learning with errors (LWE) is the problem to infer a linear n-ary function f over a finite ring from given samples y_i = f(\\mathbf{x}_i) some of which may be erroneous.\nThe LWE problem is conjectured to be hard to solve, and thus be useful in cryptography.\n\nMore precisely, an algorithm is said to solve the LWE problem if, when given access to samples (x,y) where x\\in \\mathbb{Z}_q^n (a vector of n integers modulo q) and y \\in \\mathbb{Z}_q, with the assurance, for some fixed linear function f:\\mathbb{Z}_q^n \\rightarrow \\mathbb{Z}_q, that y=f(x) with high probability and deviates from it according to some known noise model, the algorithm can recreate f or some close approximation of it with high probability.\n\nThe LWE problem was introduced by Oded Regev in 2005 (who won the 2018 G\u00f6del Prize for this work), it is a generalization of the parity learning problem. Regev showed that the LWE problem is as hard to solve as several worst-case lattice problems. Subsequently, the LWE problem has been used as a hardness assumption to create public-key cryptosystems,Oded Regev, \u201cOn lattices, learning with errors, random linear codes, and cryptography,\u201d in Proceedings of the thirty-seventh annual ACM symposium on Theory of computing (Baltimore, MD, USA: ACM, 2005), 84\u201393, http://portal.acm.org/citation.cfm?id=1060590.1060603.Chris Peikert, \u201cPublic-key cryptosystems from the worst-case shortest vector problem: extended abstract,\u201d in Proceedings of the 41st annual ACM symposium on Theory of computing (Bethesda, MD, USA: ACM, 2009), 333\u2013342, http://portal.acm.org/citation.cfm?id=1536414.1536461. such as the ring learning with errors key exchange by Peikert.", "title": "Learning with errors", "category": "Machine learning"}
{"text": "Alberto Broggi is General Manager at VisLab srl (spinoff of the University of Parma acquired by Silicon-Valley company Ambarella Inc. on June 2015)https://www.ambarella.com/news/79/122/Ambarella-Acquires-VisLab-a-European-Developer-of-Computer-Vision-and-Intelligent-Automotive-Control-Systems and  a professor of Computer Engineering at the University of Parma in Italy.", "title": "Alberto Broggi", "category": "Machine learning researchers"}
{"text": "MeeMix Ltd is a company specializing in personalizing media-related content recommendations, discovery and advertising for the telecommunication industry, founded in 2006.\n\nOn January 1, 2008, MeeMix launched meemix.com, a public personalized internet radioTechCrunch reviewVentureBeat reviewBusinesshackers review serving as an online testbed for the development of music taste-prediction technologies.About MeeMix  Subsequently, MeeMix released in 2009 a line of Business-to-business commercial services intended to personalize media recommendations, discovery and advertising. MeeMix hybrid taste-prediction technology relies on integrating machine learning algorithms, digital signal processing, behavior analysis, metadata analysis and collaborative filtering, and is provided via API web service.MeeMix technology \n\nIn August 2009, MeeMix was announced as Innovator Nominee in the GSM Association\u2019s Mobile Innovation Grand Prix worldwide contest.GSMA Grand Prix \n\nAs of 2013, MeeMix no longer features internet radios on meemix.com. On Sep 28, 2014, meemix.com went offline.", "title": "MeeMix", "category": "Data mining and machine learning software"}
{"text": "A MEX file is a type of computer file that provides an interface between MATLAB or Octave and functions written in C, C++ or Fortran. It stands for \"MATLAB executable\".\nWhen compiled, MEX files are dynamically loaded and allow external functions to be invoked from within MATLAB or Octave as if they were built-in functions.\n\nTo support the development of MEX files, both MATLAB and Octave offer external interface functions that facilitate the transfer of data between MEX files and the workspace. In addition to MEX files, Octave has its own format using its own native API, with better performance.https://www.gnu.org/software/octave/doc/interpreter/Mex_002dFiles.html", "title": "MEX file", "category": "Data analysis software"}
{"text": "Speakeasy is a numerical computing interactive environment also featuring an interpreted programming language. It was initially developed for internal use at the Physics Division of Argonne National Laboratory by the theoretical physicist Stanley Cohen.\"An introduction to Speakeasy - Informal report He eventually founded Speakeasy Computing Corporation to make the program available commercially.\n\nSpeakeasy is a very long-lasting numerical package. In fact, the original version of the environment was built around a core dynamic data repository called \"Named storage\" developed in the early 1960s,\"Named storage: a dynamic storage-allocation scheme with manipulative routines\", AEC research and development report - Volume 7021 ANL (Series) - Stanley Cohen, Physics Division, U.S. Atomic Energy Commission, Argonne National Laboratory, 1965.\"Speakeasy - An evolutionary system\", S. Cohen,  Proceedings of the ACM SIGPLAN symposium on Very high level languages (March 1974) while the most recent version has been released in 2006.\n\nSpeakeasy was aimed to make the computational work of the physicists at the Argonne National Laboratory easier. It was initially conceived to work on mainframes (the only kind of computers at that time), and was subsequently ported to new platforms (minicomputers, personal computers) as they became available. The porting of the same code on different platforms was made easier by using Mortran metalanguage macros to face systems dependencies and compilers deficiencies and differences.\"Using Mortran to translate Fortran programs from one machine to another\"\nSteven C. Pieper, Argonne National Laboratory, 1976 Speakeasy is currently available on several platforms: PCs running Windows, macOS, Linux, departmental computers and workstations running several flavors of Linux, AIX or Solaris.\n\nSpeakeasy was also among the first interactive numerical computing environments, having been implemented in such a way on a CDC 3600 system, and later on IBM TSO machines as one was in beta-testing at the Argonne National Laboratory at the time.\n\nAlmost since the beginning (as the dynamic linking functionality was made available in the operating systems) Speakeasy features the capability of expanding its operational vocabulary using separated modules, dynamically linked to the core processor as they are needed. For that reason such modules  were called \"linkules\" (LINKable-modULES).\"Speakeasy linkules - plug compatible software\" ACM - Proceedings of the 1977 annual conference They are functions with a generalized interface, which can be written in  FORTRAN or in C.\nThe independence of each of the new modules from the others and from the main processor is of great help in improving the system, especially it was in the old days.\n\nThis easy way of expanding the functionalities of the main processor was often exploited by the users to develop their own specialized packages. Besides the programs, functions and subroutines the user can write in the Speakeasy's own interpreted language, linkules add functionalities carried out with the typical performances of compiled programs.\n\nAmong the packages developed by the users, one of the most important is \"Modeleasy\", originally developed as \"FEDeasy\"\"Econometric models via SPEAKEASY/FEDEASY\", James M. Condie, John W. Davison, 1975 in the early 1970s at the research department of the Federal Reserve Board of Governors in Washington D.C..\nModeleasy implements special objects and functions for large econometric models estimation and simulation.\nIts evolution led eventually to its distribution as an independent product.", "title": "Speakeasy (computational environment)", "category": "Data analysis software"}
{"text": "Product of experts (PoE) is a machine learning technique. It models a probability distribution by combining the output from several simpler distributions.It was proposed by Geoff Hinton, along with an algorithm for training the parameters of such a system.\n\nThe core idea is to combine several probability distributions (\"experts\") by multiplying their density functions\u2014making the PoE classification similar to an \"and\" operation. This allows each expert to make decisions on the basis of a few dimensions without having to cover the full dimensionality of a problem.\n\nThis is related to (but quite different from) a mixture model, where several probability distributions are combined via an \"or\" operation, which is a weighted sum of their density functions.", "title": "Product of experts", "category": "Machine learning"}
{"text": "KNIME (), the Konstanz Information Miner, is a free and open-source data analytics, reporting and integration platform. KNIME integrates various components for machine learning and data mining through its modular data pipelining concept. A graphical user interface and use of JDBC allows assembly of nodes blending different data sources, including preprocessing (ETL: Extraction, Transformation, Loading), for modeling, data analysis and visualization without, or with only minimal, programming. To some extent as advanced analytics tool KNIME can be considered as a SAS alternative.\n\nSince 2006, KNIME has been used in pharmaceutical research, it also used in other areas like CRM customer data analysis, business intelligence and financial data analysis.", "title": "KNIME", "category": "Data mining and machine learning software"}
{"text": "Learning to rank. Slides from Tie-Yan Liu's talk at WWW 2009 conference are available online\n or machine-learned ranking (MLR) is the application of machine learning, typically supervised, semi-supervised or reinforcement learning, in the construction of ranking models for information retrieval systems.Mehryar Mohri, Afshin Rostamizadeh, Ameet Talwalkar (2012) Foundations of Machine Learning, The\nMIT Press . Training data consists of lists of items with some partial order specified between items in each list. This order is typically induced by giving a numerical or ordinal score or a binary judgment (e.g. \"relevant\" or \"not relevant\") for each item. The ranking model's purpose is to rank, i.e. produce a permutation of items in new, unseen lists in a way which is \"similar\" to rankings in the training data in some sense.", "title": "Learning to rank", "category": "Machine learning"}
{"text": "Andrew Yan-Tak Ng (; born 1976) is a Chinese-American computer scientist known as one of the most prolific researchers in machine learning and AI, with his work helping incite the recent revolution in deep learning. Also a business executive and investor in the  Silicon Valley, Ng co-founded and led Google Brain and was a former Vice President and Chief Scientist at Baidu, building the company's Artificial Intelligence Group into a team of several thousand people.\n\nNg is an adjunct professor at Stanford University (formerly associate professor and Director of its AI Lab). Also a pioneer in online education, Ng co-founded Coursera and deeplearning.ai. With his online courses, he has successfully spearheaded many efforts to \"democratize deep learning.\" Since 2018 he launched and currently heads AI Fund, initially a $175-million investment fund for backing artificial intelligence startups. He has founded Landing AI, which provides AI-powered SaaS products and Transformation Program to empower enterprises into cutting-edge AI companies.", "title": "Andrew Ng", "category": "Machine learning researchers"}
{"text": "Encog is a machine learning framework available for Java and .Net.J. Heaton http://www.jmlr.org/papers/volume16/heaton15a/heaton15a.pdf Encog: Library of Interchangeable Machine Learning Models for Java and C#\nEncog supports different learning algorithms such as  Bayesian Networks, Hidden Markov Models and Support Vector Machines.\nHowever, its main strength lies in its neural network algorithms. Encog contains classes to create a wide variety of networks, as well as support classes to normalize and process data for these neural networks. Encog trains using many different techniques.  Multithreading is used to allow optimal training performance on multicore machines.\n\nEncog can be used for many tasks, including medicalD. Heider, J. Verheyen, D. Hoffmann http://www.biomedcentral.com/content/pdf/1471-2105-11-37.pdf Predicting Bevirimat resistance of HIV-1 from genotype and financial research.J. Heaton http://www.devx.com/opensource/Article/44014/1954 Basic Market Forecasting with Encog Neural Networks A GUI based workbench is also provided to help model and train neural networks.  Encog has been in active development since 2008.http://www.heatonresearch.com/encog Description of Encog Project.", "title": "Encog", "category": "Data mining and machine learning software"}
{"text": "The primary value learned value (PVLV) model is a possible explanation for the reward-predictive firing properties of dopamine (DA) neurons. It simulates behavioral and neural data on Pavlovian conditioning and the midbrain dopaminergic neurons that fire in proportion to unexpected rewards. It is an alternative to the temporal-differences (TD) algorithm.\nIt is used as part of Leabra.", "title": "PVLV", "category": "Machine learning algorithms"}
{"text": "Andrei (Andrew) Knyazev () is a Russian-American mathematician. He graduated from the Faculty of Computational Mathematics and Cybernetics of Moscow State University under the supervision of Evgenii Georgievich D'yakonov () in 1981 and obtained his PhD in Numerical Mathematics at the Russian Academy of Sciences under the supervision of Vyacheslav Ivanovich Lebedev () in 1985. He worked at the Kurchatov Institute in 1981-1983, and then to 1992 at the Marchuk Institute of Numerical Mathematics () of the Russian Academy of Sciences, headed by Gury Marchuk ().\n\nIn 1993-1994, Knyazev held a visiting position at the Courant Institute of Mathematical Sciences of New York University, collaborating with Olof B. Widlund.\n From 1994 until retirement in 2014, he was a Professor of Mathematics at the University of Colorado Denver, supported by the National Science FoundationKnyazev's NSF awards and United States Department of Energy grants. He was a recipient of the 2008 Excellence in Research Award,\n the 2000 college Teaching Excellence Award, and a finalist of the CU President's Faculty Excellence Award for Advancing Teaching and Learning through Technology in 1999.\n \nHe was awarded the title of Professor Emeritus at the University of Colorado Denver \n \nand named the SIAM Fellow Class of 2016 \n\nand \nAMS  Fellow Class of 2019.\n\n\nIn 2012-2018, Knyazev held a Distinguished Research Scientist position at the Mitsubishi Electric Research Laboratories (MERL).Andrew Knyazev moved to MERL, 2012 His research at MERL was on algorithms for image and video processing, data sciences, optimal control, material sciences, and numerical simulation of complex phenomena, resulting in publications and 13 patent applications.Knyazev's Websiteat Mitsubishi Electric Research Laboratories \n\nKnyazev was mostly known for his work in numerical solution of large sparse eigenvalue problems, particularly preconditioning \n and the iterative method LOBPCG.\n Knyazev's reference implementation of LOBPCG was available in the public software package BLOPEX and, e.g., the electronic structure calculations library ABINIT for wavefunction parallel optimization.\n\n\nKnyazev collaborated with John Osborn\n\n\non the theory of the Ritz method in the finite element method context \nand with Nikolai Sergeevich Bakhvalov () (Erd\u0151s number 3 via Leonid Kantorovich) on numerical solution of elliptic partial differential equations with large jumps in the main coefficients.\n\nJointly with his Ph.D. students, Knyazev pioneered using majorization for bounds in the Rayleigh\u2013Ritz method\n(see \n and references there) and contributed to the theory of angles between flats.\n\n", "title": "Andrei Knyazev (mathematician)", "category": "Machine learning researchers"}
{"text": "In applied mathematics, multimodal optimization deals with optimization tasks that involve finding all or most of the multiple (at least locally optimal) solutions of a problem, as opposed to a single best solution.\nEvolutionary multimodal optimization is a branch of evolutionary computation, which is closely related to machine learning. Wong provides a short survey,Wong, K. C. (2015), Evolutionary Multimodal Optimization: A Short Survey arXiv preprint arXiv:1508.00457 wherein the chapter of ShirShir, O.M. (2012), Niching in Evolutionary Algorithms and the book of PreussPreuss, Mike  (2015), Multimodal Optimization by Means of Evolutionary Algorithms cover the topic in more detail.", "title": "Evolutionary multimodal optimization", "category": "Machine learning algorithms"}
{"text": "GeneRec is a generalization of the recirculation algorithm, and approximates Almeida-Pineda recurrent backpropagation.O'Reilly, R.C. Biologically Plausible Error-driven Learning using Local Activation Differences: The Generalized Recirculation Algorithm. Neural Computation, 8, 895-938. Abstract PDFGeneRec description in Computational explorations in cognitive neuroscience: understanding the mind by Randall C. O'Reilly, Yuko Munakata It is used as part of the Leabra algorithm for error-driven learning.Leabra overview in Emergent\nThe symmetric, midpoint version of GeneRec is equivalent to the contrastive Hebbian learning algorithm (CHL).", "title": "GeneRec", "category": "Machine learning algorithms"}
{"text": "Almeida\u2013Pineda recurrent backpropagation is an extension to the backpropagation algorithm that is applicable to recurrent neural networks. It is a type of supervised learning. It was described somewhat cryptically in Richard Feynman's senior thesis, and rediscovered independently in the context of artificial neural networks by both Fernando Pineda and Luis B. Almeida.\nA recurrent neural network for this algorithm consists of some input units, some output units and eventually some hidden units.\n\nFor a given set of (input, target) states, the network is trained to settle into a stable activation state with the output units in the target state, based on a given input state clamped on the input units.", "title": "Almeida\u2013Pineda recurrent backpropagation", "category": "Machine learning algorithms"}
{"text": "Error-driven learning is a sub-area of machine learning concerned with how an agent ought to take actions in an environment so as to minimize some error feedback. It is a type of reinforcement learning.", "title": "Error-driven learning", "category": "Machine learning algorithms"}
{"text": "Prefrontal cortex basal ganglia working memory (PBWM) is an algorithm that models working memory in the prefrontal cortex and the basal ganglia. It can be compared to long short-term memory (LSTM) in functionality, but is more biologically explainable.\n\nIt uses the primary value learned value model to train prefrontal cortex working-memory updating system, based on the biology of the prefrontal cortex and basal ganglia.\n\nIt is used as part of the Leabra framework and was implemented in Emergent.", "title": "Prefrontal cortex basal ganglia working memory", "category": "Machine learning algorithms"}
{"text": "ELKI (for Environment for DeveLoping KDD-Applications Supported by Index-Structures) is a knowledge discovery in databases (KDD, \"data mining\") software framework developed for use in research and teaching originally at the database systems research unit of Professor Hans-Peter Kriegel at the Ludwig Maximilian University of Munich, Germany. It aims at allowing the development and evaluation of advanced data mining algorithms and their interaction with database index structures.", "title": "ELKI", "category": "Data mining and machine learning software"}
{"text": "In anomaly detection, the local outlier factor (LOF) is an algorithm proposed by Markus M. Breunig, Hans-Peter Kriegel, Raymond T. Ng and J\u00f6rg Sander in 2000 for finding anomalous data points by measuring the local deviation of a given data point with respect to its neighbours.\n\nLOF shares some concepts with DBSCAN and OPTICS such as the concepts of \"core distance\" and \"reachability distance\", which are used for local density estimation.", "title": "Local outlier factor", "category": "Data mining"}
{"text": "Hans-Peter Kriegel (1 October 1948, Germany) is a German computer scientist and professor at the Ludwig Maximilian University of Munich and leading the Database Systems Group in the Department of Computer Science.\n\nHis most important contributions are the database index structures R*-tree, X-tree and IQ-Tree, the cluster analysis algorithms  DBSCAN, OPTICS and SUBCLU and the anomaly detection method Local Outlier Factor (LOF).\n\nIn 2009 the Association for Computing Machinery appointed Hans-Peter Kriegel a \"fellow\", one of its highest honors. He has been honored in particular for his contributions to \"knowledge discovery and data mining, similarity search, spatial data management, and access methods for high-dimensional data\".\n\nHe received the 2013 IEEE ICDM Research Contributions Award for his research on data mining algorithm such as DBSCAN, OPTICS, Local Outlier Factor and his work on mining high-dimensional data.\n\nHe was also awarded the 2015 ACM SIGKDD Innovation Award for his contributions to data mining in clustering, outlier detection and high-dimensional data analysis, in particular for density-based approaches.\nDBSCAN also received the 2014 ACM SIGKDD test of time award.\n\nHe is the most cited German researcher in databases and data mining.\n\nHis current research is focused around correlation clustering, high-dimensional data indexing and analysis, spatial data mining and spatial data management as well as multimedia databases.\n\nHis research group publishes a Java software framework titled Environment for DeveLoping KDD-Applications Supported by Index-Structures (ELKI) that is designed for the parallel research of index structures, data mining algorithms and their interaction, such as optimized data mining algorithms based on databases indexes.", "title": "Hans-Peter Kriegel", "category": "Machine learning researchers"}
{"text": "ArnetMiner (also AMiner) is a free online service used to index, search, and mine big scientific data.", "title": "Arnetminer", "category": "Data mining"}
{"text": "CANalyzer is an analysis software tool from Vector Informatik GmbH. This development software is widely used, primarily by automotive and electronic control unit suppliers, to analyze the data traffic in serial bus systems. The most relevant bus systems here are CAN, LIN, FlexRay, Ethernet and MOSTCANalyzer Website, downloaded November 3rd, 2011 as well as CAN-based protocols such as J1939,CANalyzer.J1939, downloaded November 3rd, 2011 CANopen,CANopen solutions, downloaded November 3rd, 2011 ARINC 825Overview CAN-based avionics protocols on www.avionics-networking.com, downloaded  June 17th, 2010 and many more.", "title": "CANalyzer", "category": "Data analysis software"}
{"text": "Elastic maps provide a tool for nonlinear dimensionality reduction. By their construction, they are a system of elastic springs  embedded in the data\nspace. This system approximates a low-dimensional manifold. The elastic coefficients of this system allow the switch from completely unstructured k-means clustering (zero elasticity) to the estimators located closely to linear PCA manifolds (for high bending and low stretching modules). With some intermediate values of the elasticity coefficients, this system effectively approximates non-linear principal manifolds. This approach is based on a mechanical analogy between principal manifolds, that are passing through \"the middle\" of the data distribution, and elastic membranes and plates. The method was developed by A.N. Gorban, A.Y. Zinovyev and A.A. Pitenko in 1996\u20131998.", "title": "Elastic map", "category": "Data mining"}
{"text": "OSIsoft, LLC is a manufacturer of application software for real-time data management, called the PI System. Founded in 1980, OSIsoft is privately held and headquartered in San Leandro, California.", "title": "OSIsoft", "category": "Data analysis software"}
{"text": "Cleverbot is a chatterbot web application that uses an artificial intelligence (AI) algorithm to have conversations with humans. It was created by British AI scientist Rollo Carpenter. It was preceded by Jabberwacky, a chatbot project that began in 1986 and went online in 1997. In its first decade, Cleverbot held several thousand conversations with Carpenter and his associates. Since launching on the web, the number of conversations held has exceeded 150 million.Gilbert, R. L., & Forney, A. (2015). Can avatars pass the Turing test? Intelligent agent perception in a 3D virtual environment. International Journal of Human-Computer Studies, 73, 30-36 Besides the web application, Cleverbot is also available as an iOS, Android, and Windows Phone app.", "title": "Cleverbot", "category": "Machine learning"}
{"text": "Core Security is an American computer and network security company that provides an attack intelligence platform, vulnerability management and network penetration testing measurement software products and services. The company\u2019s research arm, CoreLabs, proactively identifies new IT security vulnerabilities, publishes public vulnerability advisories, and works with vendors to assist in eliminating the exposures they find.\n\nIn February 2019, HelpSystems acquired the Core Security products from SecureAuth. HelpSystems is a Minnesota-based software company working in the areas of systems and network management, business intelligence, security and compliance.", "title": "Core Security Technologies", "category": "Data analysis software"}
{"text": "Ofer Dekel is a computer science researcher in the Machine Learning Department of Microsoft Research. He obtained his PhD in Computer Science from the Hebrew University of Jerusalem and is an affiliate faculty at the Computer Science & Engineering department at the University of Washington.", "title": "Ofer Dekel (researcher)", "category": "Machine learning researchers"}
{"text": "Erkki Oja (born 22 March 1948 in Helsinki) is a Finnish computer scientist and Aalto Distinguished Professor in the Department of Information and Computer Science at Aalto University School of Science. He is recognized for developing Oja's rule, which is a model of how neurons in the brain or in artificial neural networks learn over time. He is a Fellow of the International Association for Pattern Recognition and the IEEE, and a member of the Finnish Academy of Sciences. He served as chairman of the European Neural Network Society between 2000 and 2005, and as the chairman of the Academy of Finland\u2019s Research Council for Natural Sciences and Engineering between 2007 and 2012.", "title": "Erkki Oja", "category": "Machine learning researchers"}
{"text": "Feature Selection Toolbox (FST) is software primarily for feature selection in the machine learning domain, written in C++, developed at the Institute of Information Theory and Automation (UTIA), of the Czech Academy of Sciences.", "title": "Feature Selection Toolbox", "category": "Data mining and machine learning software"}
{"text": "Mountains is an image analysis and surface metrology software platform published by the company Digital Surf. Its core is micro-topography, the science of studying surface texture and form in 3D at the microscopic scale. The software is dedicated to profilometers, 3D light microscopes (\"MountainsMap\"), scanning electron microscopes (\"MountainsSEM\") and scanning probe microscopes (\"MountainsSPIP\").", "title": "MountainsMap", "category": "Data analysis software"}
{"text": "Cellebrite Mobile Synchronization is an Israeli company that manufactures data extraction, transfer and analysis devices for cellular phones and mobile devices. The company is a subsidiary of Japan's Sun Corporation.", "title": "Cellebrite", "category": "Data analysis software"}
{"text": "Christopher Granger Atkeson (born 1959) is an American roboticist and a Professor at the Robotics Institute and Human-Computer Interaction Institute at Carnegie Mellon University (CMU). Atkeson is known for his work in humanoid robots, soft robotics, and machine learning, most notably on locally weighted learning.", "title": "Christopher G. Atkeson", "category": "Machine learning researchers"}
{"text": "A growing self-organizing map (GSOM) is a growing variant of a self-organizing map (SOM). The GSOM was developed to address the issue of identifying a suitable map size in the SOM. It starts with a minimal number of nodes (usually 4) and grows new nodes on the boundary based on a heuristic. By using the value called Spread Factor (SF), the data analyst has the ability to control the growth of the GSOM.\nAll the starting nodes of the GSOM are boundary nodes, i.e. each node has the freedom to grow in its own direction at the beginning. (Fig. 1) New Nodes are grown from the boundary nodes. Once a node is selected for growing all its free neighboring positions will be grown new nodes. The figure shows the three possible node growth options for a rectangular GSOM.", "title": "Growing self-organizing map", "category": "Machine learning algorithms"}
{"text": "Multilinear subspace learning is an approach to dimensionality reduction.M. A. O. Vasilescu, D. Terzopoulos (2003) \"Multilinear Subspace Analysis of Image Ensembles\", \"Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR\u201903), Madison, WI, June, 2003\"M. A. O. Vasilescu, D. Terzopoulos (2002) \"Multilinear Analysis of Image Ensembles: TensorFaces\",  Proc. 7th European Conference on Computer Vision (ECCV'02), Copenhagen, Denmark, May, 2002M. A. O. Vasilescu,(2002) \"Human Motion Signatures: Analysis, Synthesis, Recognition\", \"Proceedings of International Conference on Pattern Recognition (ICPR 2002), Vol. 3, Quebec City, Canada, Aug, 2002, 456\u2013460.\"   \nDimensionality reduction can be performed on a data tensor whose observations have been vectorized and organized into a data tensor, or whose observations are matrices that are concatenated into a data tensor.X. He, D. Cai, P. Niyogi, Tensor subspace analysis, in: Advances in Neural Information Processing Systemsc 18 (NIPS), 2005.  Here are some examples of data tensors whose observations are vectorized  or whose observations are matrices concatenated into data tensor images (2D/3D), video sequences (3D/4D), and hyperspectral cubes (3D/4D).\n\nThe mapping from a high-dimensional vector space to a set of lower dimensional vector spaces is a multilinear projection.\n\nMultilinear subspace learning algorithms are higher-order generalizations of linear subspace learning methods such as principal component analysis (PCA), independent component analysis (ICA), linear discriminant analysis (LDA) and canonical correlation analysis (CCA).", "title": "Multilinear subspace learning", "category": "Machine learning"}
{"text": "Rexer Analytics\u2019s Annual Data Miner Survey is the largest survey of data mining, data science, and analytics professionals in the industry. It consists of approximately 50 multiple choice and open-ended questions that cover seven general areas of data mining science and practice:  (1) Field and goals, (2) Algorithms, (3) Models, (4) Tools (software packages used), (5) Technology, (6) Challenges, and (7) Future.  It is conducted as a service (without corporate sponsorship) to the data mining community, and the results are usually announced at the PAW (Predictive Analytics World) conferences and shared via freely available summary reports.  In the 2013 survey, 1259 data miners from 75 countries participated.Karl Rexer, Heather Allen, & Paul Gearan (2011); 2011 Data Miner Survey Summary'', presented at Predictive Analytics World, Oct. 2011.  After 2011, Rexer Analytics moved to a biannual schedule.", "title": "Rexer's Annual Data Miner Survey", "category": "Data mining"}
{"text": "Andrew McCallum is a professor and researcher in the computer science department at University of Massachusetts Amherst. His primary specialties are in machine learning, natural language processing, information extraction, information integration, and social network analysis.", "title": "Andrew McCallum", "category": "Machine learning researchers"}
{"text": "DataScene is a scientific graphing, animation, data analysis, and real-time data monitoring software package.M. Bedford, \"How To Create High-quality Graphs and Charts\", Computer Shopper Magazine, p. 135, Issue 273 (2010).L. G. Rubin. \"Focus On Software: Graphing Software\", Physics Today, p. 62, 62(7) (2009) It was developed with the Common Language Infrastructure technology and the GDI+ graphics library. With the two Common Language Runtime engines - the .Net and Mono frameworks - DataScene runs on all major operating systems.\n\nWith DataScene, the user can plot 39 types 2D & 3D graphs (e.g., Area graph, Bar graph, Boxplot graph, Pie graph, Line graph, Histogram graph, Surface graph, Polar graph, Water Fall graph, etc.), manipulate, print, and export graphs to various formats (e.g., Bitmap, WMF/EMF, JPEG, PNG, GIF, TIFF, PostScript, and PDF), analyze data with different mathematical methods (fitting curves, calculating statics, FFT, etc.), create chart animations for presentations (e.g. with Powerpoint), classes, and web pages, and monitor and chart real-time data.", "title": "DataScene", "category": "Data analysis software"}
{"text": "Grapheur is a data mining, modeling, optimization and interactive visualization package implementing the \n\"Learning and Intelligent Optimization\" (LION) and LIONsolver approach.Roberto Battiti and Mauro Brunato, Reactive Business Intelligence. From Data to Models to Insight, Reactive Search Srl, Italy, February 2011. .", "title": "Grapheur", "category": "Data analysis software"}
{"text": "i2 Limited was the UK-based arm of software company i2 Group which produced visual intelligence and investigative analysis software for military intelligence, law enforcement and commercial agencies. After a number of acquisitions, in 2011 it became part of IBM.", "title": "I2 Limited", "category": "Data analysis software"}
{"text": "Moose is a free and open source platform for software and data analysis built in Pharo.\n\nMoose offers multiple services ranging from importing and parsing data, to modeling, to measuring, querying, mining, and to building interactive and visual analysis tools. Moose was born in a research context,Oscar Nierstrasz, St\u00e9phane Ducasse, and Tudor G\u00eerba. The Story of Moose: an Agile Reengineering Environment. In Proceedings of the European Software Engineering Conference (ESEC/FSE'05), p. 1\u201410, ACM Press, New York NY, 2005. Invited paper. and it is currently supported by several research groups throughout the world. It is increasingly being adopted in industry.", "title": "Moose (analysis)", "category": "Data analysis software"}
{"text": "EgoNet (Egocentric Network Study Software) for the collection and analysis of egocentric social network data.http://egonet.softpedia.com/ Download EgoNet free It helps the user to collect and analyse all the egocentric network data (all social network data of a website on the Internet), and provide general global network measures and data matrixes that can be used for further analysis by other software. The egonet is the result of the links that it gives and receives certain address on the Internet,http://www.vidadigital.net/blog/2005/11/09/egonet-y-redes-sociales/ EgoNet and social networks - DigiZen and EgoNet is dedicated to collecting information about them and present it in a way useful to the users.\n\nEgonet is written in Java, so that the computer where it is going to be used must have the JRE installed. EgoNet is open source software, licensed under GPL.http://sourceforge.net/projects/egonet/ EgoNet - Download EgoNet software for free at SourceForge.net\n\nIts creator is Professor Christopher McCarty, of the University of Florida, United States.\nhttp://escoladeredes.ning.com/profiles/blogs/egonet-1 EGONET - Escola de Redes", "title": "EgoNet", "category": "Data analysis software"}
{"text": "In computer science, a ball tree, balltree or metric tree, is a space partitioning data structure for organizing points in a multi-dimensional space. The ball tree gets its name from the fact that it partitions data points into a nested set of hyperspheres known as \"balls\". The resulting data structure has characteristics that make it useful for a number of applications, most notably nearest neighbor search.", "title": "Ball tree", "category": "Machine learning"}
{"text": "Julie Beth Lovins was a computational linguist who first published a stemming algorithm for word matching in 1968.\nThe Lovins Stemmer is a single pass, context sensitive stemmer, which removes endings based on the longest-match principle. The stemmer was the first to be published and was extremely well developed considering the date of its release and has been the main influence on a large amount of the future work in the area. -Adam G., et al", "title": "Julie Beth Lovins", "category": "Machine learning researchers"}
{"text": "The life-time of correlation measures the timespan over which there is appreciable autocorrelation or cross correlation in stochastic processes.", "title": "Life-time of correlation", "category": "Machine learning"}
{"text": "Sepp Hochreiter (born Josef Hochreiter in 1967) is a German computer scientist. Since 2018 he is heading the Institute for Machine Learning at the Johannes Kepler University of Linz after having led the Institute of Bioinformatics from 2006 to 2018. Since 2017 he is also head of the Linz Institute of Technology (LIT) AI Lab which focuses on advancing research on artificial intelligence. Previously, he was at the Technical University of Berlin, at the University of Colorado at Boulder, and at the Technical University of Munich.\n\nSepp Hochreiter has made numerous contributions in the fields of machine learning, deep learning and bioinformatics. He developed the long short-term memory (LSTM) for which the first results were reported in his diploma thesis in 1991. The main LSTM paper appeared in 1997 and is considered as a discovery that is a milestone in the timeline of machine learning. The foundation of deep learning were led by his analysis of the vanishing or exploding gradient. He contributed to meta learning and proposed flat minima as preferable solutions of learning artificial neural networks to ensure a low generalization error. He developed new activation functions for neural networks like exponential linear units (ELUs)\n or scaled ELUs (SELUs) to improve learning. He contributed to reinforcement learning via actor-critic approaches\n and his RUDDER method. He applied biclustering methods to drug discovery and toxicology. He extended support vector machines to handle kernels that are not positive definite with the \"Potential Support Vector Machine\" (PSVM) model, and applied this model to feature selection, especially to gene selection for microarray data. Also in biotechnology, he developed \"Factor Analysis for Robust Microarray Summarization\" (FARMS).\n\nIn addition to his research contributions, Sepp Hochreiter is  broadly active within his field: he launched the Bioinformatics Working Group at the Austrian Computer Society; he is founding board member of different bioinformatics start-up companies; he was program chair of the conference Bioinformatics Research and Development; he is a conference chair of the conference Critical Assessment of Massive Data Analysis (CAMDA); and he is editor, program committee member, and reviewer for international journals and conferences. As a faculty member at Johannes Kepler Linz, he founded the Bachelors Program in Bioinformatics, which is a cross-border, double-degree study program together with the University of South-Bohemia in \u010cesk\u00e9 Bud\u011bjovice (Budweis), Czech Republic. He also established the Masters Program in Bioinformatics, \nwhere he is still the acting dean of both studies.", "title": "Sepp Hochreiter", "category": "Machine learning researchers"}
{"text": "Anne O'Tate  is a free, web-based application  that analyses sets of records identified on PubMed, the bibliographic database of articles from over 5,500 biomedical journals worldwide. While PubMed has its own wide range of search options to identify sets of records relevant to a researchers query it lacks the ability to analyse these sets of records further, a process for which the terms text mining and  drill down have been used. Anne O'Tate is able to perform such analysis and can process sets of up to 25,000 PubMed records.", "title": "Anne O'Tate", "category": "Data mining and machine learning software"}
{"text": "In machine learning, a hyperparameter is a parameter whose value is set before the learning process begins. By contrast, the values of other parameters are derived via training.\n\nDifferent model training algorithms require different hyperparameters, some simple algorithms (such as ordinary least squares regression) require none. Given these hyperparameters, the training algorithm learns the parameters from the data. For instance, LASSO is an algorithm that adds a regularization hyperparameter to ordinary least squares regression, which has to be set before estimating the parameters through the training algorithm.", "title": "Hyperparameter (machine learning)", "category": "Machine learning"}
{"text": "Epi Map is a module that displays geographic maps with data from Epi Info. Epi Map is built around the Esri MapObjects software. Epi Map displays shapefiles containing the geographic boundaries layered with data results from the Analysis module.\n\nEpi Map is designed to show data from Epi Info 2000 files by relating data fields to SHAPE files containing the geographic boundaries. Shapefiles also can contain data on population or other variables, and can therefore provide numeric data that become part of the display either as numerator or denominator.Dean, Andrew G. et al. Epi Info 2000 Manual \u2013 Epi Info 2000 , A Database, and Statistics Program for Public Health Professionals. Centers for Disease Control and Prevention (CDC) Atlanta, Georgia, USA", "title": "Epi Map", "category": "Data analysis software"}
{"text": "Waffles is a collection of command-line tools for performing machine learning operations developed at Brigham Young University. These tools are written in C++, and are available under the GNU Lesser General Public License.", "title": "Waffles (machine learning)", "category": "Data mining and machine learning software"}
{"text": "InfiniteGraph is an enterprise distributed graph database implemented in Java, and is from a class of NOSQL (or Not Only SQL) database technologies that focus on graph data structures. Developers use Infinitegraph to find useful and often hidden relationships in highly connected big data sets.\n InfiniteGraph is cross-platform, scalable, cloud enabled, and is designed to handle very high throughput.\n\n\n\nInfiniteGraph is suited for applications and services that solve graph problems or answer questions such as \"How am I connected to Kevin Bacon?\" or \"What are the cheapest roundtrip flights from California to New York with no more than 2 stops, at least 30 minutes between flights, and that depart at 8am Tuesday and return by 6pm Friday?\"\n\nAdoption is seen in government, telco/networking, healthcare, cyber security, manufacturing, finance, CRM, and social networking applications.", "title": "InfiniteGraph", "category": "Data analysis software"}
{"text": "The Mathematical Biosciences Institute (MBI) is an institution of higher learning affiliated with the Ohio State University in Columbus, Ohio.MBI Home PageNSF Math Institutes MBI received major funding from the National Science Foundation. The institute offers a vigorous program of research and education, and fosters the growth of an international community of researchers in the mathematical biosciences.", "title": "Mathematical Biosciences Institute", "category": "Data analysis"}
{"text": "Tom Michael Mitchell (born August 9, 1951) is an American computer scientist and E. Fredkin University Professor at the Carnegie Mellon University (CMU). He is a former Chair of the Machine Learning Department at CMU. Mitchell is known for his contributions to the advancement of machine learning, artificial intelligence, and cognitive neuroscience and is the author of the textbook Machine Learning. He is a member of the United States National Academy of Engineering since 2010. He is also a Fellow of the American Association for the Advancement of Science and a Fellow the Association for the Advancement of Artificial Intelligence. In October 2018, Mitchell was appointed as the Interim Dean of the School of Computer Science at Carnegie Mellon.", "title": "Tom M. Mitchell", "category": "Machine learning researchers"}
{"text": "Scikit-learn (formerly scikits.learn) is a free software machine learning library for the Python programming language.\nIt features various classification, regression and clustering algorithms including support vector machines, random forests, gradient boosting, k-means and DBSCAN, and is designed to interoperate with the Python numerical and scientific libraries NumPy and SciPy.", "title": "Scikit-learn", "category": "Data mining and machine learning software"}
{"text": "Turi is a graph-based, high performance, distributed computation framework written in C++. The GraphLab project was started by Prof. Carlos Guestrin of Carnegie Mellon University in 2009. It is an open source project using an Apache License. While GraphLab was originally developed for Machine Learning tasks, it has found great success at a broad range of other data-mining tasks; out-performing other abstractions by orders of magnitude.Joseph Gonzalez, Yucheng Low, Haijie Gu, Danny Bickson, Carlos Guestrin (2012). \"PowerGraph: Distributed Graph-Parallel Computation on Natural Graphs.\" Proceedings of Operating Systems Design and Implementation (OSDI).Yucheng Low, Joseph Gonzalez, Aapo Kyrola, Danny Bickson, Carlos Guestrin and Joseph M. Hellerstein (2012). \"Distributed GraphLab: A Framework for Machine Learning and Data Mining in the Cloud.\" Proceedings of Very Large Data Bases (PVLDB).", "title": "GraphLab", "category": "Data mining and machine learning software"}
{"text": "The Dehaene\u2013Changeux model (DCM), also known as the global neuronal workspace or the global cognitive workspace model is a part of Bernard Baars's \"global workspace model\" for consciousness.\n\nIt is a computer model of the neural correlates of consciousness programmed as a neural network. It attempts to reproduce the swarm behaviour  of the brain's higher cognitive functions such as consciousness, decision-makingDehaene S, Changeux JP. Reward-dependent learning in neuronal networks for planning and decision making. Prog Brain Res. 2000;126:217-29. and the central executive functions. It was developed by cognitive neuroscientists Stanislas Dehaene and Jean-Pierre Changeux beginning in 1986.Dehaene S, Changeux JP. Experimental and theoretical approaches to conscious processing. Neuron. 2011 Apr 28;70(2):200-27. It has been used to provide a predictive framework to the study of inattentional blindness and the solving of the Tower of London test.Changeux JP, Dehaene S. Hierarchical neuronal modeling of cognitive functions: from synaptic transmission to the Tower of London. Comptes Rendus de l'Acad\u00e9mie des Sciences, S\u00e9rie III. 1998 Feb\u2013Mar;321(2\u20133):241-7.Dehaene S, Changeux JP, Nadal JP. Neural networks that learn temporal sequences by selection. Proc Natl Acad Sci U S A. 1987 May;84(9):2727-31.", "title": "Dehaene\u2013Changeux model", "category": "Machine learning algorithms"}
{"text": "Corinna Cortes is a Danish computer scientist known for her contributions to machine learning. She is currently the Head of Google Research, New York. Cortes is a recipient of the Paris Kanellakis Theory and Practice Award for her work on theoretical foundations of support vector machines.", "title": "Corinna Cortes", "category": "Machine learning researchers"}
{"text": "Gremlin is a graph traversal language and virtual machine developed by Apache TinkerPop of the Apache Software Foundation. Gremlin works for both OLTP-based graph databases as well as OLAP-based graph processors. Gremlin's automata and functional language foundation enable Gremlin to naturally support imperative and declarative querying, host language agnosticism, user-defined domain specific languages, an extensible compiler/optimizer, single- and multi-machine execution models, hybrid depth- and breadth-first evaluation, as well as Turing Completeness.\n\nAs an explanatory analogy, Apache TinkerPop and Gremlin are to graph databases what the JDBC and SQL are to relational databases. Likewise, the Gremlin traversal machine is to graph computing as what the Java virtual machine is to general purpose computing.", "title": "Gremlin (programming language)", "category": "Data mining and machine learning software"}
{"text": "Stability, also known as algorithmic stability, is a notion in computational learning theory of how a  machine learning algorithm is perturbed by small changes to its inputs. A stable learning algorithm is one for which the prediction does not change much when the training data is modified slightly. For instance, consider a machine learning algorithm that is being trained to recognize handwritten letters of the alphabet, using 1000 examples of handwritten letters and their labels (\"A\" to \"Z\") as a training set. One way to modify this training set is to leave out an example, so that only 999 examples of handwritten letters and their labels are available. A stable learning algorithm would produce a similar classifier with both the 1000-element and 999-element training sets.\nStability can be studied for many types of learning problems, from language learning to inverse problems in physics and engineering, as it is a property of the learning process rather than the type of information being learned. The study of stability gained importance in computational learning theory in the 2000s when it was shown to have a connection with generalization. It was shown that for large classes of learning algorithms, notably empirical risk minimization algorithms, certain types of stability ensure good generalization.", "title": "Stability (learning theory)", "category": "Machine learning"}
{"text": "mlpy is a Python, open-source, machine learning library built on top of NumPy/SciPy, the GNU Scientific Library and it makes an extensive use of the Cython language. mlpy provides a wide range of state-of-the-art machine learning methods for supervised and unsupervised problems and it is aimed at finding a reasonable compromise among modularity, maintainability, reproducibility, usability and efficiency. mlpy is multiplatform, it works with Python 2 and 3 and it is distributed under GPL3.\n\nSuited for general-purpose machine learning tasks,Soleymani et al (2011). Continuous emotion detection in response to music videos. IEEE International Conference on Automatic Face & Gesture Recognition and Workshops 2011.Megies, T. et al (2011). ObsPy \u2013 What can it do for data centers and observatories? Annals of Geophysics, 2011.Nguyen, M. H (2010). Nguyen et al. Optimal feature selection for support vector machines. Pattern Recognition, 2010.Santana R. (2011) R. Santana. Estimation of distribution algorithms: from available implementations to potential developments. Proceedings of the 13th annual conference companion on Genetic and evolutionary computation, 2011. mlpy's motivating application field is bioinformatics, i.e. the analysis of high throughput omics data.Wuchty S. (2010). Gene pathways and subnetworks distinguish between major glioma subtypes and elucidate potential underlying biology. Journal of Biomedical Informatics, 2010", "title": "Mlpy", "category": "Data mining and machine learning software"}
{"text": "Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing, it is also known as data normalization and is generally performed during the data preprocessing step.", "title": "Feature scaling", "category": "Machine learning"}
{"text": "Skill chaining is a skill discovery method in continuous reinforcement learning.", "title": "Skill chaining", "category": "Machine learning algorithms"}
{"text": "MetaboAnalyst is a set of online tools for metabolomic data analysis and interpretation, created by members of the Wishart Research Group at the University of Alberta. It was first released in May 2009 and version 2.0 was released in January 2012. MetaboAnalyst provides a variety of analysis methods that have been tailored for metabolomic data. These methods include metabolomic data processing, normalization, multivariate statistical analysis, and data annotation. The current version is focused on biomarker discovery and classification.\nMetaboAnalyst supports a wide variety of data input types commonly generated by metabolomic studies including GC/LC-MS raw spectra, MS/NMR peak lists, NMR/MS peak intensity table, NMR/MS spectral bins, and metabolite concentrations.\n\nMetaboAnalyst has four modules:\n Data processing\n Statistical analysis (one-factor, two-factor, and time-series data)\n Functional enrichment analysis\n Metabolic pathway analysis\n\nThe table below summarizes the main features of each functional module. \n 1. Data Processing  2. Statistical Analysis  3. Functional Enrichment Analysis Peak detection  Univariate analysis  Over representation analysis  Retention time correction  Dimension reduction  Single sample profiling  Peak alignment  Feature selection  Quantitative enrichment analysis  Baseline filtering  Cluster analysis   Data integrity check  Classification  4. Metabolic Pathway Analysis Missing value imputation  Two-way ANOVA  Enrichment analysis   ASCA  Topology analysis   Temporal comparison  Interactive visualization\n\nMetaboAnalyst generates a PDF report that includes a written record of each analysis step and displays results in graphical and tabular format. Users can also download processed data files and PNG image files.\n\nMetaboAnalyst is part of a suite of metabolomics databases that also includes Human Metabolome Database (HMDB), HMDB DrugBank, DrugBank Toxin and Toxin-Target Database, T3DB and The Small Molecule Pathway Database. SMPDB The HMDB has over 7900 human metabolites and roughly 7200 associated DNA and protein sequences, that are linked to these metabolite entries. While DrugBank includes information on 6707 drugs and 4228 non-redundant drug targets, enzymes, transporters, and carriers, T3DB houses over 2900 common toxins and environmental pollutants. The suite is rounded out by SMPDB with its pathway diagrams for more than 350 human metabolic and disease pathways.", "title": "MetaboAnalyst", "category": "Data analysis software"}
{"text": "Vowpal Wabbit (also known as \"VW\") is an open-source fast out-of-core machine learning system library and program  developed originally at  Yahoo! Research, and currently at Microsoft Research.  It was started and is led by John Langford. Vowpal Wabbit is notable as an efficient scalable implementation of online machine learning with support for a number of machine learning reductions, importance weighting, and a selection of different loss functions and optimization algorithms.", "title": "Vowpal Wabbit", "category": "Data mining and machine learning software"}
{"text": "Heikki Mannila (born 1960) is a Finnish computer scientist, the president of the Academy of Finland.\nMannila earned his Ph.D. in 1985 from the University of Helsinki under the supervision of Esko UkkonenMathematical genealogy of Heikki Mannila from the International Association for Cryptologic Research, retrieved 2012-02-25. (who was President of the Academy of Finland) and for many years he was a professor at the University of Helsinki himself. From 2004 to 2008 he was Academy Professor at the Academy of Finland. He became Vice President for Academic Affairs at Aalto University in 2009, and was appointed by the Finnish government as president of the Academy of Finland for a term lasting from 2012 to 2017.Heikki Mannila appointed as President of the Academy of Finland , Finnish Ministry of Education and Culture, December 19, 2011, retrieved 2012-02-25.Heikki Mannila takes office as President of the Academy of Finland, University of Helsinki Computer Science Department, retrieved 2012-02-25. The appointment was renewed for the period 2017\u20132022.\n\nMannila is known for his research in data mining, and has published highly cited papers on association rule learning. . . and sequence mining.. With David Hand and Padhraic Smyth, he is the co-author of the book Principles of Data Mining (MIT Press, 2001).Review of Principles of Data Mining, Ashish P Sanil (2003), J. Amer. Stat. Assoc. 98 (461): 252\u2013253, .", "title": "Heikki Mannila", "category": "Machine learning researchers"}
{"text": "LIONsolver is an integrated software for data mining, business intelligence, analytics, and modeling \nLearning and Intelligent OptimizatioN\n and reactive business intelligence approach.\n A non-profit version is available as LIONoso.\n\nLIONsolver can be used to build models, visualize them, and improve business and engineering processes. \nIt is a tool for decision making based on data and quantitative models, it can be connected to most databases\nand external programs, it is fully integrated with the Grapheur business intelligence  software and intended for more advanced users, interested in designing business logic and processes and not only in simple analytics and visualization tasks.", "title": "LIONsolver", "category": "Data analysis software"}
{"text": "Yasuo Matsuyama (born March 23, 1947) is a Japanese researcher in machine learning and human-aware information processing.\n\nMatsuyama is a Professor Emeritus and an Honorary Researcher of the Research Institute of Science and Engineering of Waseda University.", "title": "Yasuo Matsuyama", "category": "Machine learning researchers"}
{"text": "Trevor John Hastie (born 27 June 1953) is a South African and American statistician and computer scientist. He is currently serving as the John A. Overdeck Professor of Mathematical Sciences and Professor of Statistics at the Stanford University. Hastie is known for his contributions to applied statistics, especially in the field of machine learning, data mining, and bioinformatics. He has authored several popular books in statistical learning, including The Elements of Statistical Learning: Data Mining, Inference, and Prediction. Hastie has been listed as an ISI Highly Cited Author in Mathematics by the ISI Web of Knowledge.", "title": "Trevor Hastie", "category": "Machine learning researchers"}
{"text": "In statistical learning theory, a representer theorem is any of several related results stating that a minimizer f^{*} of a regularized empirical risk functional defined over a reproducing kernel Hilbert space can be represented as a finite linear combination of kernel products evaluated on the input points in the training set data.", "title": "Representer theorem", "category": "Machine learning"}
{"text": "Symbolic data analysis (SDA) is an extension of standard data analysis where symbolic data tables are used as input and symbolic objects are made output as a result. The data units are called symbolic since they are more complex than standard ones, as they not only contain values or categories, but also include internal variation and structure. SDA is based on four spaces: the space of individuals, the space of concepts, the space of descriptions, and the space of symbolic objects. The space of descriptions models individuals, while the space of symbolic objects models concepts\n.", "title": "Symbolic data analysis", "category": "Data analysis"}
{"text": "SolveIT Software Pty Ltd is a provider of advanced planning and scheduling enterprise software for supply and demand optimisation and predictive modelling. Based in Adelaide, South Australia, 70% of its turnover is generated from software deployed in the mining and bulk material handling sectors.", "title": "SolveIT Software", "category": "Data mining and machine learning software"}
{"text": "Maltego is proprietary software used for open-source intelligence and forensics, developed by Paterva.  Maltego focuses on providing a library of transforms for discovery of data from open sources, and visualizing that information in a graph format, suitable for link analysis and data mining.\n\nMaltego permits creating custom entities, allowing it to represent any type of information in addition to the basic entity types which are part of the software.  The basic focus of the application is analyzing real-world relationships (social networks and computer network nodes) between people, groups, Webpages, domains, networks, internet infrastructure, and affiliations with online services such as Twitter and Facebook. Among its data sources are DNS records, whois records, search engines, online social networks, various APIs and various meta data.\n\nIt is used by security researchers and private investigators.", "title": "Maltego", "category": "Data analysis software"}
{"text": "CellCognition is a free open-source computational framework for quantitative analysis of high-throughput fluorescence microscopy (time-lapse) images in the field of bioimage informatics and systems microscopy. The CellCognition framework uses image processing, computer vision and machine learning techniques for single-cell tracking and classification of cell morphologies. This enables measurements of temporal progression of cell phases, modeling of cellular dynamics and generation of phenotype map.", "title": "CellCognition", "category": "Data mining and machine learning software"}
{"text": "VIGRA is the abbreviation for \"Vision with Generic Algorithms\". It is a free open-source computer vision library which focuses on customizable algorithms and data structures. VIGRA component can be easily adapted to specific needs of target application without compromising execution speed, by using template techniques similar to those in the C++ Standard Template Library.", "title": "VIGRA", "category": "Data mining and machine learning software"}
{"text": "ilastik  is a user-friendly free open source software for image classification and segmentation. No previous experience in image processing is required to run the software.", "title": "Ilastik", "category": "Data mining and machine learning software"}
{"text": "Google Flu Trends (GFT) was a web service operated by Google. It provided estimates of influenza activity for more than 25 countries. By aggregating Google Search queries, it attempted to make accurate predictions about flu activity. This project was first launched in 2008 by Google.org to help predict outbreaks of flu.\n\nGoogle Flu Trends is now no longer publishing current estimates. Historical estimates are still available for download, and current data are offered for declared research purposes.", "title": "Google Flu Trends", "category": "Data analysis software"}
{"text": "Random indexing is a dimensionality reduction method and computational framework for distributional semantics, based on the insight that very-high-dimensional vector space model implementations are impractical, that models need not grow in dimensionality when new items (e.g. new terminology) are encountered, and that a high-dimensional model can be projected into a space of lower dimensionality without compromising L2 distance metrics if the resulting dimensions are chosen appropriately.\nThis is the original point of the random projection approach to dimension reduction first formulated as the Johnson\u2013Lindenstrauss lemma, and locality-sensitive hashing has some of the same starting points. Random indexing, as used in representation of language, originates from the work of Pentti KanervaKanerva, Pentti, Kristoferson, Jan and Holst, Anders (2000): Random Indexing of Text Samples for Latent Semantic Analysis, Proceedings of the 22nd Annual Conference of the Cognitive Science Society, p.\u00a01036. Mahwah, New Jersey: Erlbaum, 2000.Sahlgren, Magnus (2005) An Introduction to Random Indexing, Proceedings of the Methods and Applications of Semantic Indexing Workshop at the 7th International Conference on Terminology and Knowledge Engineering, TKE 2005, August 16, Copenhagen, DenmarkSahlgren, Magnus, Holst, Anders and Pentti Kanerva (2008) Permutations as a Means to Encode Order in Word Space, In Proceedings of the 30th Annual Conference of the Cognitive Science Society: 1300-1305.Kanerva, Pentti (2009) Hyperdimensional Computing: An Introduction to Computing in Distributed Representation with High-Dimensional Random Vectors, Cognitive Computation, Volume 1, Issue 2, pp. 139\u2013159.Joshi, Aditya, Johan Halseth, and Pentti Kanerva. \"Language Recognition using Random Indexing.\" arXiv preprint arXiv:1412.7026 (2014). on sparse distributed memory, and can be described as an incremental formulation of a random projection.Recchia, Gabriel, et al. \"Encoding sequential information in vector space models of semantics: Comparing holographic reduced representation and random permutation.\" (2010): 865-870.\n\nIt can be also verified that random indexing is a random projection technique for the construction of Euclidean spaces\u2014i.e. L2 normed vector spaces.Qasemi Zadeh, Behrang & Handschuh, Siegrfied. (2014) Random Manhattan Indexing, In Proceedings of the 25th International Workshop on Database and Expert Systems Applications. In Euclidean spaces, random projections are elucidated using the Johnson\u2013Lindenstrauss lemma.\nJohnson, W. and Lindenstrauss, J. (1984) Extensions of Lipschitz mappings into a Hilbert space, in Contemporary Mathematics. American Mathematical Society, vol. 26, pp. 189\u2013206.\n\n\nThe TopSig techniqueGeva, S. & De Vries, C.M. (2011) TopSig: Topology Preserving Document Signatures, In Proceedings of Conference on Information and Knowledge Management 2011, 24-28 October 2011, Glasgow, Scotland. extends the random indexing model to produce bit vectors for comparison with the Hamming distance similarity function. It is used for improving the performance of information retrieval and document clustering. In a similar line of research, Random Manhattan Integer Indexing (RMII)Qasemi Zadeh, Behrang. & Handschuh, Siegfried. (2014) random Manhattan integer indexing: Incremental L1 Normed Vector Space Construction, In Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), pages 1713\u20131723,\nOctober 25-29, 2014, Doha, Qatar. is proposed for improving the performance of the methods that employ the Manhattan distance between text units. Many random indexing methods primarily generate similarity from co-occurrence of items in a corpus. Reflexive Random Indexing (RRI) Cohen T., Schvaneveldt Roger & Widdows Dominic (2009) Reflective Random Indexing and indirect inference: a scalable method for discovery of implicit connections, Journal of Biomedical Informatics, 43(2):240-56. generates similarity from co-occurrence and from shared occurrence with other items.", "title": "Random indexing", "category": "Machine learning"}
{"text": "Data Analysis Expressions (DAX) is the native formula and query language for Microsoft PowerPivot, Power BI Desktop and SQL Server Analysis Services (SSAS) Tabular models. DAX includes some of the functions that are used in Excel formulas with additional functions that are designed to work with relational data and perform dynamic aggregation. It is, in part, an evolution of the Multidimensional Expression (MDX) language developed by Microsoft for Analysis Services multidimensional models (often called cubes) combined with Excel formula functions. It is designed to be simple and easy to learn, while exposing the power and flexibility of PowerPivot and SSAS tabular models.", "title": "Data analysis expressions", "category": "Data analysis software"}
{"text": "The universal portfolio algorithm is a portfolio selection algorithm from the field of machine learning and information theory. The algorithm learns adaptively from historical data and maximizes the log-optimal growth rate in the long run. It was introduced by the late Stanford University information theorist Thomas M. Cover.\n\nThe algorithm rebalances the portfolio at the beginning of each trading period. At the beginning of the first trading period it starts with a naive diversification. In the following trading periods the portfolio composition depends on the historical total return of all possible constant-rebalanced portfolios.", "title": "Universal portfolio algorithm", "category": "Machine learning"}
{"text": "Astrostatistics is a discipline which spans astrophysics, statistical analysis and data mining. Astrostatistics and Astroinformatics Portal It is used to process the vast amount of data produced by automated scanning of the cosmos, to characterize complex datasets, and to link astronomical data to astrophysical theory.  Many branches of statistics are involved in astronomical analysis including nonparametrics, multivariate regression and multivariate classification, time series analysis, and especially Bayesian inference.", "title": "Astrostatistics", "category": "Machine learning"}
{"text": "DIVADIVA homepage (Data-Interpolating Variational Analysis) allows the spatial interpolation/gridding of data (analysis) in an optimal way, comparable to optimal interpolation (OI), taking into account uncertainties on observations. In comparison to standard OI, used in Data assimilation, DIVA, when applied to ocean data, takes into account coastlines, sub-basins and advection because of its variational formulation on the real domain.DIVA formulation Calculations are highly optimized and rely on a finite element resolution. Tools to generate the finite element mesh are provided as well as tools to optimize the parameters of the analysis. Quality control of data can be performed and error fields can be calculated.Troupin, C, Barth, A, Sirjacobs, D, Ouberdous, M, Brankart, J.-M, Brasseur, P, Rixen, M, Alvera Azcarate, A, Belounis, M, Capet, A, Lenartz, F, Toussaint, M.-E, & Beckers, J.-M. (2012). Generation of analysis and consistent error fields using the Data Interpolating Variational Analysis (Diva). Ocean Modelling, 52-53, 90-101. doi:10.1016/j.ocemod.2012.05.002 Also detrending of data is possible. Finally 3D and 4D extensions are included with emphasis on direct computations of climatologies from ODVODV homepage  spreadsheet files.\nThe software whose first version was available since 1996,Brasseur, P., Beckers, J.-M., Brankart, J.-M., and Schoenauen, R. (1996a). Seasonal temperature and salinity fields in the Mediterranean Sea: Climatological analyses of an historical data set. Deep-Sea Research, 43(2):159-192. can now be downloaded at the DIVA site and is the reference tool for calculating climatologies within the SeaDataNet projects. It has also been included as the state-of-the art gridding method in Ocean Data View.", "title": "DIVA software", "category": "Data analysis software"}
{"text": "Pipeline Pilot is a desktop software program developed by Accelrys Enterprise Platform to process and analyze data. Originally used in the natural sciences, the product's basic ETL (Extract, transform, load) and analytics capabilities have been broadened. The product is now used for data science, ETL, reporting, prediction and analytics in a number of sectors. The main feature of the product is the ability to design data workflows using a graphical user interface. The program is an example of visual and dataflow programming. It has use in a variety of settings, such as  cheminformatics and QSAR, Next Generation Sequencing, image analysis, and text analytics.", "title": "Pipeline Pilot", "category": "Data mining and machine learning software"}
{"text": "Julia is a high-level general-purpose dynamic programming language designed for high-performance numerical analysis and computational science.  It is also useful for low-level systems programming, as a specification language, with work being done on client and server web use. \n\nDistinctive aspects of Julia's design include a type system with parametric polymorphism and types in a fully dynamic programming language and multiple dispatch as its core programming paradigm. It allows concurrent, parallel and distributed computing, and direct calling of C and Fortran libraries without glue code. A just-in-time compiler that is referred to as \"just-ahead-of-time\" in the Julia community is used.\n\nJulia is garbage-collected, uses eager evaluation, and includes efficient libraries for floating-point calculations, linear algebra, random number generation, and regular expression matching. Many libraries are available, including some (e.g., for fast Fourier transforms) that were previously bundled with Julia and are now separate.(now available with using FFTW in current versions; that dependency is one of many moved out of the standard library to a package because it is GPL licensed, and thus is not included in Julia 1.0 by default.) \n\nTools available for Julia include IDEs; with integrated tools, e.g. a linter, debugger, and the Rebugger.jl package \"supports repeated-execution debugging\" and more.", "title": "Julia (programming language)", "category": "Data mining and machine learning software"}
{"text": "Oren Etzioni (b. 1964) is an American entrepreneur, professor of computer science, and CEO of the Allen Institute for Artificial Intelligence. He joined the University of Washington faculty in 1991, where he became the Washington Research Foundation Entrepreneurship Professor in the Department of Computer Science and Engineering. In May 2005, he founded and became the director of the university's Turing Center. The center investigates problems in data mining, natural language processing, the Semantic Web and other web search topics. Etzioni coined the term machine reading and created the first commercial comparison shopping agent.", "title": "Oren Etzioni", "category": "Machine learning researchers"}
{"text": "Dlib is a general purpose cross-platform software library written in the programming language C++. Its design is heavily influenced by ideas from design by contract and component-based software engineering. Thus it is, first and foremost, a set of independent software components. It is open-source software released under a Boost Software License.\n\nSince development began in 2002, Dlib has grown to include a wide variety of tools. As of 2016, it contains software components for dealing with networking, threads, graphical user interfaces, data structures, linear algebra, machine learning, image processing, data mining, XML and text parsing, numerical optimization, Bayesian networks, and many other tasks. In recent years, much of the development has been focused on creating a broad set of statistical machine learning tools and in 2009 Dlib was published in the Journal of Machine Learning Research. Since then it has been used in a wide range of domains.Scholarly research using DlibDlib on mloss.orgAutonome Mobile Systeme 2009ESS: Extremely Simple Serialization for C++Yan, Junchi, et al. \"Online incremental regression for electricity price prediction.\" Service Operations and Logistics, and Informatics (SOLI), 2012 IEEE International Conference on. IEEE, 2012. Kuijf, Hugo J., Max A. Viergever, and Koen L. Vincken. \"Automatic Extraction of the Curved Midsagittal Brain Surface on MR Images.\" Medical Computer Vision. Recognition Techniques and Applications in Medical Imaging. Springer Berlin Heidelberg, 2013. 225-232. Bormann, Richard Klaus Eduard. \"Vision-based place categorization.\" (2010).Brodu, Nicolas, and Dimitri Lague. \"3D terrestrial lidar data classification of complex natural scenes using a multi-scale dimensionality criterion: Applications in geomorphology.\" ISPRS Journal of Photogrammetry and Remote Sensing 68 (2012): 121\u2013134.Aung, Zeyar, et al. \"Towards accurate electricity load forecasting in smart grids.\" DBKDA 2012, The Fourth International Conference on Advances in Databases, Knowledge, and Data Applications. 2012.Rodriguez, Alberto, et al. \"Abort and retry in grasping.\" Intelligent Robots and Systems (IROS), 2011 IEEE/RSJ International Conference on. IEEE, 2011. Mohan, Vandana, et al. \"Intraoperative prediction of tumor cell concentration from Mass Spectrometry Imaging.\" Int. Symp. Math. Theo. Netw. Syst. 2010.Nakashima, Yuta, Noboru Babaguchi, and Jianping Fan. \"Detecting intended human objects in human-captured videos.\" Computer Vision and Pattern Recognition Workshops (CVPRW), 2010 IEEE Computer Society Conference on. IEEE, 2010. ", "title": "Dlib", "category": "Data mining and machine learning software"}
{"text": "Rayid Ghani is the Director of the Center for Data Science and Public Policy, Research Associate Professor in the Department of Computer Science, and a Senior Fellow at the Harris School of Public Policy at the  University of Chicago. He was also the co-founder of Edgeflip, an analytics startup that grew out of the Obama 2012 Campaign, focused on social media products for non-profits, advocacy groups, and charities.\n\nGhani started and runs the Eric & Wendy Schmidt Data Science for Social Good Summer Fellowship,  at the University of Chicago.", "title": "Rayid Ghani", "category": "Machine learning researchers"}
{"text": "In numerical mathematics, artificial precision is a source of error that occurs when a numerical value or semantic is expressed with more precision than was initially provided from measurement or user input.\nFor example, a person enters their birthday as the date 1984-01-01 but it is stored in a database as 1984-01-01T00:00:00Z which introduces the artificial precision of the hour, minute, and second they were born, and may even affect the date, depending on the user's actual place of birth. This is also an example of false precision, which is artificial precision specifically of numerical quantities or measures.", "title": "Artificial precision", "category": "Data analysis"}
{"text": "Data-informed decision-making (DIDM) gives reference to the collection and analysis of data to guide decisions that improve success.U.S. Department of Education Office of Planning, Evaluation and Policy Development (2009). Implementing data-informed decision making in schools: Teacher access, supports and use. United States Department of Education (ERIC Document Reproduction Service No. ED504191) DIDM is used in education communities (where data is used with the goal of helping students and improving curricula) but is also applicable to (and thus also used in) other fields in which data is used to inform decisions. While data based decision making is a more common term, data-informed decision-making is a preferable term since decisions should not be based solely on quantitative data.Knapp, M. S., Swinnerton, J. A., Copland, M. A., & Monpas-Hubar, J. (2006). Data-informed leadership in education. Seattle, WA: Center for the Study of Teaching and Policy. Most educators have access to a data system for the purpose of analyzing student data.Aarons, D. (2009).   Report finds states on course to build pupil-data systems. Education Week, 29(13), 6. These data systems present data to educators in an over-the-counter data format (embedding labels, supplemental documentation, and a help system, making key package/display and content decisions) to improve the success of educators\u2019 data-informed decision-making.Rankin, J. (2013, March 28). How data Systems & reports can either fight or propagate the data analysis error epidemic, and how educator leaders can help. Presentation conducted from Technology Information Center for Administrative Leadership (TICAL) School Leadership Summit. In Business, fostering and actively supporting DIDM in their firm and among their colleagues could be the main r\u00f4le of CIOs (Chief Information Officers) or CDOs (Chief Data Officers).Delort P. 2012. ICCP Technology Foresight Forum - \"Harnessing data as a new source of growth: Big data analytics and policies\" . OECD, 2012\n\nAssessment in higher education is a form of DIDM aimed at using evidence of what students learn to improve curriculum, student learning, and teaching. Standardized tests, grades, and student work scored by rubrics are forms of student learning outcomes assessment. There are numerous organizations aimed at promoting the assessment of student learning through DIDM including the National Institute for Learning Outcomes Assessment, the Association for the Assessment of Student Learning in Higher Education, and, to an extent, the Association of American Colleges and Universities.", "title": "Data-informed decision-making", "category": "Data analysis"}
{"text": "Massive Online Analysis (MOA) is a free open-source software project specific for data stream mining with concept drift. It is written in Java and developed at the University of Waikato, New Zealand.", "title": "Massive Online Analysis", "category": "Data mining and machine learning software"}
{"text": "Jubatus is an open-source online machine learning and distributed computing framework that is developed at Nippon Telegraph and Telephone and Preferred Infrastructure. Jubatus has many features like classification, recommendation, regression, anomaly detection, and graph mining.\nIt supports many client languages C++, Java, Ruby, and Python.\nJubatus uses Iterative Parameter MixtureRyan McDonald, K. Hall and G. Mann, Distributed Training Strategies for the Structured Perceptron, North American Association for Computational Linguistics (NAACL), 2010.Gideon Mann, R. McDonald, M. Mohri, N. Silberman, and D. Walker, Efficient Large-Scale Distributed Training of Conditional Maximum Entropy Models, Neural Information Processing Systems (NIPS), 2009. for distributed machine learning.", "title": "Jubatus", "category": "Data mining and machine learning software"}
{"text": "Tanagra is a free suite of machine learning software for research and academic purposes\ndeveloped by Ricco Rakotomalala at the Lumi\u00e8re University Lyon 2, France.\nTanagra supports several standard data mining tasks such as: Visualization, Descriptive statistics, Instance selection, feature selection, feature construction, regression, factor analysis, clustering, classification and association rule learning.\n\nTanagra is an academic project. It is widely used in French-speaking universities.G. Gregoire, F.X. Jollois, J.F. Petiot, A. Qannari, S. Sabourin, P. Swertwaegher, J.C. Turlot, V. Vandewalle, S. Viguier-Pla, \"Software and statistics teaching in STID department of IUT\", in Statistique et Enseignement, 2(2), 5-24, 2011. Tanagra is frequently used in real studiesS.G. Jacob and R.G. Ramani, \"Evolving Efficient Clustering and Classification Patterns in Lymphography Data through Data Mining Techniques\", in International Journal on Soft Computing (IJSC), 3(3), 119-132, 2012.E. Kirkos, C. Spathis, A. Nanopoulos, Y. Manolopoulos, \"Identifying Qualified Auditor's Opinions: A Data Mining Approach\", in Journal of Emerging Technologies in Accounting, 4(1), 183-197, 2007. and in software comparison papers.R.M. Rahman and F. Afroz, \"Comparison of Various Classification Techniques Using Different Data Mining Tools for Diabete Diagnosis\", in Journal of Software Engineering and Applications, 6, 85-97, 2013.H. Solanki \"Comparative Study of Data Mining Tools and Analysis with Unified Data Mining Theory\", in International Journal of Computer Applications, 75(16), 23-28, 2013.", "title": "Tanagra (machine learning)", "category": "Data mining and machine learning software"}
{"text": "Programming with Big Data in R (pbdR) is a series of R packages and an environment for statistical computing with big data by using high-performance statistical computation. The pbdR uses the same programming language as R with S3/S4 classes and methods which is used among statisticians and data miners for developing statistical software. The significant difference between pbdR and R code is that pbdR mainly focuses on distributed memory systems, where data are distributed across several processors and analyzed in a batch mode, while communications between processors are based on MPI that is easily used in large high-performance computing (HPC) systems. R system mainly focuses on single multi-core machines for data analysis via an interactive mode such as GUI interface.\n\nTwo main implementations in R using MPI are Rmpi and pbdMPI of pbdR.\n The pbdR built on pbdMPI uses SPMD parallelism where every processor is considered as worker and owns parts of data. The SPMD parallelism introduced in mid 1980 is particularly efficient in homogeneous computing environments for large data, for example, performing singular value decomposition on a large matrix, or performing clustering analysis on high-dimensional large data. On the other hand, there is no restriction to use manager/workers parallelism in SPMD parallelism environment.\n The Rmpi uses manager/workers parallelism where one main processor (manager) servers as the control of all other processors (workers). The manager/workers parallelism introduced around early 2000 is particularly efficient for large tasks in small clusters, for example, bootstrap method and Monte Carlo simulation in applied statistics since i.i.d. assumption is commonly used in most statistical analysis. In particular, task pull parallelism has better performance for Rmpi in heterogeneous computing environments.\nThe idea of SPMD parallelism is to let every processor do the same amount of work, but on different parts of a large data set. For example, a modern GPU is a large collection of slower co-processors that can simply apply the same computation on different parts of relatively smaller data, but the SPMD parallelism ends up with an efficient way to obtain final solutions (i.e. time to solution is shorter). It is clear that pbdR is not only suitable for small clusters, but is also more stable for analyzing big data and more scalable for supercomputers. In short, pbdR\n does not like Rmpi,  nor parallel packages in R,\n does not focus on interactive computing nor master/workers,\n but is able to use both SPMD and task parallelisms.", "title": "Programming with Big Data in R", "category": "Data mining and machine learning software"}
{"text": "H2O is open-source software for big-data analysis. It is produced by the company H2O.ai. H2O allows users to fit thousands of potential models as part of discovering patterns in data.\n\nThe H2O software runs can be called from the statistical package R, Python, and other environments. It is used for exploring and analyzing datasets held in cloud computing systems and in the Apache Hadoop Distributed File System as well as in the conventional operating-systems Linux, macOS, and Microsoft Windows. The H2O software is written in Java, Python, and R. Its graphical-user interface is compatible with four browsers: Chrome, Safari, Firefox, and Internet Explorer.", "title": "H2O (software)", "category": "Data mining and machine learning software"}
{"text": "REDIRECT Training, validation, and test sets#Validation set \nCategory:Machine learning", "title": "Validation set", "category": "Machine learning"}
{"text": "icCube is a company founded in Switzerland that provides business intelligence software of the same name. The solution can be fully embedded as an integrated solution, can be hosted in a managed environment or installed locally, on premises.\n\nThe BI tool allows end-users to create or edit dashboards themselves and is capable of processing data from multiple sources in real-time. The solution distinguishes itself by making the dashboards, the dashboard builder, the schema/cube builder and the server monitoring application accessible from a browser only. No software has to be installed at the device of the end-user.\n\nNext to the browser-based dashboard builder, data can be accessed by running queries directly on the OLAP cube using MDX, SQL or R.", "title": "IcCube", "category": "Data analysis software"}
{"text": "LIBSVM and LIBLINEAR are two popular open source machine learning libraries, both developed at the National Taiwan University and both written in C++ though with a C API. LIBSVM implements the Sequential minimal optimization (SMO) algorithm for kernelized support vector machines (SVMs), supporting classification and regression.\nLIBLINEAR implements linear SVMs and logistic regression models trained using a coordinate descent algorithm.\n\nThe SVM learning code from both libraries is often reused in other open source machine learning toolkits, including GATE, KNIME, Orange and scikit-learn.\nBindings and ports exist for programming languages such as Java, MATLAB, R, and Python.\n\nBoth libraries are free software released under the 3-clause BSD license.", "title": "LIBSVM", "category": "Data mining and machine learning software"}
{"text": "Apache Flume is a distributed, reliable, and available software for efficiently collecting, aggregating, and moving large amounts of log data. It has a simple and flexible architecture based on streaming data flows. It is robust and fault tolerant with tunable reliability mechanisms and many failover and recovery mechanisms. It uses a simple extensible data model that allows for online analytic application.", "title": "Apache Flume", "category": "Data mining and machine learning software"}
{"text": "The Wolfram Language is a general multi-paradigm computational language developed by Wolfram Research and is the programming language of the mathematical symbolic computation program Mathematica and the Wolfram Programming Cloud. It emphasizes symbolic computation, functional programming, and rule-based programming and can employ arbitrary structures and data.\n\nIt includes built-in functions for generating and running Turing machines, creating graphics and audio, analyzing 3D models, matrix manipulations, and solving differential equations. It is extensively documented.\n\nWolfram Language's core principles that differentiate it from other programming languages includes a built-in knowledgebase, automation in the form of meta-algorithms and superfunctions, a coherently elegant design and structure, built-in natural language understanding, and representation of everything as a symbolic expression.https://www.wolfram.com/language/principles/\n\nThe Wolfram language was released for the Raspberry Pi in 2013 with the goal of making it free for all Raspberry Pi users. It was included in the recommended software bundle that the Raspberry Pi Foundation provides for beginners, which caused some controversy due to the Wolfram language's proprietary nature. Plans to port the Wolfram language to the Intel Edison were announced after the board's introduction at CES 2014. In 2019, a link was added to make Wolfram libraries compatible with the Unity game engine, giving game developers access to the language's high level functions.", "title": "Wolfram Language", "category": "Data mining and machine learning software"}
{"text": "Protein Complex Enrichment Analysis Tool is an online bioinformatics tool used to analyze high-throughput datasets (or small-scale datasets) using protein complex enrichment analysis. The tool uses a protein complex resource as the back end annotation data instead of conventional gene ontology- or pathway-based annotations. The tool incorporates several useful features in order to provide a comprehensive data-mining environment, including network-based visualization and interactive querying options.\nCOMPLEAT may be used to analyze RNAi screens, proteomic datasets, gene expression data and any other high-throughput datasets where protein complex information is relevant.", "title": "COMPLEAT (Bioinformatics tool)", "category": "Data analysis software"}
{"text": "Lise Getoor is a professor in the Computer Science Department, at the University of California, Santa Cruz, and an adjunct professor in the Computer Science Department at the University of Maryland, College Park. \nHer primary research interests are in machine learning and reasoning with uncertainty, applied to graphs and structured data. \nShe also works in data integration, social network analysis and visual analytics. She has multiple best paper awards, an NSF Career Award, and is an Association for the Advancement of Artificial Intelligence (AAAI) Fellow. \nShe has edited a book on Statistical relational learning that is a main reference in this domain.\nShe has published many highly cited papers in academic journals and conference proceedings. \nShe has also served as action editor for the Machine Learning Journal, JAIR associate editor, and TKDD associate editor.  \nShe is a board member of the International Machine Learning Society, has been a member of AAAI Executive council, was PC co-chair of ICML 2011, and has served as senior PC member for conferences including AAAI, ICML, IJCAI, ISWC, KDD, SIGMOD, UAI, VLDB, WSDM and WWW.\n\nShe received her Ph.D. from Stanford University, her M.S. from UC Berkeley, and her B.S. from UC Santa Barbara.\nPrior to joining University of California, Santa Cruz, she was a professor at the University of Maryland, College Park until Nov 2013.", "title": "Lise Getoor", "category": "Machine learning researchers"}
{"text": "MagicPlot is a technical plotting, curve fitting and data analysis application. It provides a wide usage of the graphical user interface for data exploration as well as various statistical analysis tools, peak fitting options, raster or vector formats of publishable plots.\n\nMagicPlot is a commercial software. The limited functional trial version is also available.", "title": "MagicPlot", "category": "Data analysis software"}
{"text": "Jerome Harold Friedman (born December 29, 1939) is an American statistician, consultant and Professor of Statistics at Stanford University, known for his contributions in the field of statistics and data mining. Jerome H. Friedman Professor of Statistics. Accessed 18 July 2017. ", "title": "Jerome H. Friedman", "category": "Machine learning researchers"}
{"text": "In statistics and machine learning, the bias\u2013variance tradeoff is the property of a set of predictive models whereby models with a lower bias in parameter estimation have a higher variance of the parameter estimates across samples, and vice versa. The bias\u2013variance dilemma or problem is the conflict in trying to simultaneously minimize these two sources of error that prevent supervised learning algorithms from generalizing beyond their training set:\n The bias is an error from erroneous assumptions in the learning algorithm. High bias can cause an algorithm to miss the relevant relations between features and target outputs (underfitting).\n The variance is an error from sensitivity to small fluctuations in the training set. High variance can cause an algorithm to model the random noise in the training data, rather than the intended outputs (overfitting).\n\nThe bias\u2013variance decomposition is a way of analyzing a learning algorithm's expected generalization error with respect to a particular problem as a sum of three terms, the bias, variance, and a quantity called the irreducible error, resulting from noise in the problem itself.\n\nThis tradeoff applies to all forms of supervised learning: classification, regression (function fitting),Bias\u2013variance decomposition, In Encyclopedia of Machine Learning. Eds. Claude Sammut, Geoffrey I. Webb. Springer 2011. pp. 100\u2013101 and structured output learning. It has also been invoked to explain the effectiveness of heuristics in human learning.", "title": "Bias\u2013variance tradeoff", "category": "Machine learning"}
{"text": "In machine learning, the kernel embedding of distributions (also called the kernel mean or mean map) comprises a class of nonparametric methods in which a probability distribution is represented as an element of a reproducing kernel Hilbert space  (RKHS).A. Smola, A. Gretton, L. Song, B. Sch\u00f6lkopf. (2007). A Hilbert Space Embedding for Distributions. Algorithmic Learning Theory: 18th International Conference. Springer: 13\u201331.   A generalization of the individual data-point feature mapping done in classical kernel methods, the embedding of distributions into infinite-dimensional feature spaces can preserve all of the statistical features of arbitrary distributions, while allowing one to compare and manipulate distributions using Hilbert space operations such as inner products, distances, projections, linear transformations, and spectral analysis.L. Song, K. Fukumizu, F. Dinuzzo, A. Gretton (2013). Kernel Embeddings of Conditional Distributions: A unified kernel framework for nonparametric inference in graphical models. IEEE Signal Processing Magazine 30: 98\u2013111.    This learning framework is very general and can be applied to distributions over any space \\Omega  on which a sensible kernel function (measuring similarity between elements of \\Omega ) may be defined.  For example, various kernels have been proposed for learning from data which are: vectors in \\mathbb{R}^d, discrete classes/categories, strings, graphs/networks, images, time series, manifolds, dynamical systems, and other structured objects.J. Shawe-Taylor, N. Christianini. (2004). Kernel Methods for Pattern Analysis. Cambridge University Press, Cambridge, UK.T. Hofmann, B. Sch\u00f6lkopf, A. Smola. (2008). Kernel Methods in Machine Learning. The Annals of Statistics 36(3):1171\u20131220.  The theory behind kernel embeddings of distributions has been primarily developed by  Alex Smola, Le Song , Arthur Gretton, and Bernhard Sch\u00f6lkopf. A review of recent works on kernel embedding of distributions can be found in.\nThe analysis of distributions is fundamental in machine learning and statistics,  and many algorithms in these fields rely on information theoretic approaches such as entropy, mutual information, or Kullback\u2013Leibler divergence.  However, to estimate these quantities, one must first either perform density estimation, or employ sophisticated space-partitioning/bias-correction strategies which are typically infeasible for high-dimensional data.L. Song. (2008) Learning via Hilbert Space Embedding of Distributions. PhD Thesis, University of Sydney.  Commonly, methods for modeling complex distributions rely on parametric assumptions that may be unfounded or computationally challenging (e.g. Gaussian mixture models), while nonparametric methods like kernel density estimation (Note: the smoothing kernels in this context have a different interpretation than the kernels discussed here) or characteristic function representation (via the Fourier transform of the distribution) break down in high-dimensional settings.\n\nMethods based on the kernel embedding of distributions sidestep these problems and also possess the following advantages: \n Data may be modeled without restrictive assumptions about the form of the distributions and relationships between variables\n  Intermediate density estimation is not needed\n  Practitioners may specify the properties of a distribution most relevant for their problem (incorporating prior knowledge via choice of the kernel)\n If a characteristic kernel is used, then the embedding can uniquely preserve all information about a distribution, while thanks to the kernel trick, computations on the potentially infinite-dimensional RKHS can be implemented in practice as simple Gram matrix operations \n Dimensionality-independent rates of convergence for the empirical kernel mean (estimated using samples from the distribution)  to the kernel embedding of the true underlying distribution can be proven.\n Learning algorithms based on this framework exhibit good generalization ability and finite sample convergence, while often being simpler and more effective than information theoretic methods\nThus, learning via the kernel embedding of distributions offers a principled drop-in replacement for information theoretic approaches and is a framework which not only subsumes many popular methods in machine learning and statistics as special cases, but also can lead to entirely new learning algorithms.", "title": "Kernel embedding of distributions", "category": "Machine learning"}
{"text": "Quickprop is an iterative method for determining the minimum of the loss function of an artificial neural network, following an algorithm inspired by the Newton's method. Sometimes, the algorithm is classified to the group  of the second order learning methods. It follows a quadratic approximation of the previous gradient step and the current gradient, which is expected to be close to the minimum of the loss function, under the assumption that the loss function is locally approximately square, trying to describe it by means of an upwardly open parabola. The minimum is sought in the vertex of the parabola. The procedure requires only local information of the artificial neuron to which it is applied.The k-th approximation step is given by:\n\n \\Delta^{(k)} \\, w_{ij} = \\Delta^{(k-1)} \\, w_{ij} \\left ( \\frac{\\nabla_{ij} \\, E^{(k)}}{\\nabla_{ij} \\, E^{(k-1)} - \\nabla_{ij} \\, E^{(k)}} \\right) \n\nBeing  w_{ij}  the neuron j weight of its i input and E is the loss function.\n\nThe Quickprop algorithm is an implementation of the error backpropagation algorithm, but the network  can behave chaotically during the learning phase due to large step sizes.", "title": "Quickprop", "category": "Machine learning algorithms"}
{"text": "mlpack is a machine learning software library for C++, built on top of the Armadillo library. mlpack has an emphasis on scalability, speed, and ease-of-use. Its aim is to make machine learning possible for novice users by means of a simple, consistent API, while simultaneously exploiting C++ language features to provide maximum performance and maximum flexibility for expert users. Its intended target users are scientists and engineers.\n\nIt is open-source software distributed under the BSD license, making it useful for developing both open source and proprietary software. Releases 1.0.11 and before were released under the LGPL license.  The project is supported by the Georgia Institute of Technology and contributions from around the world.", "title": "Mlpack", "category": "Data mining and machine learning software"}
{"text": "Inductive programming (IP) is a special area of automatic programming, covering research from artificial intelligence and programming, which addresses learning of typically declarative (logic or functional) and often recursive programs from incomplete specifications, such as input/output examples or constraints.\n\nDepending on the programming language used, there are several kinds of inductive programming. Inductive functional programming, which uses functional programming languages such as Lisp or Haskell, and most especially inductive logic programming, which uses logic programming languages such as Prolog and other logical representations  such as description logics, have been more prominent, but other (programming) language paradigms have also been used, such as constraint programming or probabilistic programming.", "title": "Inductive programming", "category": "Machine learning"}
{"text": "The Teiresias algorithm is a combinatorial algorithm for the discovery of rigid patterns (motifs) in biological sequences. It is named after the Greek prophet Teiresias and was created in 1997 by Isidore Rigoutsos and Aris Floratos.Rigoutsos, I, Floratos, A (1998) Combinatorial pattern discovery in biological sequences: The TEIRESIAS algorithm. Bioinformatics 14: 55-67\nThe problem of finding sequence similarities in the primary structure of related proteins or genes arises in the analysis of biological sequences. It can be shown that pattern discovery in its general form is NP-hard.Maier, D., \"The Complexity of Some Problems on Subsequences and Supersequences\", Journal of the ACM, 322-336, 1978 The Teiresias algorithm is based on the observation that if a pattern spans many positions and appears exactly k times in the input then all fragments (sub patterns) of the pattern have to appear at least k times in the input. The algorithm is able to produce all patterns that have a user-defined number of copies in the given input, and manages to be very efficient by avoiding the enumeration of the entire space. Finally, the algorithm reports motifs that are maximal in both length and composition.\n\nA new implementation of the Teiresias algorithm was recently made available by the . Teiresias is also accessible through an interactive web-based user interface by the same center. See external links for both.", "title": "Teiresias algorithm", "category": "Data mining algorithms"}
{"text": "Qloo (pronounced \"clue\") is a company that uses artificial intelligence (AI) to understand taste and cultural correlations. It provides companies with an application programming interface (API). It received funding from Leonardo DiCaprio, Elton John, Barry Sternlicht, Pierre Lagrange and others.\n\nQloo establishes consumer preference correlations via machine learning across data spanning cultural domains including music, film, television, dining, nightlife, fashion, books and travel. The recommender system uses AI to predict correlations for further applications.", "title": "Qloo", "category": "Machine learning"}
{"text": "Nando de Freitas is a Professor of Computer Science at the University of Oxford. He is also a Fellow of Linacre College, Oxford. De Freitas is noted as an authority in the field of machine learning, and in particular in the subfields of neural networks, Bayesian inference and Bayesian optimization, and deep learning.", "title": "Nando de Freitas", "category": "Machine learning researchers"}
{"text": "A query-level feature or QLF is a ranking feature utilized in a machine-learned ranking algorithm.\nExample QLFs:\n How many times has this query been run in the last month?\n How many words are in the query?\n What is the sum/average/min/max/median of the BM25F values for the query?\n\nCategory:Machine learning algorithms", "title": "Query-level feature", "category": "Machine learning algorithms"}
{"text": "Text mining computer programs are available from many commercial and open source companies and sources.", "title": "List of text mining software", "category": "Data mining and machine learning software"}
{"text": "DADiSP (Data Analysis and Display, pronounced day-disp) is a numerical computing environment developed by DSP Development Corporation which allows one to display and manipulate data series, matrices and images with an interface similar to a spreadsheet. DADiSP is used in the study of signal processing, numerical analysis, statistical and physiological data processing.", "title": "DADiSP", "category": "Data mining and machine learning software"}
{"text": "OpenNN (Open Neural Networks Library) is a software library written in the C++ programming language which implements neural networks, a main area of deep learning research. The library is open-source, licensed under the GNU Lesser General Public License.", "title": "OpenNN", "category": "Data mining and machine learning software"}
{"text": "Apache Spark is an open-source distributed general-purpose cluster-computing framework. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance. Originally developed at the University of California, Berkeley's AMPLab, the Spark codebase was later donated to the Apache Software Foundation, which has maintained it since.", "title": "Apache Spark", "category": "Data mining and machine learning software"}
{"text": "Kernel methods are a well-established tool to analyze the relationship between input data and the corresponding output of a function. Kernels encapsulate the properties of functions in a computationally efficient way and allow algorithms to easily swap functions of varying complexity.\nIn typical machine learning algorithms, these functions produce a scalar output. Recent development of kernel methods for functions with vector-valued output is due, at least in part, to interest in simultaneously solving related problems. Kernels which capture the relationship between the problems allow them to borrow strength from each other. Algorithms of this type include multi-task learning (also called multi-output learning or vector-valued learning), transfer learning, and co-kriging. Multi-label classification can be interpreted as mapping inputs to (binary) coding vectors with length equal to the number of classes.\n\nIn Gaussian processes, kernels are called covariance functions. Multiple-output functions correspond to considering multiple processes. See Bayesian interpretation of regularization for the connection between the two perspectives.", "title": "Kernel methods for vector output", "category": "Machine learning algorithms"}
{"text": "SensoMotoric Instruments (SMI)SMI company . SMI. Retrieved March 13, 2017. is a German provider of dedicated computer vision applications with a major focus on eye tracking technology. SMI was founded in 1991 as a spin-off from academic and medical research at the Free University of Berlin. The company has its headquarters in Teltow near Berlin, Germany, offices in Boston, Massachusetts and San Francisco, California, in the United States, and a worldwide distributor and partner network.\n\nSMI provided eye tracking systems for scientific research, professional solutions and OEM applications. The eye trackers can be combined with motion tracking systems,Ben Coxworth (May 9, 2014) Two-part system tracks body movement and gaze. Gizmag. Retrieved April 17, 2015. EEG, Emotiv and SMI Combine Remote Eye Tracking and EEG: A Perfect Match! . Reuters. Retrieved April 3, 2014.Hisham Abboud (January 4, 2014)  New: Cedrus Introduces StimTracker for SMI Eye Trackers. Cedrus. Retrieved April 3, 2014. and other biometric data.SensoMotoric Instruments and Noldus Information Technology combine eye tracking and video analysis. Noldus. Retrieved April 2, 2014. They can be integrated into virtual reality CAVEs,Ben Lang (February 8, 2013) SMI Introduces 3D Glasses With Eye Tracking. Road to VR. Retrieved April 3, 2014. head-mounted displays - such as Google GlassSMI Gaze Interaction Powers Google Glass Prototype . Reuters. Retrieved April 17, 2015.Stephen Hall (April 16, 2015). SMI\u2019s Google Glass eye-tracking prototype is impressive. Google Glass Fans. Retrieved April 17, 2015. or Oculus Rift,Jamie Feltham (November 17, 2014). SMI Launches Oculus Rift Eye Tracking Upgrade Package. VR Focus. Retrieved April 17, 2015.Dave LeClair (November 21, 2014). SMI announces eye-tracking upgrade for Oculus Rift. Gizmag. Retrieved April 17, 2015.Oliver Kreylos (June 2, 2014). An Eye-tracked Oculus Rift. Doc-ok. Retrieved April 17, 2015. simulators, cars, or computers as a measurement or interaction modality.", "title": "SensoMotoric Instruments", "category": "Data analysis software"}
{"text": "Piranha is a text mining system developed for the United States Department of Energy (DOE) by Oak Ridge National Laboratory (ORNL).  The software processes large volumes of unrelated free-text documents and shows relationships amongst them, a technique valuable across numerous scientific and data domains, from health care fraud to national security.  The results are presented in clusters of prioritized relevance to business and government analysts. Piranha uses the term frequency/inverse corpus frequency term weighting method which provides strong parallel processing of textual information, thus the ability to analyze very large document sets.\nPiranha has six main strengths: \nCollecting and Extracting: Millions of documents from numerous sources such as databases and social media can be collected and text extracted from hundreds of file formats; This info. can then be translated to any number of languages.\nStoring and indexing: Documents in search servers, relational databases, etc. can be stored and indexed at will.\nRecommending: Recommending the most valuable information for particular users.\nCategorizing: Grouping items via supervised and semi-supervised machine learning methods and targeted search lists.\nClustering: Similarity is used to create a hierarchical group of documents.\nVisualizing: Showing relationships among documents so that users can quickly recognize connections.\n\nThis work has resulted in eight issued ( 9,256,649, 8,825,710, 8,473,314, 7,937,389, 7,805,446, 7,693,9037, 7,315,858, 7,072,883), and several commercial licenses (including TextOre and Pro2Serve), a spin-off company with the inventors, Covenant Health, and Pro2Serve called VortexT Analytics, two R&D 100 Awards, and scores of peer reviewed research publications.", "title": "Piranha (software)", "category": "Data mining and machine learning software"}
{"text": "Ben Taskar (March 3, 1977 \u2013 November 18, 2013) was a professor and researcher in the area of machine learning and applications to computational linguistics and computer vision.  He was a Magerman Term Associate Professor for Computer and Information Science at University of Pennsylvania. He co-directed PRiML: Penn Research in Machine Learning, a joint venture between the School of Engineering and Wharton. He was also a Distinguished Research Fellow at the Annenberg Center for Public Policy. At the University of Washington, he held the Boeing Professorship.\n\nHe was the first person to define Max-margin Markov networks and a pioneer in statistical relational learning.", "title": "Ben Taskar", "category": "Machine learning researchers"}
{"text": "Torch is an open-source machine learning library, \na scientific computing framework, and a script language based on the Lua programming language. It provides a wide range of algorithms for deep learning, and uses the scripting language LuaJIT, and an underlying C implementation. As of 2018, Torch is no longer in active development.Torch GitHub repository ReadMe", "title": "Torch (machine learning)", "category": "Data mining and machine learning software"}
{"text": "Inductive probability attempts to give the probability of future events based on past events. It is the basis for inductive reasoning, and gives the mathematical basis for learning and the perception of patterns. It is a source of knowledge about the world.\nThere are three sources of knowledge: inference, communication, and deduction. Communication relays information found using other methods.  Deduction establishes new facts based on existing facts.  Only inference establishes new facts from data.\n\nThe basis of inference is Bayes' theorem. But this theorem is sometimes hard to apply and understand. The simpler method to understand inference is in terms of quantities of information.\n\nInformation describing the world is written in a language. For example, a simple mathematical language of propositions may be chosen. Sentences may be written down in this language as strings of characters.  But in the computer it is possible to encode these sentences as strings of bits (1s and 0s). Then the language may be encoded so that the most commonly used sentences are the shortest. This internal language implicitly represents probabilities of statements.\n\nOccam's razor says the \"simplest theory, consistent with the data is most likely to be  correct\". The \"simplest theory\" is interpreted as the representation of the theory written in this internal language. The theory with the shortest encoding in this internal language is most likely to be correct.", "title": "Inductive probability", "category": "Machine learning"}
{"text": "Sisense is a business analytics software company with offices in New York City,  San Francisco, Tel Aviv, London, Melbourne, Tokyo, and Scottsdale, Arizona. Its business intelligence product includes both a back-end powered by in-chip technology that enables non-technical users to join and analyze large data sets from multiple sources, and a front-end for creating visualizations, like dashboards and reports, on any device, including mobile.", "title": "Sisense", "category": "Data analysis software"}
{"text": "Eclipse Deeplearning4j is a deep learning programming library written for Java and the Java virtual machine (JVM) and a computing framework with wide support for deep learning algorithms. Deeplearning4j includes implementations of the restricted Boltzmann machine, deep belief net, deep autoencoder, stacked denoising autoencoder and recursive neural tensor network, word2vec, doc2vec, and GloVe. These algorithms all include distributed parallel versions that integrate with Apache Hadoop and Spark.\n\nDeeplearning4j is open-source software released under Apache License 2.0, developed mainly by a machine learning group headquartered in San Francisco and Tokyo and led by Adam Gibson. It is supported commercially by the startup Skymind, which bundles DL4J, Tensorflow, Keras and other deep learning libraries in an enterprise distribution called the Skymind Intelligence Layer. Deeplearning4j was contributed to the Eclipse Foundation in October 2017.", "title": "Deeplearning4j", "category": "Data mining and machine learning software"}
{"text": "In data mining, the WINEPI algorithm is an influential algorithm for episode mining, which helps discover the knowledge hidden in an event sequence.\nWINEPI derives part of its name from the fact that it uses a sliding window to go through the event sequence.\n\nThe outcome of the algorithm are episode rules describe temporal relationships between events and form an extension of association rules.", "title": "WINEPI", "category": "Data mining algorithms"}
{"text": "Yooreeka is a library for data mining, machine learning, soft computing, and mathematical analysis. The project started with the code of the book \"Algorithms of the Intelligent Web\". Although the term \"Web\" prevailed in the title, in essence, the algorithms are valuable in any software application.\n\nIt covers all major algorithms and provides many examples.\n\nYooreeka 2.x is licensed under the Apache License rather than the somewhat more restrictive LGPL (which was the license of v1.x).\n\nThe library is written 100% in the Java language.", "title": "Yooreeka", "category": "Data mining and machine learning software"}
{"text": "Data exploration is an approach similar to initial data analysis, whereby a data analyst uses visual exploration to understand what is in a dataset and the characteristics of the data, rather than through traditional data management systemsFOSTER Open Science, Overview of Data Exploration Techniques: Stratos Idreos, Olga Papaemmonouil, Surajit Chaudhuri.. These characteristics can include size or amount of data, completeness of the data, correctness of the data, possible relationships amongst data elements or files/tables in the data.\nData exploration is typically conducted using a combination of automated and manual activities.Stanford.edu, 2011 Wrangler: Interactive Visual Specification of Data Transformation Scripts, Kandel, Paepcke, Hellerstein Heer. Automated activities can include data profiling or data visualization or tabular reports to give the analyst an initial view into the data and an understanding of key characteristics.FOSTER Open Science, Overview of Data Exploration Techniques: Stratos Idreos, Olga Papaemmonouil, Surajit Chaudhuri.\n\nThis is often followed by manual drill-down or filtering of the data to identify anomalies or patterns identified through the automated actions.  Data exploration can also require manual scripting and queries into the data (e.g. using languages such as SQL or R) or using Excel or similar tools to view the raw data.Stanford.edu, IEEE Visual Analytics Science & Technology (VAST), Oct 2012 Enterprise Data Analysis and Visualization: An Interview Study., Sean Kandel, Andreas Paepcke, Joseph Hellerstein, Jeffrey Heer Proc.\n\nAll of these activities are aimed at creating a clear mental model and understanding of the data in the mind of the analyst, and defining basic metadata (statistics, structure, relationships) for the data set that can be used in further analysis.FOSTER Open Science, Overview of Data Exploration Techniques: Stratos Idreos, Olga Papaemmonouil, Surajit Chaudhuri.\n\nOnce this initial understanding of the data is had, the data can be pruned or refined by removing unusable parts of the data, correcting poorly formatted elements and defining relevant relationships across datasets. This process is also known as determining data quality.\n\nData exploration can also refer to the ad hoc querying and visualization of data to identify potential relationships or insights that may be hidden in the data.\n\nTraditionally, this had been a key area of focus for statisticians, with John Tukey being a key evangelist in the field.  Exploratory Data Analysis, Pearson. . Today, data exploration is more widespread and is the focus of data analysts and data scientists; the latter being a relatively new role within enterprises and larger organizations.", "title": "Data exploration", "category": "Machine learning"}
{"text": "In machine learning, the vanishing gradient problem is a difficulty found in training artificial neural networks with gradient-based learning methods and backpropagation. In such methods, each of the neural network's weights receives an update proportional to the partial derivative of the error function with respect to the current weight in each iteration of training. The problem is that in some cases, the gradient will be vanishingly small, effectively preventing the weight from changing its value. In the worst case, this may completely stop the neural network from further training. As one example of the problem cause, traditional activation functions such as the hyperbolic tangent function have gradients in the range , and backpropagation computes gradients by the chain rule. This has the effect of multiplying  of these small numbers to compute gradients of the \"front\" layers in an -layer network, meaning that the gradient (error signal) decreases exponentially with  while the front layers train very slowly.\n\nBack-propagation allowed researchers to train supervised deep artificial neural networks from scratch, initially with little success. Hochreiter's diploma thesis of 1991S. Hochreiter. Untersuchungen zu dynamischen neuronalen Netzen. Diploma thesis, Institut f. Informatik, Technische Univ. Munich, 1991.S. Hochreiter, Y. Bengio, P. Frasconi, and J. Schmidhuber. Gradient flow in recurrent nets: the difficulty of learning long-term dependencies. In S. C. Kremer and J. F. Kolen, editors, A Field Guide to Dynamical Recurrent Neural Networks. IEEE Press, 2001. formally identified the reason for this failure in the \"vanishing gradient problem\", which not only affects many-layered feedforward networks, but also recurrent networks. The latter are trained by unfolding them into very deep feedforward networks, where a new layer is created for each time step of an input sequence processed by the network.\n\nWhen activation functions are used whose derivatives can take on larger values, one risks encountering the related exploding gradient problem.", "title": "Vanishing gradient problem", "category": "Machine learning"}
{"text": "Pietro Perona is the Allan E. Puckett Professor of Electrical Engineering and Computation and Neural Systems at the California Institute of Technology and director of the National Science Foundation Engineering Research Center in Neuromorphic Systems Engineering.\nHe is known for his research in computer vision and is the director of the Caltech Computational Vision Group.", "title": "Pietro Perona", "category": "Machine learning researchers"}
{"text": "Sketch Engine is a corpus manager and text analysis software developed by Lexical Computing Limited since 2003. Its purpose is to enable people studying language behaviour (lexicographers, researchers in  corpus linguistics, translators or language learners) to search large text collections according to complex and linguistically motivated queries. Sketch Engine gained its name after one of the key features, word sketches: one-page, automatic, corpus-derived summaries of a word's grammatical and collocational behaviour. Currently, it supports and provides corpora in 90+ languages.", "title": "Sketch Engine", "category": "Data mining and machine learning software"}
{"text": "Action model learning (sometimes abbreviated action learning) is an area of machine learning concerned with creation and modification of software agent's knowledge about effects and preconditions of the actions that can be executed within its environment. This knowledge is usually represented in logic-based action description language and used as the input for automated planners.\n\nLearning action models is important when goals change. When an agent acted for a while, it can use its accumulated knowledge about actions in the domain to make better decisions. Thus, learning action models differs from reinforcement learning. It enables reasoning about actions instead of expensive trials in the world.\n Action model learning is a form of inductive reasoning, where new knowledge is generated based on agent's observations. It differs from standard supervised learning in that correct input/output pairs are never presented, nor imprecise action models explicitly corrected.\n\nUsual motivation for action model learning is the fact that manual specification of action models for planners is often a difficult, time consuming, and error-prone task (especially in complex environments).", "title": "Action model learning", "category": "Machine learning"}
{"text": "In mathematics and statistics, random projection is a technique used to reduce the dimensionality of a set of points which lie in Euclidean space. Random projection methods are known for their power, simplicity, and low error rates when compared to other methods. According to experimental results, random projection preserves distances well, but empirical results are sparse.\nThey have been applied to many natural language tasks under the name random indexing.", "title": "Random projection", "category": "Machine learning"}
{"text": "Quantum machine learning is an emerging interdisciplinary research area at the intersection of quantum physics and machine learning.  The most common use of the term refers to machine learning algorithms for the analysis of classical data executed on a quantum computer. While machine learning algorithms are used to compute immense quantities of data, quantum machine learning increases such capabilities intelligently, by creating opportunities to conduct analysis on quantum states and systems. This includes hybrid methods that involve both classical and quantum processing, where computationally difficult subroutines are outsourced to a quantum device. These routines can be more complex in nature and executed faster with the assistance of quantum devices. Furthermore, quantum algorithms can be used to analyze quantum states instead of classical data. Beyond quantum computing, the term \"quantum machine learning\" is often associated with machine learning methods applied to data generated from quantum experiments, such as learning quantum phase transitions or creating new quantum experiments. Quantum machine learning also extends to a branch of research that explores methodological and structural similarities between certain physical systems and learning systems, in particular neural networks. For example, some mathematical and numerical techniques from quantum physics are applicable to classical deep learning and vice versa. Finally, researchers investigate more abstract notions of learning theory with respect to quantum information, sometimes referred to as \"quantum learning theory\".", "title": "Quantum machine learning", "category": "Machine learning"}
{"text": "Health care analytics is the healthcare analysis activities that can be undertaken as a result of data collected from four areas within healthcare; claims and cost data, pharmaceutical and research and development (R&D) data, clinical data (collected from electronic medical records (EHRs)), and patient behavior and sentiment data (patient behaviors and preferences, (retail purchases e.g. data captured in running stores). Health care analytics is a growing industry in the United States, expected to grow to more than $31 billion by 2022. The industry focuses on the areas of clinical analysis, financial analysis, supply chain analysis, as well as, fraud and HR analysis.\n\nHealth care analytics allows for the examination of patterns in various healthcare data in order to determine how clinical care can be improved while limiting excessive spending.", "title": "Health care analytics", "category": "Data analysis"}
{"text": "Fei-Fei Li (born 1976), who also publishes under the name Li Fei-Fei (), is a Professor of Computer Science at Stanford University. She is currently the Co-Director of Stanford University's Human-Centered AI Institute and the Stanford Vision and Learning Lab. She served as the director of the Stanford Artificial Intelligence Lab (SAIL) from 2013 to 2018. In 2017, she co-founded AI4ALL, a nonprofit organization working to increase diversity and inclusion in the field of artificial intelligence.  Her research expertise includes artificial intelligence (AI), machine learning, deep learning, computer vision and cognitive neuroscience. Li is one of the most prolific researchers in the field of AI. She was the leading scientist and principal investigator of ImageNet, a critical dataset and computer vision project that resulted in the recent deep learning revolution. ", "title": "Fei-Fei Li", "category": "Machine learning researchers"}
{"text": "The Bradley\u2013Terry model is a probability model that can predict the outcome of a paired comparison. Given a pair of individuals  and  drawn from some population, it estimates the probability that the pairwise comparison  turns out true, as\nP(i > j) = \\frac{p_i}{p_i + p_j}\n\nwhere  is a positive real-valued score assigned to individual . The comparison  can be read as \" is preferred to \", \" ranks higher than \", or \" beats \", depending on the application.\n\nFor example,  may represent the skill of a team in a sports tournament, estimated from the number of times  has won a match. P(i>j) then represents the probability that  will win a match against . Another example used to explain the model's purpose is that of scoring products in a certain category by quality. While it's hard for a person to draft a direct ranking of (many) brands of wine, it may be feasible to compare a sample of pairs of wines and say, for each pair, which one is better. The Bradley\u2013Terry model can then be used to derive a full ranking.", "title": "Bradley\u2013Terry model", "category": "Machine learning"}
{"text": "Social media mining is the process of obtaining big data from user-generated content on social media sites and mobile apps in order to extract patterns, form conclusions about users, and act upon the information, often for the purpose of advertising to users or conducting research. The term is an analogy to the resource extraction process of mining for rare minerals. Resource extraction mining requires mining companies to sift through vast quantities of raw ore to find the precious minerals; likewise, social media mining requires human data analysts and automated software programs to sift through massive amounts of raw social media data in order to discern patterns and trends relating to social media usage, online behaviours, sharing of content, connections between individuals, online buying behaviour, and more. These patterns and trends are of interest to companies, governments and not-for-profit organizations, as these organizations can use these patterns and trends to design their strategies or introduce new programs, new products, processes or services.\n\nSocial media mining uses a range of basic concepts from computer science, data mining, machine learning and statistics. Social media miners develop algorithms suitable for investigating massive files of social media data. Social media mining is based on theories and methodologies from  social network analysis, network science, sociology, ethnography, optimization and mathematics. It encompasses the tools to formally represent, measure and model meaningful patterns from large-scale social media data. In the 2010s, major corporations, governments and not-for-profit organizations engaged in social media mining to obtain data about customers, clients and citizens.", "title": "Social media mining", "category": "Data analysis"}
{"text": "In the field of statistical learning theory, matrix regularization generalizes notions of vector regularization to cases where the object to be learned is a matrix. The purpose of regularization is to enforce conditions, for example sparsity or smoothness, that can produce stable predictive functions. For example, in the more common vector framework, Tikhonov regularization optimizes over\n \\min_x \\|Ax - y\\|^2 + \\lambda \\|x\\|^2\n\nto find a vector x that is a stable solution to the regression problem. When the system is described by a matrix rather than a vector, this problem  can be written as\n\n \\min_X \\|AX - Y\\|^2 + \\lambda \\|X\\|^2,\n\nwhere the vector norm enforcing a regularization penalty on x has been extended to a matrix norm on X.\n\nMatrix regularization has applications in matrix completion, multivariate regression, and multi-task learning. Ideas of feature and group selection can also be extended to matrices, and these can be generalized to the nonparametric case of multiple kernel learning.", "title": "Matrix regularization", "category": "Machine learning"}
{"text": "In Machine Learning and Computer Vision, M-Theory is a learning framework inspired by feed-forward processing in the ventral stream of visual cortex and originally developed for recognition and classification of objects in visual scenes. M-Theory was later applied to other areas, such as speech recognition. On certain image recognition tasks, algorithms based on a specific instantiation of M-Theory, HMAX, achieved human-level performance.Serre T., Oliva A., Poggio T. (2007) A feedforward architecture accounts for rapid categorization. PNAS, vol. 104, no. 15, pp. 6424-6429\n\nThe core principle of M-Theory is extracting representations invariant to various transformations of images (translation, scale, 2D and 3D rotation and others). In contrast with other approaches using invariant representations, in M-Theory they are not hardcoded into the algorithms, but learned. M-Theory also shares some principles with Compressed Sensing. The theory proposes multilayered hierarchical learning architecture, similar to that of visual cortex.", "title": "M-Theory (learning framework)", "category": "Machine learning"}
{"text": "Multiple kernel learning refers to a set of machine learning methods that use a predefined set of kernels and learn an optimal linear or non-linear combination of kernels as part of the algorithm. Reasons to use multiple kernel learning include a) the ability to select for an optimal kernel and parameters from a larger set of kernels, reducing bias due to kernel selection while allowing for more automated machine learning methods, and b) combining data from different sources (e.g. sound and images from a video) that have different notions of similarity and thus require different kernels. Instead of creating a new kernel, multiple kernel algorithms can be used to combine kernels already established for each individual data source.\n\nMultiple kernel learning approaches have been used in many applications, such as event recognition in video,Lin Chen, Lixin Duan, and Dong Xu, \"Event Recognition in Videos by Learning From Heterogeneous Web Sources,\" in IEEE International Conference on Computer Vision and Pattern Recognition (CVPR), 2013, pp. 2666-2673 object recognition in images,Serhat S. Bucak, Rong Jin, and Anil K. Jain, Multiple Kernel Learning for Visual Object Recognition: A Review. T-PAMI, 2013. and biomedical data fusion.Yu et al. L2-norm multiple kernel learning and its application to biomedical data fusion. BMC Bioinformatics 2010, 11:309", "title": "Multiple kernel learning", "category": "Machine learning algorithms"}
{"text": "John D. Lafferty is an American scientist, Professor at Yale University and leading researcher in machine learning. He is best known for proposing the Conditional Random Fields with Andrew McCallum and Fernando C.N. Pereira.", "title": "John D. Lafferty", "category": "Machine learning researchers"}
{"text": "Eric Xing is a professor at Carnegie Mellon University and researcher in machine learning, computational biology, and statistical methodology.", "title": "Eric Xing", "category": "Machine learning researchers"}
{"text": "\n\nSmartPLS is a software with graphical user interface for variance-based structural equation modeling (SEM) using the partial least squares (PLS) path modeling method.Wong, K. K. K. (2013). Partial least squares structural equation modeling (PLS-SEM) techniques using SmartPLS. Marketing Bulletin, 24(1), pp. 1-32, p. 1, p. 15, and p. 30.Hair Jr, J. F., Hult, G. T. M., Ringle, C., & Sarstedt, M. (2016). A primer on partial least squares structural equation modeling (PLS-SEM), Thousand Oaks, CA: Sage Publications.Hair Jr, J. F., Sarstedt, M., Ringle, C. M., & Gudergan, S. P. (2017). Advanced issues in partial least squares structural equation modeling (PLS-SEM),Thousand Oaks, CA: Sage Publications. Besides estimating path models with latent variables using the PLS-SEM algorithm,Lohm\u00f6ller, J.-B. (1989). Latent Variable Path Modeling with Partial Least Squares. Physica: Heidelberg, p. 29.Wold, H. O. A. (1982). Soft Modeling: The Basic Design and Some Extensions, in: K. G. J\u00f6reskog and H. O. A. Wold (eds.), Systems Under Indirect Observations: Part II, North-Holland: Amsterdam, pp. 1-54, pp. 2-3. the software computes standard results assessment criteria (e.g., for the reflective and formative measurement models, the structural model, and the goodness of fit)Ramayah, T., Cheah, J., Chuah, F., Ting, H., and Memon, M. A. (2016). Partial Least Squares Structural Equation Modeling (PLS-SEM) Using SmartPLS 3.0: An Updated and Practical Guide to Statistical Analysis, Singapore et al.: Pearson, pp. 59-148. and it supports additional statistical analyses (e.g., confirmatory tetrad analysis, importance-performance map analysis, segmentation, multigroup).Garson, G. D. (2016). Partial Least Squares Regression and Structural Equation Models, Statistical Associates: Asheboro, pp. 122-188. Since SmartPLS is programmed in Java, it can be executed and run on different computer operating systems such as Windows and Mac.Temme, D., Kreis, H., and Hildebrandt, L. (2010). A Comparison of Current PLS Path Modeling Software: Features, Ease-of-Use, and Performance, in: V. Esposito Vinzi, W. W. Chin, J. Henseler, and H. Wang (eds.), Handbook of Partial Least Squares: Concepts, Methods and Applications, Springer: Berlin-Heidelberg, pp. 737-756, p.745.", "title": "SmartPLS", "category": "Data analysis software"}
{"text": "Archetypal analysis in the statistics is an unsupervised learning method similar to the cluster analysis and introduced by Adele Cutler and Leo Breiman in 1994. Rather than \"typical\" observations (cluster centers), it seeks extremal points in the multidimensional data, the \"archetypes\". The archetypes are convex combinations of observations chosen so that observations can be approximated by convex combinations of the archetypes.", "title": "Archetypal analysis", "category": "Data mining"}
{"text": "Adversarial machine learning is a technique employed in the field of machine learning which attempts to fool models through malicious input. This technique can be applied for a variety of reasons, the most common being to attack or cause a malfunction in standard machine learning models.\n\nMachine learning techniques were originally designed for stationary and benign environments in which the training and test data are assumed to be generated from the same statistical distribution. However, when those models are implemented in the real world, the presence of intelligent and adaptive adversaries may violate that statistical assumption to some degree, depending on the adversary. This technique shows how a malicious adversary can surreptitiously manipulate the input data so as to exploit specific vulnerabilities of learning algorithms and compromise the security of the machine learning system.", "title": "Adversarial machine learning", "category": "Machine learning"}
{"text": "ECU-TEST is a software tool developed by TraceTronic GmbH, based in Dresden, Germany, for test and validation of embedded systems. Since the first release of ECU-TEST in 2003,H.-C. Reuss, R. Deutschmann, J. Liebl, F. Munk, C. Schmidt: Automatic ECU Test with HiL-Simulation. 5th Stuttgart International Symposium on Automotive and Engine Technology\u201c. Expert, 2003. the software is used as standard tool in the development of automotive ECUsRocco Deutschmann, Frank G\u00fcnther, Matthias Roch, Hans-Christian Reuss, Frank Kessler, Wolfram Bohne, Carsten Krug: New strategies and solutions for automated test of embedded software. 6th Stuttgart International Symposium on Automotive and Engine Technology. Expert, 2005.Wolfgang Schl\u00fcter, Franz Dengler: HiL-Testsysteme f\u00fcr den BMW Hydrogen 7. 7th Conference on \u201eHardware-in-the-Loop-Simulation\u201c. Haus der Technik, 2007.Daniel Br\u00fcckner, Michael Kahle: OTX als Test- und Applikationssprache in der On-Board-Diagnose. 6th Conference on \u201eDiagnose in mechatronischen Fahrzeugsystemen\u201c. Expert, 2012. and increasingly in the development of heavy machineryThomas Neubert, Rocco Deutschmann: Automated software test using HiL technology. 13th ITI Symposium, 2010.Thomas Borchert, Rocco Deutschmann, Ren\u00e9 M\u00fcller, Andreas Abel, Torsten Blochwitz: Simulation and Testing of Off-Road Vehicles in Virtual Reality - Development of a Validation Framework for Multi-Purpose Vehicles. 13th ITI Symposium, 2010.Rocco Deutschmann, Ren\u00e9 M\u00fcller, Andreas Abel, Torsten Blochwitz: Simulation and Test of Multi-purpose Vehicles. ATZoffhighway, 2011. as well as in factory automation.Klaus Kabitzsch, Andr\u00e9 Gellrich, Jens Naake: Automatisierte Steuerungstests vereinfachen die virtuelle Inbetriebnahme in der Fabrikautomation. atp edition, 2012. The development of the software started within a research project on systematic testing of control units and laid the foundation for the spin-off of TraceTronic GmbH from TU Dresden.\nECU-TEST aims at the specification, implementation, documentation, execution and assessment of test cases. Owing to various test automation methods, the tool ensures an efficient implementation of all necessary activities for the creation, execution and assessment of test cases.Rocco Deutschmann: Semi-formal methods for the automated test of embedded systems. Doctoral thesis, TU Dresden, 2007.", "title": "ECU-TEST", "category": "Data analysis software"}
{"text": "Logic Learning Machine (LLM) is a machine learning method based on the generation of intelligible rules. LLM is an efficient implementation of the Switching Neural Network (SNN) paradigm, developed by Marco Muselli, Senior Researcher at the Italian National Research Council CNR-IEIIT in Genoa.\nLogic Learning Machine is implemented in the Rulex suite.\n\nLLM has been employed in different fields, including orthopaedic patient classification, DNA microarray analysis  and Clinical Decision Support System.", "title": "Logic learning machine", "category": "Machine learning"}
{"text": "Distributed R is an open source, high-performance platform for the R language. It splits tasks between multiple processing nodes to reduce execution time and analyze large data sets. Distributed R enhances R by adding distributed data structures, parallelism primitives to run functions on distributed data, a task scheduler, and multiple data loaders. It is mostly used to implement distributed versions of machine learning tasks. Distributed R is written in C++ and R, and retains the familiar look and feel of R. , Hewlett-Packard (HP) provides enterprise support for Distributed R with proprietary additions such as a fast data loader from the Vertica database.", "title": "Distributed R", "category": "Data mining and machine learning software"}
{"text": "Native-language identification (NLI) is the task of determining an author's native language (L1) based only on their writings in a second language (L2).Wong, Sze-Meng Jojo, and Mark Dras. \"Exploiting parse structures for native language identification\". Proceedings of the Conference on Empirical Methods in Natural Language Processing. Association for Computational Linguistics, 2011. NLI works through identifying language-usage patterns that are common to specific L1 groups and then applying this knowledge to predict the native language of previously unseen texts. This is motivated in part by applications in second-language acquisition, language teaching and forensic linguistics, amongst others.", "title": "Native-language identification", "category": "Machine learning"}
{"text": "Zeroth is a platform for brain-inspired computing from Qualcomm. It is based around a  (NPU) AI accelerator chip and a software API to interact with the platform. It makes a form of machine learning known as deep learning available to mobile devices. It is used for image and sound processing, including speech recognition. The software operates locally rather than as a cloud application.\nMobile chip maker Qualcomm announced in March 2015 that it would bundle the software with its next major mobile device chip, the Snapdragon 820 processor.", "title": "Zeroth (software)", "category": "Data mining and machine learning software"}
{"text": "In mathematics applied to the study of networks, the Wiener connector, named in honor of chemist Harry Wiener who first introduced the Wiener Index, is a means of maximizing efficiency in connecting specified \"query vertices\" in a network. Given a connected, undirected graph and a set of query vertices in a graph, the minimum Wiener connector is an induced subgraph that connects the query vertices and minimizes the sum of shortest path distances among all pairs of vertices in the subgraph. In combinatorial optimization, the minimum Wiener connector problem is the problem of finding the minimum Wiener connector. It can be thought of as a version of the classic Steiner tree problem (one of Karp's 21 NP-complete problems), where instead of minimizing the size of the tree, the objective is to minimize the distances in the subgraph.DIMACS Steiner Tree Challenge\n\nThe minimum Wiener connector was first presented by Ruchansky, et al. in 2015.\n\nThe minimum Wiener connector has applications in many domains where there is a graph structure and an interest in learning about connections between sets of individuals. For example, given a set of patients infected with a viral disease, which other patients should be checked to find the culprit? Or given a set of proteins of interest, which other proteins participate in pathways with them?", "title": "Wiener connector", "category": "Data mining"}
{"text": "Cubes is a light-weight open source multidimensional modelling and OLAP toolkit for development reporting applications and browsing of aggregated data written in Python programming language released under the MIT License.\n\nCubes provides to an analyst or any application end-user \"understandable and natural way of reporting using concept of data Cubes \u2013 multidimensional data objects\".\n\nCubes was first publicly released in March 2011. The project was originally developed for Public Procurements of Slovakia.Public Procurements of Slovakia by Transparency International Slovakia Cubes 1.0 was released in September 2014 and presented on the PyData Conference in New YorkCubes 1.0 Overview at PyData NYC 2014 (video).", "title": "Cubes (OLAP server)", "category": "Data analysis software"}
{"text": "Armin Bernd Cremers (born June 7, 1946 in Eisenach, Germany) is a German mathematician and computer scientist. He is a Prof. em. in the computer science institute at the University of Bonn, Germany. He is most notable for his contributions to several fields of discrete mathematics including formal languages and automata theory. In more recent years he has been recognized for his work in artificial intelligence, machine learning and robotics as well as in geoinformatics and deductive databases.", "title": "Armin B. Cremers", "category": "Machine learning researchers"}
{"text": "In machine learning, local case-control sampling  is an algorithm used to reduce the complexity of training a logistic regression classifier. The algorithm reduces the training complexity by selecting a small subsample of the original dataset for training. It assumes the availability of a (unreliable) pilot estimation of the parameters. It then performs a single pass over the entire dataset using the pilot estimation to identify the most \"surprising\" samples. In practice, the pilot may come from prior knowledge or training using a subsample of the dataset. The algorithm is most effective when the underlying dataset is imbalanced. It exploits the structures of conditional imbalanced datasets more efficiently than alternative methods, such as case control sampling and weighted case control sampling.", "title": "Local case-control sampling", "category": "Machine learning"}
{"text": "Neural Designer is a software tool for data analytics based on neural networks, a main area of artificial intelligence research, and contains a graphical user interface which simplifies data entry and interpretation of results.\n\nIn 2015, Neural Designer was chosen by the European Commission, within the Horizon 2020 program, as a disruptive technology in the ICT field.", "title": "Neural Designer", "category": "Data mining and machine learning software"}
{"text": "Salvatore J. Stolfo is a tenured professor of computer science at Columbia University in New York and a leading expert in computer security. He is known for his research in machine learning applied to computer security, intrusion detection systems, anomaly detection algorithms and systems, fraud detection, and parallel computing.", "title": "Salvatore J. Stolfo", "category": "Machine learning researchers"}
{"text": "REDIRECT Stochastic gradient descent#AdaGrad", "title": "Adagrad", "category": "Machine learning algorithms"}
{"text": "User behavior analytics (UBA) as defined by Gartner is a cybersecurity process about detection of insider threats, targeted attacks, and financial fraud. UBA solutions look at patterns of human behavior, and then apply algorithms and statistical analysis to detect meaningful anomalies from those patterns\u2014anomalies that indicate potential threats.Market Guide for User Behavior Analytics  Instead of tracking devices or security events, UBA tracks a system's users.The hunt for data analytics: Is your SIEM on the endangered list? Big data platforms like Apache Hadoop are increasing UBA functionality by allowing them to analyze petabytes worth of data to detect insider threats and advanced persistent threats.", "title": "User behavior analytics", "category": "Machine learning"}
{"text": "Error level analysis (ELA) is the analysis of compression artifacts in digital data with lossy compression such as JPEG.", "title": "Error level analysis", "category": "Data analysis"}
{"text": "ND4S is a free, open-source extension of the Scala programming language operating on the Java Virtual Machine \u2013 though it is compatible with both Java and Clojure.\n\nND4S is a scientific computing library for linear algebra and matrix manipulation in a production environment, integrating with Hadoop and Spark to work with distributed GPUs. It supports n-dimensional arrays for JVM-based languages.\n\nND4S has primarily been developed by the group in San Francisco that built Deeplearning4j, led by Adam Gibson. It was created under an Apache Software Foundation license.", "title": "ND4S", "category": "Data mining and machine learning software"}
{"text": "BisQue is a free, open source web-based platform for the exchange and exploration of large, complex datasets. It is being developed at the Vision Research Lab  Vision Research Lab Homepage at the University of California, Santa Barbara. BisQue specifically supports large scale, multi-dimensional multimodal-images and image analysis. Metadata is stored as arbitrarily nested and linked tag/value pairs, allowing for domain-specific data organization. Image analysis modules can be added to perform complex analysis tasks on compute clusters. Analysis results are stored within the database for further querying and processing. The data and analysis provenance is maintained for reproducibility of results. BisQue can be easily deployed in cloud computing environments or on computer clusters for scalability. BisQue has been integrated into the NSF Cyberinfrastructure project CyVerse.CyVerse Cyberinfrastructure Homepage The user interacts with BisQue via any modern web browser.", "title": "BisQue (Bioimage Analysis and Management Platform)", "category": "Data analysis software"}
{"text": "Fluentd is a cross platform open-source data collection software project originally developed at Treasure Data. It is written primarily in the Ruby programming language.", "title": "Fluentd", "category": "Data mining and machine learning software"}
{"text": "Poimapper is field data collection, sharing and analysing software.\n\nMobile application is used to collect data and update data. By uploading data to a cloud server it is shared among other mobile and office workers.\n\nPoimapper is developed by Pajat Solutions Ltd. Pajat Solutions was founded in 2009 and is headquartered in Finland. It creates mobile solutions for field reporting.https://www.crunchbase.com/organization/pajat-solutions. In 2013 Pajat was awarded the European CSR award for innovative, non-business partnerships that have helped to solve social problems while creating business advantage. The award came from a partnership where NGO's like Plan International were using Poimapper in their health-related monitoring and evaluation work.", "title": "Poimapper", "category": "Data analysis software"}
{"text": "Yoshua Bengio  (born 1964 in Paris, France) is a Canadian computer scientist, most noted for his work on artificial neural networks and deep learning. He was a co-recipient of the 2018 ACM A.M. Turing Award for his work in deep learning. He is a professor at the Department of Computer Science and Operations Research at the Universit\u00e9 de Montr\u00e9al and scientific director of the Montreal Institute for Learning Algorithms (MILA).", "title": "Yoshua Bengio", "category": "Machine learning researchers"}
{"text": "Pedro Domingos is Professor at University of Washington. He is a researcher in machine learning and known for markov logic network enabling uncertain inference.", "title": "Pedro Domingos", "category": "Machine learning researchers"}
{"text": "Dark data is data which is acquired through various computer network operations but not used in any manner to derive insights or for decision making. The ability of an organisation to collect data can exceed the throughput at which it can analyse the data. In some cases the organisation may not even be aware that the data is being collected. IBM estimate that roughly 90 percent of data generated by sensors and analog-to-digital conversions never get used.\nIn an industrial context, dark data can include information gathered by sensors and telematics.\n\nOrganizations retain dark data for a multitude of reasons, and it is estimated that most companies are only analyzing 1% of their data.The big data challenge of transformation for the manufacturing industry Often it is stored for regulatory complianceAre you using your dark data effectively and record keeping. Some organizations believe that dark data could be useful to them in the future, once they have acquired better analytic and business intelligence technology to process the information. Because storage is inexpensive, storing data is easy. However, storing and securing the data usually entails greater expenses (or even risk) than the potential return profit.", "title": "Dark data", "category": "Data analysis"}
{"text": "The stochastic block model is a generative model for random graphs. This model tends to produce graphs containing communities, subsets characterized by being connected with one another with particular edge densities. For example, edges may be more common within communities than between communities. The stochastic block model is important in statistics, machine learning, and network science, where it serves as a useful benchmark for the task of recovering community structure in graph data.", "title": "Stochastic block model", "category": "Machine learning"}
{"text": "The Master Algorithm: How the Quest for the Ultimate Learning Machine Will Remake Our World is a book by Pedro Domingos released in 2015. Domingos wrote the book in order to generate interest from people outside the field.\n\nThe book outlines five tribes of machine learning: inductive reasoning, connectionism, evolutionary computation, bayes theorem and analogical modelling. The author explains these tribes to the reader by referring to more understandable processes of logic, connections made in the brain, natural selection, probability and similarity judgements. Throughout the book, it is suggested that each different tribe has the potential to contribute to a unifying \"master algorithm\".\n\nTowards the end of the book the author pictures a \"master algorithm\" in the near future, where machine learning algorithms asymptotically grow to a perfect understanding of how the world and people in it work. Although the algorithm doesn't yet exist, he briefly reviews his own invention of the Markov logic network.", "title": "The Master Algorithm", "category": "Machine learning"}
{"text": "GB & Smith is an independent software editor which provides layer independent matrix-based console allowing instant visual review on any supported computing platform.", "title": "GB &amp; Smith", "category": "Data analysis software"}
{"text": "TensorFlow is a free and open-source software library for dataflow and differentiable programming across a range of tasks. It is a symbolic math library, and is also used for machine learning applications such as neural networks.\"TensorFlow: Open source machine learning\" \"It is machine learning software being used for various kinds of perceptual and language understanding tasks\" \u2014 Jeffrey Dean, minute 0:47 / 2:17 from YouTube clip It is used for both research and production at Google.\u2009\u2009\n\nTensorFlow was developed by the Google Brain team for internal Google use. It was released under the Apache License 2.0 on November 9, 2015.", "title": "TensorFlow", "category": "Data mining and machine learning software"}
{"text": "ILNumerics is a mathematical class library for Common Language Infrastructure (CLI) developers and a domain specific language (DSL) for the implementation of numerical algorithms on the .NET platform. While algebra systems with graphical user interfaces focus on prototyping of algorithms, implementation of such algorithms into distribution-ready applications is done using \ndevelopment environments and general purpose programming languages (GPL). ILNumerics is an extension to Visual Studio and aims at supporting the creation of technical applications based on .NET.", "title": "ILNumerics", "category": "Data analysis software"}
{"text": "Out-of-bag (OOB) error, also called out-of-bag estimate, is a method of measuring the prediction error of random forests, boosted decision trees, and other machine learning models utilizing bootstrap aggregating (bagging) to sub-sample data samples used for training. OOB is the mean prediction error on each training sample , using only the trees that did not have  in their bootstrap sample.\n\nSubsampling allows one to define an out-of-bag estimate of the prediction performance improvement by evaluating predictions on those observations which were not used in the building of the next base learner. Out-of-bag estimates help avoid the need for an independent validation dataset, but often underestimates actual performance improvement and the optimal number of iterations.", "title": "Out-of-bag error", "category": "Machine learning algorithms"}
{"text": "Sparse dictionary learning is a representation learning method which aims at finding a sparse representation of the input data (also known as sparse coding) in the form of a linear combination of basic elements as well as those basic elements themselves. These elements are called atoms and they compose a dictionary. Atoms in the dictionary are not required to be orthogonal, and they may be an over-complete spanning set. This problem setup also allows the dimensionality of the signals being represented to be higher than the one of the signals being observed. The above two properties lead to having seemingly redundant atoms that allow multiple representations of the same signal but also provide an improvement in sparsity and flexibility of the representation. \n\nOne of the most important applications of sparse dictionary learning is in the field of compressed sensing or signal recovery. In compressed sensing, a high-dimensional signal can be recovered with only a few linear measurements provided that the signal is sparse or nearly sparse. Since not all signals satisfy this sparsity condition, it is of great importance to find a sparse representation of that signal such as the wavelet transform or the directional gradient of a rasterized matrix. Once a matrix or a high dimensional vector is transferred to a sparse space, different recovery algorithms like basis pursuit, CoSaMP or fast non-iterative algorithmsLotfi, M.; Vidyasagar, M.\"A Fast Non-iterative Algorithm for Compressive Sensing Using Binary Measurement Matrices\" can be used to recover the signal. \n\nOne of the key principles of dictionary learning is that the dictionary has to be inferred from the input data. The emergence of sparse dictionary learning methods was stimulated by the fact that in signal processing one typically wants to represent the input data using as few components as possible. Before this approach the general practice was to use predefined dictionaries (such as fourier or wavelet transforms). However, in certain cases a dictionary that is trained to fit the input data can significantly improve the sparsity, which has applications in data decomposition, compression and analysis and has been used in the fields of image denoising and classification, video and audio processing. Sparsity and overcomplete dictionaries have immense applications in image compression, image fusion and inpainting.  ", "title": "Sparse dictionary learning", "category": "Machine learning"}
{"text": "Structured sparsity regularization is a class of methods, and an area of research in statistical learning theory, that extend and generalize sparsity regularization learning methods. Both sparsity and structured sparsity regularization methods seek to exploit the assumption that the output variable  Y  (i.e., response, or dependent variable) to be learned can be described by a reduced number of variables in the input space  X  (i.e., the domain, space of features or explanatory variables). Sparsity regularization methods focus on selecting the input variables that best describe the output. Structured sparsity regularization methods generalize and extend sparsity regularization methods, by allowing for optimal selection over structures like groups or networks of input variables in  X .\n\nCommon motivation for the use of structured sparsity methods are model interpretability, high-dimensional learning (where dimensionality of  X  may be higher than the number of observations  n ), and reduction of computational complexity. Moreover, structured sparsity methods allow to incorporate prior assumptions on the structure of the input variables, such as overlapping groups, non-overlapping groups, and acyclic graphs. Examples of uses of structured sparsity methods include face recognition, magnetic resonance image (MRI) processing, socio-linguistic analysis in natural language processing, and analysis of genetic expression in breast cancer.", "title": "Structured sparsity regularization", "category": "Machine learning"}
{"text": "In the fields of machine learning, the theory of computation, and random matrix theory, a probability distribution over vectors is said to be in isotropic position if its covariance matrix is equal to the identity matrix. ", "title": "Isotropic position", "category": "Machine learning"}
{"text": "Shane Legg  is a machine learning researcher and cofounder of DeepMind Technologies, acquired by Google in 2014.", "title": "Shane Legg", "category": "Machine learning researchers"}
{"text": "These datasets are used for machine-learning research and have been cited in peer-reviewed academic journals. Datasets are an integral part of the field of machine learning. Major advances in this field can result from advances in learning algorithms (such as deep learning), computer hardware, and, less-intuitively, the availability of high-quality training datasets. High-quality labeled training datasets for supervised and semi-supervised machine learning algorithms are usually difficult and expensive to produce because of the large amount of time needed to label the data. Although they do not need to be labeled, high-quality datasets for unsupervised learning can also be difficult and costly to produce.Weiss, Gary M., and Foster Provost. \"Learning when training data are costly: the effect of class distribution on tree induction.\" Journal of Artificial Intelligence Research (2003): 315\u2013354.Turney, Peter. \"Types of cost in inductive concept learning.\" (2000).Abney, Steven. Semisupervised learning for computational linguistics. CRC Press, 2007.\u017dliobait\u0117, Indr\u0117, et al. \"Active learning with evolving streaming data.\" Machine Learning and Knowledge Discovery in Databases. Springer Berlin Heidelberg, 2011. 597\u2013612.", "title": "List of datasets for machine-learning research", "category": "Machine learning"}
{"text": "The following table compares notable software frameworks, libraries and computer programs for deep learning.\n", "title": "Comparison of deep-learning software", "category": "Data mining and machine learning software"}
{"text": "Renjin is an implementation of the R programming language atop the Java Virtual Machine. It is free software released under  the GPL. Renjin is tightly integrated with Java to allow the embedding of the interpreter into any Java application with full two-way access between the Java and R code.\n\nRenjin's development is primarily supported by BeDataDriven, but ultimately made possible by several current and past contributors including Mehmet Hakan Satman,\nHannes M\u00fchleisen, and Ruslan Shevchenko.", "title": "Renjin", "category": "Data mining and machine learning software"}
{"text": "Vault AI is an Israeli\u2013based artificial intelligence company that lays claims to have created technologies that can \"read\" movie and TV screenplays in order to predict box office and investment performance.An AI to predict the success of a movie, a July 2015 article from Humanoids  Part of the process reportedly entails analyzing 300,000 to 400,000 elements from the script, which could be anything from plot, character development, script structure, scene events. This startup uses artificial intelligence to predict whether a Hollywood film will be a hit or a flop \u2014 just by scanning the script, a July 2015 article from Business Insider  The founders are made up of high frequency trading veterans and state they use similar approaches to predicting film performance.  Vault published its 2015 film predictions for over 20 movies in early 2015 and successfully predicted correctly many box office performances throughout that year.Using AI to pedict Hollywood hits, July 2015 article from Australian Robotics Review  Vault's algorithms out earned the market on a return on investment basis.2015 Predictions, Vaultml.com. July 2015.", "title": "VaultML", "category": "Machine learning"}
{"text": "Chih-Jen Lin () is Distinguished Professor of Computer Science at National Taiwan University, and a leading researcher in machine learning, optimization, and data mining. He is best known for the open source library LIBSVM, an implementation of support vector machines.", "title": "Chih-Jen Lin", "category": "Machine learning researchers"}
{"text": "Darkforest is a computer go program developed by Facebook, based on deep learning techniques using a convolutional neural network. Its updated version Darkfores2 combines the techniques of its predecessor with  Monte Carlo tree search. The MCTS effectively takes tree search methods commonly seen in computer chess programs and randomizes them. With the update, the system is known as Darkfmcts3.\n\nDarkforest is of similar strength to programs like CrazyStone and Zen.http://livestream.com/oxuni/StracheyLectureDrDemisHassabis It has been tested against a professional human player at the 2016 UEC cup. Google's AlphaGo program won against a professional player in October 2015 using a similar combination of techniques.\n\nDarkforest is named after Liu Cixin's science fiction novel The Dark Forest.", "title": "Darkforest", "category": "Machine learning"}
{"text": "Apache SystemML is a flexible machine learning system that automatically scales to Spark and Hadoop clusters. SystemML's\ndistinguishing characteristics are:\n\n Algorithm customizability via R-like and Python-like languages.\n Multiple execution modes, including Standalone, Spark Batch, Spark MLContext, Hadoop Batch, and JMLC.\n Automatic optimization based on data and cluster characteristics to ensure both efficiency and scalability.", "title": "Apache SystemML", "category": "Data mining and machine learning software"}
{"text": "Phocas Software is a business intelligence software company headquartered in Coventry, England. As of 2015, it services more than 1,000 customers.", "title": "Phocas Software", "category": "Data analysis software"}
{"text": "XGBoost is an open-source software library which provides a gradient boosting framework for C++, Java,\nPython,\nR, and\nJulia.\nIt works on Linux,\nWindows, and\nmacOS. From the project description, it aims to provide a \"Scalable, Portable and Distributed Gradient Boosting (GBM, GBRT, GBDT) Library\". Other than running on a single machine, it also supports the distributed processing frameworks Apache Hadoop, Apache Spark, and Apache Flink.\nIt has gained much popularity and attention recently as the algorithm of choice for many winning teams of machine learning competitions.", "title": "XGBoost", "category": "Data mining and machine learning software"}
{"text": "The Aphelion Imaging Software Suite is a software suite that includes three base products -  Aphelion Lab, Aphelion Dev, and Aphelion  for addressing image processing and image analysis applications. The suite also includes a set of extension programs to implement specific vertical applications that benefit from imaging techniques.\n\nThe Aphelion software products can be used to prototype and deploy applications, or can be integrated, in whole or in part, into a user's system as processing and visualization libraries whose components are available as both DLLs or .Net components.", "title": "Aphelion (software)", "category": "Data mining and machine learning software"}
{"text": "ND4J is a scientific computing and linear algebra library, written in the programming language Java, operating on the Java virtual machine (JVM), and compatible with other languages such as Scala, and Clojure. ND4J was contributed to the Eclipse Foundation in October 2017.\n\nND4J is for performing linear algebra and matrix manipulation in a production environment, integrating with Apache Hadoop and Spark to work with distributed central processing units (CPUs) or graphics processing units (GPUs). It supports n-dimensional arrays for JVM-based languages.\n\nND4J is free and open-source software, released under Apache License 2.0, and developed mostly by the group in San Francisco that built Deeplearning4j. It was created under an Apache Software Foundation license.", "title": "ND4J (software)", "category": "Data mining and machine learning software"}
{"text": "Movidius is a company based in San Mateo, California that designs specialised low-power processor chips for computer vision. The company was acquired by Intel in September 2016.", "title": "Movidius", "category": "Machine learning"}
{"text": "Microsoft Cognitive Toolkit,\n previously known as CNTK and sometimes styled as The Microsoft Cognitive Toolkit, is a deep learning framework developed by Microsoft Research. Microsoft Cognitive Toolkit describes neural networks as a series of computational steps via a directed graph.", "title": "Microsoft Cognitive Toolkit", "category": "Data mining and machine learning software"}
{"text": "AnswerRocket is an American computer software company based in Sandy Springs, GA. AnswerRocket is a natural language Search-Powered Analytics\u2122 solution that provides business intelligence and analytics to business users.", "title": "AnswerRocket", "category": "Data analysis software"}
{"text": "Bayesian structural time series (BSTS) model is a machine learning technique used for feature selection, time series forecasting, nowcasting, inferring causal impact and other applications. The model is designed to work with time series data.\n\nThe model has also promising application in the field of analytical marketing. In particular, it can be used in order to assess how much different marketing campaigns have contributed to the change in web search volumes, product sales, brand popularity and other relevant indicators. Difference-in-differences models and interrupted time series designs are alternatives to this approaches. \"In contrast to classical difference-in-differences schemes, state-space models make it possible to (i) infer the temporal evolution of attributable impact, (ii) incorporate empirical priors on the parameters in a fully Bayesian treatment, and (iii) flexibly accommodate multiple sources of variation, including the time-varying influence of contemporaneous covariates, i.e., synthetic controls.\"", "title": "Bayesian structural time series", "category": "Machine learning"}
{"text": "In statistics, spike-and-slab regression is a Bayesian variable selection technique that is particularly useful when the number of possible predictors is larger than the number of observations.\nInitially, the idea of the spike-and-slab model was proposed by Mitchell & Beauchamp (1988). The approach was further significantly developed by Madigan & Raftery (1994) and George & McCulloch (1997). The final adjustments to the model were done by Ishwaran & Rao (2005).", "title": "Spike-and-slab regression", "category": "Machine learning"}
{"text": "Most of the terms listed in Wikipedia glossaries are already defined and explained within Wikipedia itself.  However, glossaries like this one are useful for looking up, comparing and reviewing large numbers of terms together.  You can help enhance this page by adding new terms or writing definitions for existing ones.\n\nThis glossary of artificial intelligence terms is about artificial intelligence, its sub-disciplines, and related fields.", "title": "Glossary of artificial intelligence", "category": "Machine learning"}
{"text": "UNISoN is a Java application that can download Usenet messages from free NNTP servers, show the saved messages, then allow filtering of data to save to a Pajek network file or CSV file. It creates networks using the author of each post. If someone replies to a post, there is a unidirectional link created from the author of the post to the author of the message they are replying to. There is also a preview panel that shows the network visually. It was developed in 2008 as part of an MSc Business Systems Analysis & Design at City University London.Project Website(unison.sleonard.co.uk) and was released as Freeware. In 2016 the code was made Open Source.GitHub/unison/(GitHub)", "title": "UNISoN (Social Network Analysis Tool)", "category": "Data analysis software"}
{"text": "Continuous analytics is a data science process that abandons ETLs and complex batch data pipelines in favor of cloud-native and microservices paradigms. Continuous data processing enables realtime interactions and immediate insights with fewer resources.", "title": "Continuous analytics", "category": "Data analysis"}
{"text": "Bing Predicts is a prediction engine developed by Microsoft that uses machine learning from data on trending social media topics (and sentiment towards those topics), along with trending searches on Bing. It predicts the outcomes of political elections, popular reality shows, and major sporting events. Predictions can be accessed through the Bing search engine.", "title": "Bing Predicts", "category": "Machine learning"}
{"text": "This page is a timeline of machine learning. Major discoveries, achievements, milestones and other major events are included.", "title": "Timeline of machine learning", "category": "Machine learning"}
{"text": "Ilya Sutskever is a computer scientist working in machine learning and currently serving as the Chief scientist of OpenAI.\n\nHe has made several major contributions to the field of deep learning. He is the co-inventor of famous AlexNet, a convolutional neural network. He invented Sequence to Sequence Learning, together with Oriol Vinyals and Quoc Le. Sutskever is also co-inventor of AlphaGo, and TensorFlow.", "title": "Ilya Sutskever", "category": "Machine learning researchers"}
{"text": "Richard Zemel, better known by Rich Zemel, is a computer scientist and professor at University of Toronto, Department of Computer Science, and a leading figure in the field of Machine Learning and Computer Vision.\n\nZemel obtained his Ph.D under Geoffrey Hinton from University of Toronto, Department of Computer Science.", "title": "Richard Zemel", "category": "Machine learning researchers"}
{"text": "Dataiku is a computer software company headquartered in New York City. The company develops collaborative data science software marketed for big data.", "title": "Dataiku", "category": "Data analysis software"}
{"text": "Open coding in grounded theory method is the analytic process by which concepts (codes) to the observed data and phenomenon are attached during qualitative data analysis. It is one of the 'procedures' for working with text as characterized by Strauss (1987) and Strauss and Corbin (1990). Open coding aims at developing substantial codes describing, naming or classifying the phenomenon under consideration. Open coding is achieved by segmenting data into meaningful expressions and describing them in single words or short sequence of words. Further, relevant annotations and concepts are then attached to these expressions.\n\nOpen coding may be applied in varying degrees of detail. The codes can be linked to a line, a sentence, a paragraph or wholesome text (protocol, case, etc.). The application of the alternatives depends on the research question, on the relevant data, personal style of analyst and the stage of research. However, while coding, the main aim of coding should be in sight i.e. to break down and understand the text and develop categories to be put in order in the course of time.\n\nThe result of open coding should be a list characterising codes and categories attached to the text and supported by code notes that were produced to explain the content of codes. These notes could be striking observations and thoughts that are relevant to the development of theory.\n\nAlthough codes are exclusive to the research material and the style of the analyst, it is suggested researchers should address the text with the following questions:\n What? - Identify the underlying issue and the phenomenon\n Who? - Identify the actors involved and the roles they play.\n How? - Identifying the aspects of phenomenon\n When? How long? Where? - Time, course and location\n How much? How long? - Identifying the intensity \n Why? - Identifying the reasons attached to the phenomenon\n What for? - Identifying intention or purpose\n By which? - Strategies and tactics to achieve the goal", "title": "Open coding", "category": "Data analysis"}
{"text": "Connect is a new social network analysis software data mining computer system developed by HMRC (UK) that cross-references business's and people's tax records with other databases to establish fraudulent or undisclosed (misdirected) activity.", "title": "Connect (computer system)", "category": "Data analysis software"}
{"text": "Ian J. Goodfellow is a researcher working in machine learning, currently employed at Apple Inc. as its director of machine learning in the Special Projects Group. He was previously employed as a research scientist at Google Brain. He has made several contributions to the field of deep learning.", "title": "Ian Goodfellow", "category": "Machine learning researchers"}
{"text": "Thomas G. Dietterich is emeritus professor of computer science at Oregon State University. He is one of the founders of the field of machine learning. He served as executive editor of Machine Learning (journal) (1992\u201398) and helped co-found the Journal of Machine Learning Research. In response to the media's attention on the dangers of artificial intelligence, Dietterich has been quoted for an academic perspective to a broad range of media outlets including National Public Radio, Business Insider, Microsoft Research, CNET, and The Wall Street Journal.\n\nAmong his research contributions were the invention of error-correcting output coding to multi-class classification, the formalization of the multiple-instance problem, the MAXQ framework for hierarchical reinforcement learning, and the development of methods for integrating non-parametric regression trees into probabilistic graphical models.", "title": "Thomas G. Dietterich", "category": "Machine learning researchers"}
{"text": "Anthony Levandowski (born 15 March 15 1980) is an American self-driving car engineer. In 2016 he co-founded Otto, an autonomous trucking company, with Lior Ron, Claire Delaunay and Don Burnette. Prior to Otto, he built the Google self-driving car while working as a co-founder and technical lead on the project, known as Waymo. He is known for his work in the advancement of self-driving technology. In 2018 he co-founded Pronto, which he announced via a blog post. Pronto was the first company to complete a cross-country drive in an autonomous vehicle in October 2018. At the 2019 AV Summit hosted by The Information, Levandowski remarked that a fundamental breakthrough in AI is needed to move autonomous vehicle technology forward.\n\nOn May 15, 2017, United States District Judge \nbanned Levandowski from further work on Otto's Lidar technology on the basis of having breached the confidentiality of former employer Waymo.Case 3:17-cv-00939-WHA Document 433 Filed 05/15/17 \"By way of summary, this order finds plaintiff Waymo LLC has shown compelling evidence that its former star engineer, Anthony Levandowski, downloaded over 14,000 confidential files from Waymo immediately before leaving his employment there.\" \n On May 30th, 2017, Uber fired Levandowski for failing to cooperate with investigators.", "title": "Anthony Levandowski", "category": "Machine learning researchers"}
{"text": "Keras is an open-source neural-network library written in Python. It is capable of running on top of TensorFlow, Microsoft Cognitive Toolkit, Theano, or PlaidML. Designed to enable fast experimentation with deep neural networks, it focuses on being user-friendly, modular, and extensible. It was developed as part of the research effort of project ONEIROS (Open-ended Neuro-Electronic Intelligent Robot Operating System), and its primary author and maintainer is Fran\u00e7ois Chollet, a Google engineer. Chollet also is the author of the XCeption deep neural network model.\n\nIn 2017, Google's TensorFlow team decided to support Keras in TensorFlow's core library. Chollet explained that Keras was conceived to be an interface rather than a standalone machine learning framework. It offers a higher-level, more intuitive set of abstractions that make it easy to develop deep learning models regardless of the computational backend used.Chollet GitHub Comment Microsoft added a CNTK backend to Keras as well, available as of CNTK v2.0.CNTK Keras GitHub Issue", "title": "Keras", "category": "Data mining and machine learning software"}
{"text": "Klaus-Robert M\u00fcller (born 1964 in Karlsruhe, Germany) is a German physicist and computer scientist, most noted for his work in Machine Learning and Brain-Computer Interfaces.", "title": "Klaus-Robert M\u00fcller", "category": "Machine learning researchers"}
{"text": "Lior Ron (born March 16, 1977) is an Israeli-born businessman. He served in the Israel Defense Forces from 1997 to 2004, before attending Stanford to pursue a MBA. In 2016 he co-founded Otto, a self-driving truck company, with Anthony Levandowski, Claire Delaunay and Don Burnette. Prior to Otto he was the Product Lead for Google Maps and then the Product Lead for Motorola Mobility, which was acquired by Google in 2011.", "title": "Lior Ron (business executive)", "category": "Machine learning researchers"}
{"text": "The multiplicative weights update method is an algorithmic technique most commonly used for decision making and prediction, and also widely deployed in game theory and algorithm design. The simplest use case is the problem of prediction from expert advice, in which a decision maker needs to iteratively decide on an expert whose advice to follow. The method assigns initial weights to the experts (usually identical initial weights), and updates these weights multiplicatively and iteratively according to the feedback of how well an expert performed: reducing it in case of poor performance, and increasing it otherwise.  It was discovered repeatedly in very diverse fields such as machine learning (AdaBoost, Winnow, Hedge), optimization (solving linear programs), theoretical computer science (devising fast algorithm for LPs and SDPs), and game theory.", "title": "Multiplicative weight update method", "category": "Machine learning"}
{"text": "Computational X is the set of fields of study that have emerged from the applications of informatics and big data to specific disciplines. Examples include computational biology, computational neuroscience, computational physics, and computational linguistics.", "title": "Computational X", "category": "Data mining"}
{"text": "Negative testing is a method of testing an application or system that ensures that the plot of the application is according to the requirements and can handle the unwanted input and user behavior. Invalid data is inserted to compare the output against the given input. Negative testing is also known as failure testing or error path testing. When performing negative testing exceptions are expected. This shows that the application is able to handle improper user behavior. Users input values that do not work in the system to test its ability to handle incorrect values or system failure.", "title": "Negative testing", "category": "Data analysis"}
{"text": "Apache MXNet is an open-source deep learning software framework, used to train, and deploy deep neural networks. It is scalable, allowing for fast model training, and supports a flexible programming model and multiple programming languages (including C++, Python, Julia, Matlab, JavaScript, Go, R, Scala, Perl, and Wolfram Language.)\n\nThe MXNet library is portable and can scale to multiple GPUs and multiple machines. MXNet is supported by public cloud providers including Amazon Web Services (AWS) and Microsoft Azure. Amazon has chosen MXNet as its deep learning framework of choice at AWS. Currently, MXNet is supported by Intel, Dato, Baidu, Microsoft, Wolfram Research, and research institutions such as Carnegie Mellon, MIT, the University of Washington, and the Hong Kong University of Science and Technology.", "title": "Apache MXNet", "category": "Data mining and machine learning software"}
{"text": "AIVA (Artificial Intelligence Virtual Artist) is a electronic composer recognized by the SACEM.", "title": "AIVA", "category": "Machine learning"}
{"text": "Chainer is an open source deep learning framework written purely in Python on top of Numpy and CuPy Python libraries. The development is led by Japanese venture company Preferred Networks in partnership with IBM, Intel, Microsoft, and Nvidia.\n\nChainer is notable for its early adoption of \"define-by-run\" scheme, as well as its performance on large scale systems. The first version was released in June 2015 and has gained large popularity in Japan since then. Furthermore, in 2017, it was listed by KDnuggets in top 10 open source machine learning Python projects.", "title": "Chainer", "category": "Data mining and machine learning software"}
{"text": "Instance selection (or dataset reduction, or dataset condensation) is an important data pre-processing step that can be applied in many machine learning (or data mining) tasks.S. Garc\u00eda, J. Luengo, and F. Herrera, Data preprocessing in data mining. Springer, 2015. Approaches for instance selection can be applied for reducing the original dataset to a manageable volume, leading to a reduction of the computational resources that are necessary for performing the learning process. Algorithms of instance selection can also be applied for removing noisy instances, before applying learning algorithms. This step can improve the accuracy in classification problems.\n\nAlgorithm for instance selection should identify a subset of the total available data to achieve the original purpose of the data mining (or machine learning) application as if the whole data had been used. Considering this, the optimal outcome of IS would be the minimum data subset that can accomplish the same task with no performance loss, in comparison with the performance achieved when the task is performed using the whole available data. Therefore, every instance selection strategy should deal with a trade-off between the reduction rate of the dataset and the classification quality.", "title": "Instance selection", "category": "Machine learning"}
{"text": "Social profiling is the process of constructing a user's profile using his or her social data. In general, profiling refers to the data science process of generating a person's profile with computerized algorithms and technology. There are many mediums and platforms for sharing these information with the help of the increasing number of successful social networks, including but not limited to LinkedIn, Google+, Facebook and Twitter etc.", "title": "Social profiling", "category": "Data mining"}
{"text": "The following outline is provided as an overview of and topical guide to machine learning. Machine learning is a subfield of soft computing within computer science that evolved from the study of pattern recognition and computational learning theory in artificial intelligence.http://www.britannica.com/EBchecked/topic/1116194/machine-learning  In 1959, Arthur Samuel defined machine learning as a \"field of study that gives computers the ability to learn without being explicitly programmed\". Machine learning explores the study and construction of algorithms that can learn from and make predictions on data. Such algorithms operate by building a model from an example training set of input observations in order to make data-driven predictions or decisions expressed as outputs, rather than following strictly static program instructions.", "title": "Outline of machine learning", "category": "Machine learning"}
{"text": "Unihalt is a Visakhapatnam, India, based data analytics startup. It is first financially sustainable startup mentored by Startup Village. Unihalt is one of the IBM SmartCamp Vizag winners. They are picked up under IBM GEP for support.\n\nDanfeng Li, Director and the Chief Data Officer at Alibaba Group joined Unihalt as an advisor on its board.\n\nThe company has been closed down due to unknown reasons. The company http://www.unihalt.com official website is now unavailable.", "title": "Unihalt", "category": "Data analysis"}
{"text": "CAFFE (Convolutional Architecture for Fast Feature Embedding) is a deep learning framework, originally developed at University of California, Berkeley. It is open source, under a BSD license. It is written in C++, with a Python interface.", "title": "Caffe (software)", "category": "Data mining and machine learning software"}
{"text": "Stefan Schaal is a German-American computer scientist specializing in robotics, machine learning, autonomous systems, and computational neuroscience. Born in Frankfurt, Main in Germany, Schaal grew up in the North Bavarian town of N\u00fcrnberg. After graduating from school, he served in the German army in the Ski Patrol Division of Bad Reichenhall, where he honorably discharged with the rank of a Lieutenant. Schaal studied mechanical engineering at the Technical University of Munich, graduating in 1987 with a Diploma degree (Summa Cum Laude). Subsequently, Schaal did his Ph.D. in computer aided design and artificial intelligence at the Technical University of Munich and the Massachusetts Institute of Technology, receiving his Ph.D. in 1991 (Summa Cum Laude).\n\nIn 1991, Schaal was a Postdoctoral Fellow at the Department and Brain and Cognitive Science and the Artificial Intelligence Lab at the Massachusetts Institute of Technology, funded by the Alexander von Humboldt Foundation  and the German Scholarship Foundation. Starting from 1992, he became an invited researcher at the ATR Computational Neuroscience Labs in Japan, where he created a robotics lab focusing on biological principles of motor control and learning. In 1994, Schaal moved to the Georgia Institute of Technology as an adjunct assistant professor, and also held the same rank at the Pennsylvania State University. In 1996, Schaal assumed a group leader position in the ERATO Kawato Dynamic Brain Project in Japan. Starting from 1997, Schaal began his tenure at the University of Southern California, where he advanced from the ranks of assistant professor, to associate professor, to full professor.\n\nIn 2009, Schaal became a founder in defining and creating the Max Planck Institute for Intelligent Systems in T\u00fcbingen/Stuttgart Germany, an institute focusing on principles of perception-action-learning systems in synthetic intelligence. In 2012, Schaal created the Autonomous Motion Department at this institute and led it to international recognition.\n\nIn 2018, DER SPIEGEL published an article alleging that Schaal had improperly accepted the position at MPI while retaining his full-time position at USC and was under investigation for misuse of public funds. His employment for the Max Planck Society has since been terminated.\n\nStefan Schaal's interests focus on autonomous perception-action-learning systems, in particular anthropomorphic robotic systems. He works on topics of machine learning for control, control theory, computational neuroscience for neuromotor control, experimental robotics, reinforcement learning, artificial intelligence, and nonlinear dynamical systems. Stefan has co-authored more than 400 publications. in top conference and journals, and served as organizers on various top conferences in machine learning and robotics. He has received numerous best paper awards and honors in his scientific community. Stefan Schaal as been noted as one of the five leaders in robotics in 2011, and among the top robotics experts in the world.\n", "title": "Stefan Schaal", "category": "Machine learning researchers"}
{"text": "Stefano Soatto is Professor of Computer Science at the University of California, Los Angeles (UCLA), in Los Angeles, CA, where he is also Professor of Electrical Engineering and Founding Director of the UCLA Vision Lab. He was named Fellow of the Institute of Electrical and Electronics Engineers (IEEE) in 2013 for contributions to dynamic visual processes. He received the David Marr Prize in Computer Vision in 1999.", "title": "Stefano Soatto", "category": "Machine learning researchers"}
{"text": "Machine learning control (MLC) is a subfield of machine learning, intelligent control and control theorywhich solves optimal control problems with methods of machine learning.\nKey applications are complex nonlinear systems\nfor which linear control theory methods are not applicable.", "title": "Machine learning control", "category": "Machine learning"}
{"text": "Gary Bryce Fogel (born 1968) is an American biologist and computer scientist. He is the Chief Executive Officer of Natural Selection, Inc.http://www.natural-selection.com/management He is most known for his applications of computational intelligence and machine learning to bioinformatics, computational biology, and industrial optimization.", "title": "Gary B. Fogel", "category": "Machine learning researchers"}
{"text": "Machine learning, a subfield of computer science involving the development of algorithms that learn how to make predictions based on data, has a number of emerging applications in the field of bioinformatics. Bioinformatics deals with computational and mathematical approaches for understanding and processing biological data. \n\nPrior to the emergence of machine learning algorithms, bioinformatics algorithms had to be explicitly programmed by hand which, for problems such as protein structure prediction, proves extremely difficult. Machine learning techniques such as deep learning enable the algorithm to make use of automatic feature learning which means that based on the dataset alone, the algorithm can learn how to combine multiple features of the input data into a more abstract set of features from which to conduct further learning. This multi-layered approach to learning patterns in the input data allows such systems to make quite complex predictions when trained on large datasets. In recent years, the size and number of available biological datasets have skyrocketed, enabling bioinformatics researchers to make use of these machine learning systems. Machine learning has been applied to six main subfields of bioinformatics: genomics, proteomics, microarrays, systems biology, evolution, and text mining.", "title": "Machine learning in bioinformatics", "category": "Machine learning"}
{"text": "PyTorch is software, specifically a machine learning library for the programming language Python, based on the Torch library, used for applications such as deep learning and natural language processing. It is primarily developed by Facebook's artificial-intelligence research group, and Uber's Pyro probabilistic programming language software is built on it. It is free and open-source software released under one of the BSD licenses.\n\nPyTorch provides two high-level features:\n Tensor computing (like NumPy) with strong acceleration via graphics processing units (GPU)\n Deep neural networks built on a tape-based autodiff system", "title": "PyTorch", "category": "Data mining and machine learning software"}
{"text": "Arthur Zimek is a professor in data mining, data science and machine learning at the University of Southern Denmark in Odense, Denmark.\n\nHe graduated from the Ludwig Maximilian University of Munich in Munich, Germany, where he worked with Prof. Hans-Peter Kriegel. His dissertation on \"Correlation Clustering\" was awarded the \"SIGKDD Doctoral Dissertation Award 2009 Runner-up\" by the Association for Computing Machinery.\n\nHe is well knownE.g.  for his work on outlier detection, density-based clustering, correlation clustering, and the curse of dimensionality.\n\nHe is one of the founders and core developers of the open-source ELKI data mining framework.", "title": "Arthur Zimek", "category": "Machine learning researchers"}
{"text": "Mixture of experts refers to a machine learning technique where multiple experts (learners) are used to divide the problem space into homogeneous regions. An example from the computer vision domain is combining a neural network model for human detection with another for pose estimation. If the output is conditioned on multiple levels of probabilistic gating functions, the mixture is called a hierarchical mixture of experts.\nA gating network decides which expert to use for each input region. Learning thus consists of 1) learning the parameters of individual learners and 2) learning the parameters of the gating network.", "title": "Mixture of experts", "category": "Machine learning algorithms"}
{"text": "The International Journal of Data Warehousing and Mining (IJDWM). is a quarterly peer-reviewed academic journal covering data warehousing and data mining. It was established in 2005 and is published by IGI Global. The editor-in-chief is David Taniar (Monash University, Australia).", "title": "International Journal of Data Warehousing and Mining", "category": "Data mining"}
{"text": "Alexei \"Alyosha\" A. Efros is a Russian-American computer scientist and associate professor at University of California, Berkeley. He is widely recognized for his contributions to computer vision and his work has been referenced in media outlets including Wired, BBC News, The New York Times, and the New Yorker.", "title": "Alexei A. Efros", "category": "Machine learning researchers"}
{"text": "In machine learning, hyperparameter optimization or tuning is the problem of choosing a set of optimal hyperparameters for a learning algorithm. A hyperparameter is a parameter whose value is used to control the learning process. By contrast, the values of other parameters (typically node weights) are learned.\nThe same kind of machine learning model can require different constraints, weights or learning rates to generalize different data patterns. These measures are called hyperparameters, and have to be tuned so that the model can optimally solve the machine learning problem. Hyperparameter optimization finds a tuple of hyperparameters that yields an optimal model which minimizes a predefined loss function on given independent data.  The objective function takes a tuple of hyperparameters and returns the associated loss. Cross-validation is often used to estimate this generalization performance.", "title": "Hyperparameter optimization", "category": "Machine learning"}
{"text": "Connectionist temporal classification (CTC) is a type of neural network output and associated scoring function, for training recurrent neural networks (RNNs) such as LSTM networks to tackle sequence problems where the timing is variable. It can be used for tasks like on-line handwriting recognition or recognizing phonemes in speech audio. CTC refers to the outputs and scoring, and is independent of the underlying neural network structure. It was introduced in 2006.\n\nThe input is a sequence of observations, and the outputs are a sequence of labels, which can include blank outputs. The difficulty of training comes from there being many more observations than there are labels. For example in speech audio there can be multiple time slices which correspond to a single phoneme. Since we don't know the alignment of the observed sequence with the target labels we predict a probability distribution at each time step. A CTC network has a continuous output (e.g. softmax), which is fitted through training to model the probability of a label. CTC does not attempt to learn boundaries and timings: Label sequences are considered equivalent if they differ only in alignment, ignoring blanks. Equivalent label sequences can occur in many ways \u2013 which makes scoring a non-trivial task, but there is an efficient forward\u2013backward algorithm for that.\n\nCTC scores can then be used with the back-propagation algorithm to update the neural network weights.\n\nAlternative approaches to a CTC-fitted neural network include a hidden Markov model (HMM).", "title": "Connectionist temporal classification", "category": "Machine learning"}
{"text": "Documenting Hate is a project of ProPublica, in collaboration with a number of journalistic, academic, and computing organizations, for systematic tracking of hate crimes and bias incidents. It uses an online form to facilitate reporting of incidents by the general public. Since August 2017, it has also used machine learning and natural language processing techniques to monitor and collect news stories about hate crimes and bias incidents. , over 100 news organizations had joined the project.", "title": "Documenting Hate", "category": "Machine learning"}
{"text": "BigDL is a distributed deep learning framework for Apache Spark, created by Jason Dai at Intel.", "title": "BigDL", "category": "Data mining and machine learning software"}
{"text": "Rada Mihalcea is a professor of computer science and engineering at the University of Michigan. Her research focuses on natural language processing, multimodal processing, and computational social science.", "title": "Rada Mihalcea", "category": "Machine learning researchers"}
{"text": "Pushpak Bhattacharyya is a computer scientist and a Professor at Computer Science and Engineering Department, IIT Bombay. Currently, he is also the Director of Indian Institute of Technology Patna.Prof. Pushpak Bhattacharyya, Director IIT Patna Indian Institute of Technology Patna. Retrieved 2018-11-21. He is a past President of Association for Computational Linguistics (2016-17),Executive Committee Retrieved 2018-11-21. and Ex-Vijay and Sita Vashee Chair ProfessorChair Professors 2015 Retrieved 2018-11-21. He currently heads the Natural language processing research group Center For Indian Language Technology (CFILT) lab at IIT Bombay.", "title": "Pushpak Bhattacharyya", "category": "Machine learning researchers"}
{"text": "In machine learning, a highway network is an approach to optimizing networks and increasing their depth. Highway networks use learned gating mechanisms to regulate information flow, inspired by Long Short-Term Memory (LSTM) recurrent neural networks. The gating mechanisms allow neural networks to have paths for information to follow across different layers (\"information highways\").\n\nHighway networks have been used as part of text sequence labeling and speech recognition tasks.", "title": "Highway network", "category": "Machine learning"}
{"text": "Seeq Corporation is a software company,Seeq raises $6 million, looks to help manufacturers mine industrial data. GeekWire. Retrieved 2017-10-18. founded in 2013  and headquartered in Seattle, Washington, United States, that provides software with advanced analytics capabilities to the industrial process manufacturing sector including pharmaceutical,Creating Value from Data Assets. Pharmaceutical Manufacturing. Retrieved 2017-10-18. oil and gas,Remotely analyzing gas processing data. ISA.org. Retrieved 2017-10-18. mining and minerals, pulp and paper, energy and utilities,Harness big data to achieve big gains. Control. Retrieved 2017-10-18. IIoT,IIoT optimizes evaporative cooling. Control Engineering. Retrieved 2017-10-18. and chemical industries among others. Seeq's browser-based software is designed specifically for use with time series data\u201cSeeqing\u201d Out New Manufacturing Intelligence Methods. AutomationWorld. Retrieved 2017-10-18. which is most often aggregated in data historians such as OSIsoft's PI system, Inductive Automation's Ignition system and other similar data historians such as Emerson's Ovation and DeltaV, GE Proficy, Honeywell's Uniformance PHD, Wonderware, and AspenTech IP.21, as well as many others.Leveraging big data to streamline plant operations. Control. Retrieved 2017-10-18.\n\nSeeq's multiple applications allow organizations to analyze their data to improve business outcomes. Workbench, one of Seeq's applications, includes data visualization, data modeling, and interactive tools for diagnostic, monitoring, predictive and descriptive analyticsLeveraging Data Analytics Innovations to Improve Process Outcomes. BioPharm International. Retrieved 2017-10-18. It also includes Google-like search, knowledge-capture and collaboration tools. Seeq Organizer is used to create documents that assemble analyses and visualizations into reports, presentations, and meeting agendas. Organizer documents are dynamic because they tie directly to the underlying data, and are \u201ctime relative\u201d so they can be defined by any batch, shift, day, etc. Seeq Runtime performs continuous data cleansing, boundary management, and streaming calculations on historian data. The runtime, which is accessed through either Seeq Workbench or the Seeq REST API, runs autonomously and may be integrated with existing alarm systems or dashboard solutions.\n\nSeeq can be set up and running on a dedicated server, server cluster, or virtual machine in as little time as an hour. On-premise installations on the same network as a plant or enterprise historian, or on the cloud (Microsoft Azure, Amazon Web Services, etc.), or on a mixed environment of on-premise and cloud resources are supported. Seeq is extensible through data export, data integration, and a REST API for creating custom templates and modules. Data export options include Microsoft Excel and PowerPoint, and any OData client (Tableau, Microsoft PowerBI, etc.). Data integration with OSIsoft Vision is supported, and the REST API has SDKs for programming in C#, Python, MatLab, and Java. Seeq does not copy or duplicate data from the source of record. Instead, data is accessed via a connector retrieving data on the fly based on user actions. All Seeq documents such as workbooks, worksheets, topics, and search definitions are stored by Seeq for easy user access and sharing.", "title": "Seeq Corporation", "category": "Data analysis software"}
{"text": "Algorithmic bias describes systematic and repeatable errors in a computer system that create unfair outcomes, such as privileging one arbitrary group of users over others. Bias can emerge due to many factors, including but not limited to the design of the algorithm itself, unintended or unanticipated use or decisions relating to the way data is coded, collected, selected or used to train the algorithm. Algorithmic bias is found across platforms, including but not limited to search engine results and social media platforms, and can have impacts ranging from inadvertent privacy violations to reinforcing social biases of race, gender, sexuality, and ethnicity. The study of algorithmic bias is most concerned with algorithms that reflect \"systematic and unfair\" discrimination. This bias has only recently been addressed in legal frameworks, such as the 2018 European Union's General Data Protection Regulation.\n\nAs algorithms expand their ability to organize society, politics, institutions, and behavior, sociologists have become concerned with the ways in which unanticipated output and manipulation of data can impact the physical world. Because algorithms are often considered to be neutral and unbiased, they can inaccurately project greater authority than human expertise, and in some cases, reliance on algorithms can displace human responsibility for their outcomes. Bias can enter into algorithmic systems as a result of pre-existing cultural, social, or institutional expectations; because of technical limitations of their design; or by being used in unanticipated contexts or by audiences who are not considered in the software's initial design.\n\nAlgorithmic bias has been cited in cases ranging from election outcomes to the spread of online hate speech. Problems in understanding, researching, and discovering algorithmic bias stem from the proprietary nature of algorithms, which are typically treated as trade secrets. Even when full transparency is provided, the complexity of certain algorithms poses a barrier to understanding their functioning. Furthermore, algorithms may change, or respond to input or output in ways that cannot be anticipated or easily reproduced for analysis. In many cases, even within a single website or application, there is no single \"algorithm\" to examine, but a network of many interrelated programs and data inputs, even between users of the same service.", "title": "Algorithmic bias", "category": "Machine learning"}
{"text": "Automated machine learning (AutoML) is the process of automating the end-to-end process of applying machine learning to real-world problems. In a typical machine learning application, practitioners must apply the appropriate data pre-processing, feature engineering, feature extraction, and feature selection methods that make the dataset amenable for machine learning. Following those preprocessing steps, practitioners must then perform algorithm selection and hyperparameter optimization to maximize the predictive performance of their final machine learning model. As many of these steps are often beyond the abilities of non-experts, AutoML was proposed as an artificial intelligence-based solution to the ever-growing challenge of applying machine learning. Automating the end-to-end process of applying machine learning offers the advantages of producing simpler solutions, faster creation of those solutions, and models that often outperform models that were designed by hand.", "title": "Automated machine learning", "category": "Machine learning"}
{"text": "Babak Hodjat (born in 1967) is the co-founder and CEO of Sentient Technologies. He is a specialist in the field of artificial intelligence and machine learning.", "title": "Babak Hodjat", "category": "Machine learning researchers"}
{"text": "Tech mining or technology mining refers to applying text mining methods to technical documents. For patent analysis purposes, it is named \u2018patent mining\u2019. Porter, as one of the pioneers in technology mining, defined \u2018tech mining\u2019 in his book as follows: \u201cthe application of text mining tools to science and technology information, informed by understanding of technological innovation processes.\u201d Therefore, tech mining has two significant characteristics: 1) using \u2018text mining tools\u2019, 2) applying these tools to \u2018technology management\u2019. Also, technology mining can be considered as one of technology intelligence branches.", "title": "Technology mining", "category": "Data mining"}
{"text": "Algorithms of Oppression: How Search Engines Reinforce Racism is a 2018 book by Safiya Noble in the fields of information science, machine learning, and human-computer interaction.", "title": "Algorithms of Oppression", "category": "Machine learning algorithms"}
{"text": "ads.txt (Authorized Digital Sellers) is an initiative from IAB Technology Laboratory. It specifies a text file that companies can host on their web servers, listing the other companies authorized to sell their products or services. This is designed to allow online buyers to check the validity of the sellers from whom they buy, for the purposes of internet fraud prevention.", "title": "Ads.txt", "category": "Data analysis"}
{"text": "Argument mining, or argumentation mining, is a research area within the natural-language processing field. The goal of argument mining is the automatic extraction and identification of argumentative structures from natural language text with the aid of computer programs. Such argumentative structures include the premise, conclusions, the argument scheme and the relationship between the main and subsidiary argument, or the main and counter-argument within discourse. The Argument Mining workshop series is the main research forum for argument mining related research.", "title": "Argument mining", "category": "Data mining"}
{"text": "Carol E. Reiley is an entrepreneur, computer scientist, and roboticist. She is a pioneer in teleoperated and autonomous robot systems in applications such as surgery, space exploration, disaster rescue and self driving cars. She previously worked at Intuitive Surgical, Lockheed Martin, and General Electric. She co-founded, invested, and was President of Drive.ai raising over $77 million. She is the first female engineer on the cover of MAKE magazine and is recognized by Forbes, Inc, and Quartz as a top female entrepreneur. She is a published children's book author.  She is currently CEO of a healthcare startup, a creative advisor of the San Francisco Symphony, and a brand ambassador for Guerlain Cosmetics.", "title": "Carol E. Reiley", "category": "Machine learning researchers"}
{"text": "RAMnets is one of the oldest practical neurally inspired classification algorithm is still one of the best. The RAMnets  is also known as a type of \"n-tuple recognition method\" or \"weightless neural network\".", "title": "RAMnets", "category": "Machine learning"}
{"text": "Paul Viola is a computer vision researcher, former MIT professor, and vice president of science for Amazon Air. He is best \nknown for his seminal work in facial recognition and machine learning.   He is \nthe co-inventor of the Viola\u2013Jones object detection framework along with Michael Jones. He won the Marr Prize in 2003 and the Helmholtz Prize from the International Conference on Computer Vision in 2013.\nHe\nis the holder of at least 57 patents in the areas of advanced machine learning, web search,\ndata mining, and image processing.\nHe is the author of more than 50 academic\nresearch papers with over 56,000 citations.\n", "title": "Paul Viola", "category": "Machine learning researchers"}
{"text": "Forrest Iandola is an American computer scientist and entrepreneur. While a graduate student at University of California, Berkeley, Iandola developed SqueezeNet, a lightweight deep neural network that has been deployed on smartphones and other embedded devices. Iandola is the co-founder of DeepScale, which develops energy-efficient deep learning technology for the automotive industry.", "title": "Forrest Iandola", "category": "Machine learning researchers"}
{"text": "ML.NET is a free software machine learning library for the C#, F# and VB.NET programming languages. It also supports Python models when used together with NimbusML. The preview release of ML.NET included transforms for feature engineering like n-gram creation, and learners to handle binary classification, multi-class classification, and regression tasks. Additional ML tasks like anomaly detection and recommendation systems have since been added, and other approaches like deep learning will be included in future versions.", "title": "ML.NET", "category": "Data mining and machine learning software"}
{"text": "Ashutosh Saxena is an Indian-American Computer Scientist, Researcher, and Entrepreneur known for his contributions to the field of Artificial Intelligence and Robotics. His research interests include Machine Learning, Robotics, and 3-Dimensional Computer Vision. Dr. Saxena is the Co-Founder and CEO of Caspar.AI, which is an artificial intelligence company that automates peoples' homes and learns from their preferences via the use of electronic appliances and sensors. Prior to Caspar.AI, Ashutosh co-founded Cognical Zibby, which provides a no credit required alternative to traditional financing for online and omni-channel retail. Before Cognical Zibby, Dr. Saxena was an Assistant Professor in the Computer Science Department and Director of the RoboBrain Project at Cornell University.", "title": "Ashutosh Saxena", "category": "Machine learning researchers"}
{"text": "The Adamic/Adar index is a measure introduced in 2003 by Lada Adamic and Eytan Adar to predict links in a social network, according to the amount of shared links between two nodes. It is defined as the sum of the inverse logarithmic degree centrality of the neighbours shared by the two nodes\n\nA(x,y) = \\sum_{u \\in N(x) \\cap N(y)} \\frac{1}{\\log{|N(u)|}}\n\n\nwhere N(u) is the set of nodes adjacent to u. Such definition is based on the concept that common elements with very large neighbourhoods are lesser significant when predicting a connection between two nodes compared with elements shared between a small number of nodes..", "title": "Adamic/Adar index", "category": "Data mining"}
{"text": "Yee Whye Teh is a Professor of Statistical Machine Learning in the Department of Statistics at the University of Oxford. Prior to 2012 he was a reader at the Gatsby Computational Neuroscience Unit at University College London. His work is primarily in machine learning.", "title": "Yee Whye Teh", "category": "Machine learning researchers"}
{"text": "rnn is an open-source machine learning framework that implements Recurrent Neural Network architectures, such as LSTM and GRU, natively in the R programming language.\n\nThe rnn package is distributed through the Comprehensive R Archive Network under the open-source GPL v3 license.", "title": "Rnn (software)", "category": "Data mining and machine learning software"}
{"text": "Appen Limited (formerly known as Appen Butler Hill) is a publicly traded company listed on the Australian Securities Exchange (ASX) under the code APX.\n\nAppen provides or improves data used for the development of machine learning and artificial intelligence products. Data types include speech and natural language data, image and video data, text and alphanumeric data and relevance data to improve search and social media engines. Appen's customers use machine learning for a variety of use cases including automatic speech recognition (ASR), computer vision, increasing conversions in eCommerce, delivering more meaningful and personalized advertising, enhancing social media feeds or improving customer service capabilities with tools like chatbots and virtual assistants.\n\nFor machines to demonstrate artificial intelligence, they need to be programmed with human-quality training data that helps them learn.  Appen uses crowdsourcing to collect and improve data and has access to a skilled crowd of over than 1,000,000 part-time contractors who collect, annotate, evaluate, label, rate, test, translate and transcribe speech, image, text and video data to turn it into effective machine learning training data for a variety of use cases.", "title": "Appen (company)", "category": "Machine learning"}
{"text": "Geoffrey J. Gordon is a professor at the Machine Learning Department at Carnegie Mellon University in Pittsburgh and director of research at the Microsoft Montr\u00e9al lab.Microsoft appoints Carnegie Mellon professor to head expanded Montreal AI research lab, itbusiness.ca, 2018-01-24Leaders in Davos acknowledge AI\u2019s potential for good, but point to unanswered questions, Justin Trudeau twittering about Gordons appointment from WEF, itbusiness.ca. 2018-01-24.Here's Why Canada Can Win The AI Race, Forbes, 2018-03-13Canadian Tech Sector Thrives, but Struggles to Keep Its Talent, Wall Street Journal, 2018-02-08.Microsoft announces expansion of Montreal AI research lab, windowscentral, 2018-01-24. He is known for his research in statistical relational learning (a subdiscipline of artificial intelligence and machine learning) and on anytime dynamic variants of the A* search algorithm.Likhachev, Maxim; Gordon, Geoff; Thrun, Sebastian. \"ARA*: Anytime A* search with provable bounds on sub-optimality\". In S. Thrun, L. Saul, and B. Sch\u00f6lkopf, editors, Proceedings of Conference on Neural Information Processing Systems (NIPS), Cambridge, MA, 2003. MIT Press. His research interests include multi-agent planning, reinforcement learning, decision-theoretic planning, statistical models of difficult data (e.g. maps, video, text), computational learning theory, and game theory.\n\nGordon received a B.A. in computer science from Cornell University in 1991, and a Phd at Carnegie Mellon in 1999.", "title": "Geoffrey J. Gordon", "category": "Machine learning researchers"}
{"text": "Andrej Karpathy (born October 23, 1986Self-reported on twitter) is the director of artificial intelligence and Autopilot Vision at Tesla. He specializes in deep learning and image recognition and understanding.\n\nAndrej Karpathy was born in Slovakia and moved with his family to Toronto when he was 15. He completed his Computer Science and Physics undergraduate degree at University of Toronto in 2009 and completed his Master's degree at University of British Columbia in 2011, where he worked on physically-simulated figures. He graduated with PhD from Stanford University in 2015 under the supervision of Dr. Fei-Fei Li, focusing on intersection of natural language processing and computer vision, and deep learning models suited for this task. He joined the artificial intelligence group OpenAI as a research scientist in September 2016 and became Tesla\u2019s director of artificial intelligence in June 2017.\n\nHe has a YouTube channel dedicated to speedcubing.YouTube channel badmephisto", "title": "Andrej Karpathy", "category": "Machine learning researchers"}
{"text": "An associative classifier (AC) is a kind of supervised learning model that uses association rules to assign a target value. The term associative classification was coined by Bing Liu et al., in which the authors defined a model made of rules \"whose right-hand side are restricted to the classification class attribute\".", "title": "Associative classifier", "category": "Machine learning"}
{"text": "The tidyverse is a collection of R packages introduced by Hadley Wickham and his team that \"share an underlying design philosophy, grammar, and data structures\" of tidy data. The core packages are ggplot2, dplyr, tidyr, readr, purrr, tibble, stringr, and forcats, which provide functionality to model, transform, and visualize data. As of November 2018, the tidyverse package and some of its individual packages make up 5 out of the top 10 most downloaded R packages, and are the subject of multiple books and papers.", "title": "Tidyverse", "category": "Data analysis software"}
{"text": "Angelo Dalli (born 14 April 1978) is a computer scientist specialising in artificial intelligence, a serial entrepreneur, and business angel investor.", "title": "Angelo Dalli", "category": "Machine learning researchers"}
{"text": "Triplet loss is a loss function for artificial neural networks where a baseline (anchor) input is compared to a positive (truthy) input and a negative (falsy) input. The distance from the baseline (anchor) input to the positive (truthy) input is minimized, and the distance from the baseline (anchor) input to the negative (falsy) input is maximized.\n\nIt is often used for learning similarity of for the purpose of learning embeddings, like word embeddings and even thought vectors, and metric learning.\n\nThe loss function can be described using a Euclidean distance function\n\n \\mathcal{L} \\left ( A, P, N \\right ) =\\operatorname{max} \\left (\n {\\| \\operatorname{f} \\left ( A \\right ) - \\operatorname{f} \\left ( P \\right ) \\|}^2\n - {\\| \\operatorname{f} \\left ( A \\right ) - \\operatorname{f} \\left ( N \\right ) \\|}^2\n + \\alpha, 0 \\right )\n where A is an anchor input, P is a positive input of the same class as A , N is a negative input of a different class from A, \\alpha is a margin between positive and negative pairs, and \\operatorname{f} is an embedding.\n\nThis can then be used in a cost function, that is the sum of all losses, which can then be used for minimization of the posed optimization problem\n\n \\mathcal{J} = \\sum_{i=1}^{{}M} \\mathcal{L} \\left ( A ^{(i)}, P ^{(i)}, N ^{(i)} \\right ) \n\nThe indexes are for individual input vectors given as a triplet. The triplet is formed by drawing an anchor input, a positive input that describes the same entity as the anchor entity, and a negative input that does not describe the same entity as the anchor entity. These inputs are then run through the network, and the outputs are used in the loss function.\n\nIn computer vision a prevailing belief has been that the triplet loss is inferior to using surrogate losses followed by separate metric learning steps. Alexander Hermans, Lucas Beyer, and Bastian Leibe showed that for models trained from scratch, as well as pretrained models, a special version of triplet loss doing end-to-end deep metric learning outperforms most other published methods as of 2017.", "title": "Triplet loss", "category": "Machine learning algorithms"}
{"text": "Social Blade (sometimes spelled SocialBlade) is a website that tracks social media statistics and analytics. Social Blade most notably tracks the YouTube platform, but also has analytical information regarding Twitch, Instagram, Twitter, Facebook, Mixer, and Dailymotion. Social Blade functions as a third-party to the respective social media platforms. Jason Urgo is the CEO of Social Blade.", "title": "Social Blade", "category": "Data analysis"}
{"text": "Tamara Ann Broderick is an American mathematician and computer scientist at the Massachusetts Institute of Technology. She works on machine learning and Bayesian inference.", "title": "Tamara Broderick", "category": "Machine learning researchers"}
{"text": "Animashree (Anima) Anandkumar is the Bren Professor of Computing at California Institute of Technology. She is a director of Machine Learning research at NVIDIA. Her research considers tensor-algebraic methods, deep learning and non-convex problems.", "title": "Anima Anandkumar", "category": "Machine learning researchers"}
{"text": "Tal Arbel is a Professor of Electrical Engineering at McGill University who specialises in computer vision. She is interested in the application of artificial intelligence in healthcare.", "title": "Tal Arbel", "category": "Machine learning researchers"}
{"text": "waifu2x is an image scaling and noise reduction program for anime-style art, but also supports photos.\n\nwaifu2x was inspired by Super-Resolution Convolutional Neural Network (SRCNN).https://github.com/nagadomi/waifu2xDong C, Loy C C, He K, et al. [J]. IEEE Transactions on Pattern Analysis and Machine Intelligence, 2016, 38(2): 295-307. It uses Nvidia CUDA for computing.", "title": "Waifu2x", "category": "Machine learning"}
{"text": "A learning curve shows the validation and training score of an estimator for varying numbers of training samples. It is a tool to find out how much a machine learning model benefits from adding more training data and whether the estimator suffers more from a variance error or a bias error. If both the validation score and the training score converge to a value that is too low with increasing size of the training set, it will not benefit much from more training data.\n\nThe machine learning curve is useful for many purposes including comparing different algorithms,  choosing model parameters during design, adjusting optimization to improve convergence, and determining the amount of data used for training.\n\nIn the machine learning domain, there are two connotations of learning curves differing in the x-axis of the curves, with experience of the model graphed either as the number of training examples used for learning or the number of iterations used in training the model.", "title": "Learning curve (machine learning)", "category": "Machine learning"}
{"text": "The learning rate or step size in machine learning is a hyperparameter which determines to what extent newly acquired information overrides old information. The learning rate is often denoted by the character \u03b7 or \u03b1. A too high learning rate will make the learning jump over minima but a too low learning rate will either take too long to converge or get stuck in an undesirable local minima. Constant learning rates are always smaller than 1 as otherwise the learning will not converge and typically take on values ranging from 0.0001 to 0.4 but this is highly dependent upon the problem at hand. In order to achieve faster convergence, prevent oscillations and getting stuck in undesirable local minima the learning rate is often varied during training either in accordance to a learning rate schedule or by using an adaptive learning rate.", "title": "Learning rate", "category": "Machine learning"}
{"text": "Deep reinforcement learning (DRL) uses deep learning and reinforcement learning principles in order to create efficient algorithms that can be applied on areas like robotics, video games, finance, healthcare. Implementing deep learning architecture (deep neural networks or etc) with reinforcement learning algorithm (Q-learning, actor critic or etc), a powerful model (DRL) can be created that is capable to scale to problems that were previously unsolvable.That is because DRL usually uses raw sensor or image signals as input as can be seen in DQN for ATARI games, and can receive the benefit of end-to-end reinforcement learning as well as that of convolutional neural network.", "title": "Deep reinforcement learning", "category": "Machine learning algorithms"}
{"text": "Tom\u00e1\u0161 Mikolov is a Czech computer scientist working in the field of machine learning. He is currently a Research Scientist at Facebook.\n\nTomas Mikolov has made several contributions to the field of deep learning and natural language processing. He is mostly known as the inventor of the famous word2vec method of Word embedding.", "title": "Tomas Mikolov", "category": "Machine learning researchers"}
{"text": "Tang Xiao\u2019ou () is the founder of SenseTime, an artificial intelligence (AI) company, and remains a professor at the Chinese University of Hong Kong with the Department of Information Engineering.", "title": "Tang Xiao'ou", "category": "Machine learning researchers"}
{"text": "Weak supervision is a branch of machine learning where noisy, limited, or imprecise sources are used to provide supervision signal for labeling large amounts of training data in a supervised learning setting. This approach alleviates the burden of obtaining hand-labeled data sets, which can be costly or impractical. Instead, inexpensive weak labels are employed with the understanding that they are imperfect, but can nonetheless be used to create a strong predictive model.", "title": "Weak supervision", "category": "Machine learning researchers"}
{"text": "Federated learning designates a set of techniques striving to simultaneously train a single machine learning algorithm across multiple decentralized servers holding local data samples, without exchanging their data samples. This approach stands in contrast to traditional centralized machine learning techniques where all data samples are uploaded to one server, as well as to more classical decentralized approaches which assume that local data samples are identically distributed.\n\nFederated learning enables multiple actors to build a common, robust machine learning model without sharing data samples, thus addressing critical issues such as data privacy, data security, data access rights and access to heterogeneous data. Its applications are spread over a number of industries including defense, telecommunications, IoT, or pharmaceutics.\n\n Definition \nFederated learning aims at training a machine learning algorithm, for instance deep neural networks, on multiple local datasets contained in local nodes without exchanging data samples. The general principle consists in training local models on local data samples and exchanging parameters (e.g. the weights of a deep neural network) between these local models at some frequency to generate a global model.\n\nFederated learning algorithms may use a central server that orchestrates the different steps of the algorithm and acts as a reference clock, or they may be peer-to-peer, where no such central server exists. In the non peer-to-peer case, a federated learning process can be broken down in multiple rounds, each consisting of 4 general steps.\n\nThe main difference between federated learning and distributed learning lies in the assumptions made on the properties of the local datasetsFederated Optimization: Distributed Optimization Beyond the Datacenter, Jakub Konecny, H. Brendan McMahan, Daniel Ramage, 2015, as distributed learning originally aims at parallelizing computing power where federated learning originally aims at training on heterogeneous datasets. While distributed learning also aims at training a single model on multiple servers, a common underlying assumption is that the local datasets are identically distributed and roughly have the same size. None of these hypotheses are made for federated learning; instead, the datasets are typically heterogeneous and their sizes may span several orders of magnitude.\n\n Federated learning important features ", "title": "Federated learning", "category": "Machine learning"}
{"text": "Weaviate is an open source knowledge graph based on a vector storage mechanism called the contextionary. It allows a user to search for context or keywords in a dataset rather than fixed keywords alone. It provides a GraphQL interface to query the knowledge graph and an HTTP web interface to add the data via an ontology schema.", "title": "Weaviate", "category": "Data mining and machine learning software"}
